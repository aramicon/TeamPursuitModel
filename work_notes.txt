-- launch mongo
C:\mongodb\bin\mongod.exe  --config C:\mongodb\data\db\mongod.cfg

-- try to not lose the best strat in each generation through mutation (keep one pure copy)

-- figure out how to send info from the test to GA to the tester

-- read the wiki on GAs: https://en.wikipedia.org/wiki/Genetic_algorithm

-- first launch mongo with C:\mongodb\bin\mongod.exe  --config C:\mongodb\data\db\mongod.cfg

-- now launch the experiment server in C:\Users\Donal\Documents\Projects\RESEARCH\bikeracing\TeamPursuitModel\TeamPursuitModel\experiment_server
node app.js

-- why don't I move the whole thing onto the node server??

-- how do i serve up a flat html page?

-- foook... i already had a page built for creating settings :-( this is now done twice. but hey.

-- create a new url path for http://127.0.0.1:3003/ga/ and load up the main ga page, no?

-- ok, so moved a lot of files, and renamed stuff, and it now loads from node

-- clean up the js- put it all under a public/js folder

-- ok, so it now serves up the files and seeeems to run the GA

-- now look at getting the settings to port from the GA to the game version

-- create a new route for the game version 

-- ok, can now access and run the original game via http://127.0.0.1:3003/tpgame

-- oh, since everything is on node I can just send the id of the settings in the db long with the instructions?

-- tpgame can then do its own lookup? try try

-- id is not being returned from the db. do i need to add it to the global_settings?

-- how can I add it... don't want to save it in the general settings. 
-- maybe store it in another field? Hidden?

-- bug: if i use one very strong rider it evolves to be the lead rider, but when i watch it in the game it drops the others and laps them, so the time taken is much longer than the GA's version. Must be some difference in the physics again :-(

-- at least fix the GA to keep the best riders

-- fuck, GA is actually very different, I must have changed it a lot... looks at groups in the population. But it is losing the winners as it goes from one generation to the next in some cases. Must fix.

-- note: if instructions or startign order do not change, there's no need to re-run that race

- save this file and commit everything.

-- two main issues right now: putting strong rider on front for too long. ANd GA losing the best strat from popualtion to popualtion.

-- 16th march
-- look at losing-best-strat issue first 
-- record the best strat after running races, then find where it is in the next gen.

-- ok, need to work on how to identify strats and add a few more properties, like the generation, a type, and a variant counter
-- all variant ids are the same? eek. need to set up the id props at the first gen as well

everything in the id is undefined after we run first batch of races. Warum??

-- now they have legit ids from one generation to the next-- need to now look at the groups/tounraments in a generation and see what is happpening there

-- looks like it works ok and the fastest strat is kept

-- BUT!! found example where the starting order of the fastest race is changed! this must be it!

-- also found another one where the time taken jumps by 1- but it looks like the instrucitons are identical and starting_ordet oo, so maybe a rounding issue?

-- ok, so starting_order changes for the whole population hwne it is shuffled, not for a single race... oops

-- right, so thsi reproduces the bug:
a = {id:1,s:[0,1,2]};
b = {};
b.id = 2;
b.s = a.s;
b.s[0] = 5

-- now both a.s[0] and b.s[0] will be 5. when we assign b.s = a.s it is a reference that is stored. then because we shuffle in place and do not return a new array, kerpoom!

-- could look for JS 'deepcopy' and change = line OR return a new array with the shuffle instead of just editing the original?

-- made slight change to the shuffle array. not sure why it goes down through the array and not up. why?

-- need a deep copy. leave shuffle as is (uses less ram?) use Array.from() when we assign start_order

let a = [1,2,3];
let b = Array.from(a);

-- no waits, can use the ES6 b = [...a] syntax :-)

-- what else am I shuffling and does it break?
-- just the new_population i thinks

-- goooood, seems to have fixed that issue.

-- now on to the problem with getting different outcomes in the visual and ga races 

-- so when i run the ga i am getting faster times... in the game version the lead riders are dropping others 

-- will have to switch on the big logging messages setting to see what's goign down.

-- was able to run the logging on the ga end but not the game one

-- settings id is not loaded into the url in the ga results 

-- ah, when i update settings it doesn't display the id <span>

-- fixed... update relies with data.value.name etc. 

-- now need to change so that the logging is NOT done when running the GA itself... 

-- bah, getting the error Uncaught (in promise) TypeError: Assignment to constant variable. seems you can't mod anything that comes in from an export, so I have to assigne those to local vars instead

-- enough for today... fixed one bug, now need to retest the game, currenlty it does seem to displat intstructions but...
-- looks like the start_order is NOT being used now when i load settings via url- makes sense as it ALSO gets a start order from the settings and needs to make sure the url one is taken 

-- also, fatigue dispaly looks suspicious, will need to look into wy it is 5/5 for the strong rider.

-- wednesday 18th, day after P day. do one hour. also, do diary today. and get outside.

-- created a new batch script to launch things quicker, now have START_TPURSUIT_APP.bat on the desktop to start mongo, node and chrome

-- now try to change how settings are applied... basic problem=url start_order loaded, then db settings loaded that overwrite this.. split things up.
-- 1, get id
-- 2, load db settings
-- 3, add start_order and instructions from url

-- done BUT looks like the order is not used :-( will need to dig more. first switch off the logging to speedo speedo.

-- balls, fixed some more BUT time still off... are the instructions being run? 

-- ignores first two instrucitons??

-- ok, it gets the instruction but the rider doesn't drop back... a rider is supposed to drop back only in certain track areas so the IF for this may be failing? will continue later, my hour is done and wellll done.

-- -- monday april 6th
-- to get back into it, add a vertical slider on the game page to adjust the SPEED of the game, i.e. the wait between moves... maybe in notches, 0-1 second

-- 1 = slowest, maybe 1000
-- 10 = quickest, maybe 1
-- slider provides 1 - 10
-- so what formula? (10-x)*100?

-- first attempt, 200 is way too slow, need to rejig and shrink everything a bit. linear from 0 to 1000
-- ok, so new formula is simply (10-x)*60. defaulted to 120. works ol. commit to git then
-- done, a/G_6

-- try to make the GA page a 3 column design as opposed to just 1
-- put rows and cols into the GA page
-- add tooltop text to the table
--fuckkk... massive problems caused by <script src = "js/ga.js" type="module"></script>
-- why was type="module" included? still seems to work without it and fixes painful funciton not defined bug

-- ok, added column names, and also added a double-click event that updates the single race settings

--robustness check not working
-- page looks much neater: do the same for the race page itself.

-- tuesday April 7th., home. coronatime

-- first get the robustness going. was throwing an error.

-- ui. when you double-click an id, have note saying 'generation 23 best race loaded'

-- done, beter comment, robustness works, also added id to results.

-- remove the unused info from the end of the results table

-- move to the game view and start improving
-- add bootstrap row/cols 

-- stuff won't fit, need to move things about

-- ok, better now, need to look ahead

-- aim is to have d3.js drawring a bunch of different graphs... need to be able to get the data to d3
-- could look at
-- 1: returning the data from the worker as pure json
-- 2: parsing that json, i.e. doing the display code on the front JS
-- 3: saving that results json to mongo
-- 4: adding enough info when saving to be able to list and retrive again, such that it is somewhat replicable, e.g. all settings used 
-- 5: having another page accessed from the panel that would allow me to go through the results and start building graphs for the data
-- first graph: fitness from generation to generation (simple line)
-- need to be able to save/export the graph as jpen/png
-- as usual commit to git

-- wednesday april 8th.

-- so far a shit day for productivity. pure muck. and already 5PM 5PM that's fuckign crazy

-- changed bat file to also load this file.

-- work on saving results to mongo after running a 'test'.
-- need to save the date_time plus all of the settings used... 
-- added a button but big change needed to save results: need to return the results as a JSON array, not as HTML, dameet.

-- Thursday. work until 3 at getting json results and then trying to save them
-- now returns json but have to put the table drawring code in

-- ok, results now show and are available as json. SO i now can look at storing them
-- add a date_time to the results (maybe start time and end_time?

-- ok, the damn things now save
-- add a message tot he front end to say it has saved
--oh, forgot to add the notes field: what other user input might be needed?

-- notes added, awkward to get the joi to work, not yet returning the _id and printing 'new results added'

-- Friday April 10th
-- spend a good hour at it right now to try and make progress
-- results ARE saving but no way to view them 
-- first test saving again and make sure the messages are ok

-- ok result is back. notes are not being saved...
-- was missing a line in app.js. they are saving now

-- add a new page to look at results... will need a way to search for them?
-- first, list all
-- make a menu for the three pages, make the whole thing like a site

-- why do I have to use results.html but can just do ga and not ga.html?

-- long break. now have a menu bar and a 5 pages. need to add content but go look at the results

-- add a new JS file for this

-- aim 1: display a table with results.

-- need to add a date created to the results (not the ga results inside?)

-- draws simple list of result names.... date_created is not being saved. What columns do I need to include?

-- MOnday 13th. fuck already too alte. ah jeez

-- need to get data: generation and fitness of best race.
-- be able to select a result: return all data
-- then have a dropdown to select a graph to draw 
-- first graph = best race fitness per generation line graph
-- a thi8s stage will need D3.js

-- added button that calls load_results() 
-- need a new fetch and rest endpoint

-- now loading data for results using id
-- can use the same funciton as in the ga page to show the results but also need to load all other details?

-- yay, got first graph to appear, best race time per generation. looks mud but better than 0

-- shit, get a payload too large error if i try to save it for 200 generations

-- tuesday. home of course. get a better grip on d3 and learn how to save them as images

-- seems to bean npm package for saving them

-- https://github.com/exupero/saveSvgAsPng

-- npm install save-svg-as-png

-- ok, had to muck a bit but can now save them. hurrah.

-- now make the file name generation more smart: have the graph name and the results id and the date/time in there?

-- done, graph name, results id, and datetime added.

-- added x.y labels and colour legend

-- need to add another graph... what other figures are interesting?

-- runnign more ga's and they all seem so.. similar. dumb even. What am I trying to show again?

-- bug 1: make all riders normal. best score can get slower by a second after X generations. why?

-- bug 2: wrong settigns id stored. I think this happens if I adjust an existing set and save them as new: it doesn't updated the selected settings id.

-- fixed bug 2, i think. set the settings id after adding new settings.

-- try to hit bug 1 again

-- try running same setup 5 times and compare the final instruction sets

-- thursday, i think, april 30th

-- need to email COlm. What's the least I can do for now to get the ball rolling? 

-- restart the tests for basic conditions, send on screenshots and graphs?

-- also load up overleaf and write up another section of that 'paper'

-- need to work on a video

-- need to add more graphs- UI looks fine

-- monday 4th. of may. fuck. just get the ball at least rolling. make a second graph showing somethign dumb.

-- change the draw_graph function to make it more general, i.e. so that it can qctually draw different graphs rather than copyint/pasting it with tiny changes

-- each graph: title, x_label, y_label, line_label_1, x_data_1, y_data_1, line_label_2, x_data_2, y_data_2... second set of data optional

-- yikes, that sucked, too much work, need to now add a second LINE graph.
-- can use  FALL-THROUGH in the switch case statement 

-- idea: average length of instructions + average instructions to added race per generation  
call this graph Change in Instructions

-- second graph now 'exists' but looks poo

-- need a Clear Canvas button

-- added button. now get graph 2 to work a little better. title of graph 1 not drawn

-- bisschen besser, now add a third line to the second one, for instrucitons removed. will need to make sure that this covers ALL instrucitons and not just effort or drop ones

-- actually, add two more lines: one for the avg. # of effort instructions, one for avg. # instrucitons removed.

-- ok, do another quick graph on the number of variants in each generation

-- one final test before dinner: can I actually add crossover back in? Does it crash it? If not, does it add new variants as time goes by?

-- ok so crossover is NOT being applied in this new_population_tournament_selection() approach. could add it?

-- tuesday 5th.

-- 1: read emails about grc

-- ok so have to upload 1) your short (~10min) video (.mp4) and 2) your presentation slides (.pdf or .pptx). to https://drive.google.com/drive/folders/131jgcF_VbkFCKRNFqCA5OKF291TIAFOi?usp=sharing

-- that's only 3 days including today. need to wrap up as much as possible today

-- My GRC with Sam Redfern, John Newell, and Pilib, is on for May 14th 09:30-10. I need to make contact with all three (CC) beforehand to share contact details. Need to send these the 'annual student report' as well, for/about which I need to email Colm.

-- where are GAs used?

-- optimisation problems
-- e.g. bank loan decisions https://www.sciencedirect.com/science/article/pii/S0957417417301677?casa_token=J_urCRXu6ioAAAAA:t2x-HW2zgq4TzPhbCIJP0C14Sgta5O00TAVnd_EnBjQYce0UAT4sdUcVOkIlSvzsuYlq3oc6

-- or airline crew pairing https://arxiv.org/pdf/2003.03792.pdf

-- or task allocation in multicomputers https://laur.lau.edu.lb:8443/xmlui/handle/10725/7957

-- Solving matrix game with rough payoffs using genetic algorithm   https://www.researchgate.net/profile/Sankar_Roy/publication/282545132_Solving_matrix_game_with_rough_payoffs_using_genetic_algorithm/links/5804b26b08ae293d3680c679/Solving-matrix-game-with-rough-payoffs-using-genetic-algorithm.pdf

-- wednesday may 6th.lotssss to do.

-- find last years slides and make a copy

-- done, needs a lot of labour

-- look at getting crossover to run in the new_population_tournament_selection() option.

-- variant IDs of crossover strats are wayyyy too long: the parent ids are combined... this gradually gets longer and longer

-- need to create variant ids that can be used to trace lineage (if needed) but don't keep elongating

-- gen 1: ids 1, 2, 3,4,etc
-- gen 2: ids 1_2,1_3,3_4, etc
-- gen 3: ids 1_2_1_3, 3_4_7_9, etc

change to
-- gen 1: ids 1, 2, 3,4,etc
-- gen 2: ids 1_2|G2I0,1_3|G2I1,3_4|G2I2, etc
-- gen 3: ids G2I0_G2I1|G3I0, etc... this is as long as the variant ids can get and technically you can trace lineage


-- try OBS software for screen capture... don't want to use screencast-o-matic

--ok, shorter variant ids, BUT undefined_undefined_undefined is appearing at the end. how is this being appended again?

-- seems to work now... but with crossover it does find a good solution, just as fast as the mutation. eeeek.

-- variants count stays HIGH and fluctuates a lot with crossover... need to know HOW much crossover is happening per generation, i.e. a new graph, and check to see if it all makes sense.

-- first, add more feedback in the results page when a results set is loaded: can't tell which one was just loaded. Need to see the name over where the graphs are, or even better as titles under each graph

-- also add a bit more info here, like the number of generations, the population size, and the date it was run 

-- ok, seeeems to look a bit better

-- now hide the results table in an accordian container to provide more space for the graphing

-- better... commit to git.

-- now, add another graph showing the number of crossover vs mutant members of a population 
-- done: might be more interesting to show more about the composition of a generation, i.e. new crossover, new mutants, total crossover, total mutants 

-- also, extend the graph width as text is truncated...

-- do ai need that daft square root populaiton error anymore?

-- add a new global setting: ga_run_robustness_check
-- if this is set to 1, for each generation, take the BEST strategy and run the robustness check some number of times
-- use anothe rglobal variable to control this, ga_run_robustness_check_number_of_mutants:100

-- oops, already have this last setting, called robustness_check_population_size
=
-- note, the ga_tournament_selection_group_size setting was set to 3, which seems too small. Try 7

-- robsutness averagr seems to be too high- always seems to score badly... but... it is an average, so should also track the BEST and WORST to see if better ones are sometimes found

-- after, look at counting the number of direct copies and mutations done at each generation. could express as a % so that the y axis can just be 100.

-- works, though worst robustness is VERY HIGH, can't even see the BEST one thanks to the daft scale

-- right, now shows mutants/crossover/direct being added per generation. Can't tell from which set the better times are coing but that would take effort I think. 

-- ideally would have at least one non-line graph.

-- need slides/script and test of screen capturing

-- Thursday 7th. have to upload slides and video today. big effort needed.

-- first, set up and run a sequence of more consistent tests with
-- all normal
-- 1 strong 
-- 2 strong 
-- 3 strong 
-- all strong

-- keep all other settings the same. #

-- with all strong there is an inconsistent result, when I run the final strat on the visualiser a 2nd rider gets dropped and the time is slower :-( 

-- run it again and see if it finds the same problem: does it happen if I run it from the GA page non-vis?

-- second run doesn't have this problem- final time is a little slower... will need to investigate further but not now, for reference the problem is the final strategy in results 5eb3f07e49a604007c07cc5d | T1_THREE_STRONG

-- now back to the slides/video

-- ok, time to give the video a go 

-- Monday 11th...

-- have to prep for the GRC. Need to email them about how to share.
-- need to write at least some form of paper 
-- need to fix more bugs: issue with inconsistent time (above) and issue with worst case race being massive. is it legit?

-- Thursday 14th.
-- clean up and reorganise the file structure: will need to make sure the research flder is BACKED UP. main code is on GIT but would still be a pain to recover the rest of it.
-- grc. eek. 09:30-10 or so.

--idea: based on the Kevin Norton 2014 paper, have the visual model output each rider's power as a graph, or, even save it then be able to generate the graph after. Compare this with what is being found in that paper. Then, aim to get the settings/model closer to its general findings about the team pursuit and track racing in general.

-- let's make a basic app for saving references? can store notes and findings about papers and get it to generate the refs in different formats. ideally it would be able to store and display the papers themselves so you could 'upload' them into it.

-- datacamp access to do courses via NUIG that might give me credits

-- grc meetign notes. present, me, Sam Redfern, JOhn Newell, Pilib O' Broin.

-- issues to note: I have to get on top of the box-ticking parts of the structured phd program, i.e. accumulate all the module points that are needed.

-- I will have to be able to defend my work in the space of genetic algorithms research. This is most likely the 'home' for my work. IN this regard I need to do a ton of reading and study.

-- I need to finsih paper 1 and find references to add to it. 

-- think about this time next year- what would be the minimum requirements for getting through? minimum is two papers at least plus a bunuch more directions explored.

-- So, will need to start reading much more systematically

-- save power info for each rider in each race: then save this for the fastest race for each ga generation
-- create a graph that can be run for each generation that draws the power outputs for each of the 4 riders.

-- tuesday may 26th.

-- look at outputting and graphing the power of riders...

-- is javaScript pass by value or reference? https://stackoverflow.com/questions/518000/is-javascript-a-pass-by-reference-or-pass-by-value-language

--so, I cannot just set the power values as an attribute of the object (race_r) passed in... I have to return them. Now, I already return the time_taken... this means I needs to change this and return an object containing both time-taken AND rider_power??

"It's always pass by value, but for objects the value of the variable is a reference. Because of this, when you pass an object and change its members, those changes persist outside of the function. This makes it look like pass by reference. But if you actually change the value of the object variable you will see that the change does not persist, proving it's really pass by value."

-- so, return a more complex object like {time_taken: 123, power_output:[[100,200],[200,220]]} 

-- ok, so output now gets returned from the ga for each generation best race, and it gets saved to the db

-- next step is to draw it... can't put it in the main graph dropdown as the data is there for every generation
-- so add a new button/link to each line in the data results? "Power Graph" ?

-- cool, have power graph for all 4 riders... looks wrong tho, why is rider[0] all-powerful?
-- is data[0] storing the power of the rider on the front? must be... 
-- yup, looks dodge, can store power separate for each rider then bung em into the results ofter?
-- wait, can I not jsut use [race_r.current_order[i]] instead of just [i]?

-- Thursday 28th

-- added a new fatigue formula... old one was a bit bonkers
-- do i also need to look at the recovery?? same thing right?

-- changed recovery formula to include a global property like with the fatigue.

-- June 02

-- read, or at least scan, Alex's paper.

--line 61 "to be a 1000;" should "be to be 1000;"?

-- line 87 "The a nodes, a' and b nodes" should be The a, a', and b nodes OR The a nodes, a' nodes, and b nodes?

-- line 180/181: (the largest minimum value of a from a solution 181 was a=12445). The 3 a's make this a bit confusing... could the variable name a be in bold?

-- 199/200 making it so that all cooperators will revert to being defectors. Maybe " which results in all cooperators eventually becoming defectors"?


-- done. basic idea is a particular graph topology that defines a few types of nodes joined by key nodes that ensure that if all nodes start with stragey A, then perturbing one node to stratgey B will eventually return back to all A. These are known as 'resiliant' graphs. Seems well written though not massively readable- but that's academic writing for ya

-- try to get weak rider to be dropped
-- bug on line 275

-- how do i check if an object has a property or exists again?
-- use typeof... if it returns undefined then there's a problem
-- spit out console info if typeof is undefined
-- use JSON.stringify() to log the object

-- doesn't include data for power for last generation... but only for this run... works for other experiments

-- MOnday June 8th. Jeepurs I've done nothing. Need to work on the paper and actually write shit.

-- is there any way I could change how the power is used so that a more accurate start can be modelled. In my version I simply limit the power being output at any timestep, and it can rise or fall at a certain rate, while in reality there is a more instantaneous power. 

-- Also, it seems that general strategies would be to put out a lot of power early on to get-up-to-speed. 

-- Was I not intending to have TWO energy systems, not wholly independent but yet somewhat, basiclaly the sprint and the aerobic?

-- Also need to see if I can access the NUIG intranet to get papers.

-- you will be reduced. you will be... ah hells.

-- monday june 15th.
-- try to get crossover to use some random length between the length of the two parents...

-- ok, so worked on the length of crossover children...this is now done in two steps
-- 1, get random number in range betwen parent sizes (inclusive)
-- 2: adjust this in some cases in range (-3,+3) with decreasing probability of size. 
-- E.g. chance of 0 = 0.5, chance of 1 or -1 = 0.5, chance of 2 or -2 = 0.25, chance of 3 or +3 = 0.125
-- make this 0.5 a global setting that defaults to 0.5?
-- "ga_crossover_length_adjustment_probability":0.5

-- ok, it vurks 

-- shuld it not (probabilistically) mutate also AFTER crossover??

-- add another param and test what happens if crossover is the dominant method?

- tuesday 16th BLOOMSDAY 2020
-- need to start writing on Overleaf- meeting with COlm in one hour

-- add a reference to the witley paper, maybe write it yourself to get to grips with the format?
-- Whitley, D. A genetic algorithm tutorial. Stat Comput 4, 65â€“85 (1994). https://doi.org/10.1007/BF00175354

-- there's a more recent Whitley work too. Whitley, D. (2001). An overview of evolutionary algorithms: practical issues and common pitfalls. Information and software technology, 43(14), 817-831. https://www.sciencedirect.com/science/article/pii/S0950584901001884?casa_token=EZ6sKJq50YcAAAAA:b8yHRoERz6a1bUB57_wSmpPww1RInjlwCwyvktxyqSmj1GFbjHnLCLPEGpgrCMw7XU8konp92Q

-- added paragraphs in a few sections. struggled with Latex. some progress tho

-- wednesdayy 17th. bloomsday uncelebrated. another un gun

-- results from most recent tests are odd. may

-- wednesday 24th. fuck. did nothing. spent ages looking at reinforcement learning but don't understand that either.

-- at least add anew graph of the ordered race result/fitness for each gen.

-- added this graph. looks like in every gen there are a low number of real outliers that take ages... would need to know what is going on with these strategies, can take thousands of seconds to complete the race...

-- dursday 25th june 2020
-- save instructions of WORST race in each generation
-- aved worst and found a fukking BUG! If you set a low power and keep doing drop instructions, the power gets halved each time, so the rider goes slower and slower. When a rider takes over at the front they are supposed to MATCH the speed, not reduce it

-- seems to be HALVING the power when assuming the lead! balls. This will have a huge effect on the race. How to debug? Need to look at what happens when a rider drops back

-- technically when a rider takes over the lead, it is the speed  they want to match and not the power? E.g. that rider might be much heavier and so need to produce more power for the same speed?

-- looks like the issue is in here mapPowerToEffort(settings.threshold_power_effort_level, current_leader_power, new_leader.threshold_power, new_leader.max_power)

-- i improved the mapping of effort to power but did NOT update this reverse function. why does it end up being exactly half though?

3 parts to this: mapPowerToEffort
UNDER threshold
  effort_level = ((rider_power*threshold_effort_level)/rider_threshold)
 AT threshold
 effort_level = threshold_effort_level;
OVER threshold
  effort_level = ((rider_power - rider_threshold )*(9-threshold_effort_level))/(rider_max - rider_threshold) + threshold_effort_level;
  
 I need to compare these with the three ways to do the opposite (middle should be same same)
 mapEffortToPower
UNDER threshold
power_from_effort = rider_threshold*(rider_effort)/10;
AT threshold
  power_from_effort = rider_threshold;
OVER threshold
power_from_effort = rider_threshold + (rider_max - rider_threshold)  * ((rider_effort-threshold_effort_level)/(9-threshold_effort_level));

need to do these up in Excel to ensure they are all allez korrekt
-- friyay 26th

=(IF(C15<$B$5,($B$7*(C15/10)),IF(C15=$B$5,$B$7,($B$7+($B$3-$B$7)*((C15-$B$5)/(9-($B$5)))))))

-- initial findings: formula is 'ok' BUT not linear. need to graph and rebuild... but first determine the source of the BUG
-- must be in the mapPowerToEffort funciton
-- write a test for this in the JS, that copies this Excel data. YOu shoudl get the same values, and then ALSO convert back into effort from power...

-- done,and it looks bad for lower values. check compare these two:
e to p: rider_threshold*(rider_effort)/10
p to e: ((rider_power*threshold_effort_level)/rider_threshold)

-- yup, looks odd. first is linear as though we were using rider effort of 0 to 10. Are we not using 0 to 9? Does this matter?
-- ANd in any case, the second is based on a linear from 0 to the threshold level, i.e. 6. These do NOT match up. Two different forms. Need to graph both then test then choose best then test again.

-- added graph... bug looks pretty obvious now, big kink in slope as effort approached threshold level 6
-- add formula for p to e

=(IF(D4<$B$8,(D4*$B$6/$B$8),IF(D4=$B$8,$B$6,$B$6+((D4-$B$8)*(9-$B$6)/($B$4-$B$8)))))
-- ok can now SEE the error. add a version for the corrected power formula
=(IF(E4<$B$8,(E4*$B$6/$B$8),IF(E4=$B$8,$B$6,$B$6+((E4-$B$8)*(9-$B$6)/($B$4-$B$8)))))

-- yup, this 'fixes' it though the graph is odd. Fix it, check the tests in JS that they match, then run some GAs and look at the worst performers.
-- note, also need fix in the game version

-- IMPROVEMENT; worst race perofrmance is now MUCH better, doesn't get stuck in that slowening grip

-- note, key lines related to the fatigue
  if(race_rider.endurance_fatigue_level >= failure_level){
        race_rider.output_level = (settings.threshold_power_effort_level-settings.recovery_effort_level_reduction);
      }
-- noticing that the worst races simply set a very low effort. makes sense I guess. If riders go too hard they still finish with an ok time, but I can tweak that by increasing recovery_effort_level_reduction?

-- was set to 1. Try setting it to 3 and run the same ga

-- now try a crazy high punishment, like set them to effort of < 1, so recovery_effort_level_reduction = 5.5

-- oops. threshold_power_effort_level is set to 5 not 6. why? How does this affect the graphs?

-- monday june 29 2020. later than ya think

-- so, the power-to-effort and effort-to-power should now by symmetric. what next?

-- do i want a steeper curve mapping effort to power when above  Surely, 5, which has very little change, is ideal?

-- this does mean that instructions are VERY rider-dependent... curve changes... but of course it is rider-dependent.

-- now, the question is... should I not be trying to match the SPEED and not the POWER... but this might not be as hard as I fear?
-- Let's say I know the target speed... how do I work out the power that a different rider needs to put out to match it?

-- it should be an easier calc right?

-- note, this will only have an affect if a rider has a different weight/frontal area?

-- need to translate speed to power to effort level when a rider takes the lead... assume transition from shelter to non-shelter is instantaneous 

key lines from http://bikecalculator.com/

if(!calcMode) {	// we calculate velocity from power when calcMode = 0
			powerv = eval(power.value);
			
			v = newton(A2, headwindv, tres, transv, powerv) * 3.6;      // convert to km/h
			if (v > 0.0) t = 60.0* distancev / v;
				else t = 0.0;  // don't want any div by zero errors
			
			velocity.value = makeDecimal2(v * (units ? 0.6214 : 1.0) );
			
		} else {  // we calculate power from velocity
			v = eval(velocity.value) / 3.6 * (units ? 1.609 : 1.0);  // converted to m/s;
			tv = v + headwindv; 
			var A2Eff = (tv > 0.0) ? A2 : -A2; // wind in face, must reverse effect
			powerv = (v * tres + v * tv * tv * A2Eff) / transv;
			
			if (v > 0.0) t = 16.6667 * distancev / v;  // v is m/s here, t is in minutes
			else t = 0.0;  // don't want any div by zero errors

			power.value = makeDecimal0(powerv);
			dragSlider.setValue(powerv/500.0);
		}
make a new funciton called power_from_velocity()

-- ok, basic draft version created, now need to call this with the right params, and form where exactly?

-- ok, it seems to do something! But it looks like the velocity is ALREADY in m/s

-- note, to convert from km/h to m/s, you DIVIDE BY 3.6, i.e. multiply by (1000m/3600s)

--ok, removed conversion in function and it now seems to return a legit power, though it has many digits
-- do i needs to do rounding?

-- need to go back over how the sheltering is done :-( 

-- initial test fails- speed is LOWER after switch when done step by step... should be identical

-- hmmm, much bugs... the final velocity DOES seem very very close to the initial velocity BUT it is too slow
-- is the initial velocity wrong? Could I use the rider's OWN velocity but make sure that it is losing the aero savings? 

-- why would the velocity of the old leader be too slow? perhaps they have already started slowign down?

-- ok, so it seems that the SHELTER is being taken into account when working out the power needed to match the velocity... so we need to make sure that we use a non-sheltered value here
ace_rider.aero_A2 = Math.round((race_rider.aero_A2 - race_rider.aero_A2*(shelter_effect_strength*level_of_shelter))*10000)/10000;
-- which we are re-calculating at every step
  race_rider.aero_A2 = Math.round((0.5 * settings.frontalArea * race_rider.aero_density)*10000)/10000;
  
  -- hmmm maybe just recalcualte this... plus frontalArea should be a rider setting not a global?
  
  -- ok, this seems to work. but the whole process seems fierce fragile
  
  -- in any cases, copy these changes to the GA race and see if a ga will run.
  
  -- there is defo too much of a DIP in speed during a switch. This may cause GA's to avoid switching? Seems like the whole physics model used is meh. Acceleration not good enough: riders could increase power faster? But power should be a level seperatd from speed? power can increase much quicker than speed? And they have momentum so keeping a speed is easier. That transition to the lead is important. HIgh cost will punich changes.
  
  -- watched women's race from 2012 olympics... they change on every lap. my whole model is a joke.
  
  -- but let's tweak the fatigue/recovery to see if more swithces emerge?
  -- fatigue set with
    let fatigue_rise = race_rider.fatigue_rate*Math.pow(( (race_rider.power_out- race_rider.threshold_power)/(race_rider.max_power-race_rider.threshold_power)),settings_r.fatigue_power_rate);
	
	let's do up an exel sheet to look at different values of fatigue_rate and fatigue_power_rate? oh wait, this is what I had already done :-) 
	
	ok, attempt 1 with linear fatige is v. high- ga finds no improvements.
	
	-- tuesday june 30th LAST LAST LAST fukk
	
	-- ned to do a couple of hours of writing today
	
	-- where was i? Ran some tests varying the fatigue/recovery, now need to get past that
	
	-- fukk. test 5efa00620fe486250c87d434  gen 28, ga says time 252 but if I play race I get 277 :-( :-( these fukking errors will never go away.
	
	fatigue 10 recovery 20 for all riders
	
	start order: [1,2,0,3]
	[[19,"effort=6.72"],[39,"drop=2"],[61,"drop=2"],[96,"drop=1"],[143,"effort=7.75"],[148,"drop=2"],[172,"drop=3"],[187,"effort=8.05"],[206,"effort=2.4699999999999998"],[209,"effort=9.57"],[227,"effort=6.2"],[232,"effort=8.17"]]
	
	ok, phew, figured this out! the play race pulls the settings from the db and since doing it I changed those fatigue/recovery, so it is no longer identical... meaning things are not as 'repeatable' as I thought?
	
	-- no, it does look like i am saving the settings with each result, but I must be loading them wrong? I need to send the id of the results, not the settings, when trying to run a game FROM THE RESULTS BUT NOT FROM THE GA: so there are TWO ways not one. SO I need to send extra information to say RUNNING FROM RESULTS PAGE 
	--easy to code so do it.
	-- in results JS added source=results to args sent. also changed id from settings_it to results_id
	-- add source=ga to ga JS
	-- done, now add a big IF in the part in game where settings be loaded
	
	-- ok, not tooo bad, seems to work ok, same times when running from ga or results page
	
	-- now need to find settings that somewhat mimic the fast switching of a real race--- lots of fatigue?
	-- maybe there are not enough instructions involved? 
	
	-- try tweaking
	"ga_probability_of_instruction_per_timestep_lower":0.01,
	"ga_probability_of_instruction_per_timestep_upper":0.03,
		"ga_probability_of_drop_instruction":0.5,
		"ga_p_crossover":0.2,
		"ga_p_shuffle_start":0.001,
		"ga_p_add_instruction":0.006,
	"ga_p_delete_instruction":0.16,
	"ga_p_change_effort":0.012,
	"ga_p_change_drop":0.012,
	"ga_p_move_instruction":0.012,
	"ga_range_to_move_instruction":10,
	"ga_range_to_change_effort":2,
	to
	"ga_probability_of_instruction_per_timestep_lower":0.02,
	"ga_probability_of_instruction_per_timestep_upper":0.04,
		"ga_probability_of_drop_instruction":0.6,
		"ga_p_crossover":0.3,
	"ga_p_shuffle_start":0.002,
	"ga_p_add_instruction":0.009,
	"ga_p_delete_instruction":0.2,
	"ga_p_change_effort":0.015,
	"ga_p_change_drop":0.015,
	"ga_p_move_instruction":0.015,
	"ga_range_to_move_instruction":12,
	"ga_range_to_change_effort":2.5,
	
-- damm, crashing when i try to run 100 gens, seems to run some number of gens then go awol
-- looks like an infiloop? fan starts up, stuck on gen 21/100, jumped to code but inside a seemingly innocuous FOR loop

-- ok, retest this

-- change sort of results so that the NEWEST appears at the top
-- is this causing trouble?
start order  [2, 0, 1, 3]
instructions [[59,"effort=6.31"],[127,"drop=2"],[129,"effort=9.21"],[180,"drop=1"],[219,"drop=1"],[223,"effort=9.33"],[233,"effort=5.18"]]
yup,  race_r.race_clock is a BIG number 33426317 so it looks like the race is NOT being finished at all

-- YIKES. riders are ending up BEHIND the second last finisher... what the heck is that ARE WE FINSIHED code doing?

added some lines and now 100 gens run BUT do I need to dig further into WHY a race was able to go infiloop?
-- no infiloop if i try to run this race above.. odd. guess I shoudl still add the new code to the game JS. maybe add an extra few lines to at least LOG info IF it looks like a race could go infiloop?

here's one 
###### warning: min_distance_travelled 6004.9977584177295 ######
race_function_no_vis.js:1460 Start order [2,1,0,3]
race_function_no_vis.js:1461 Instructions [[14,"effort=6.25"],[15,"drop=2"],[43,"drop=2"],[91,"effort=6.66"],[111,"drop=2"],[117,"drop=2"],[152,"drop=1"],[154,"drop=2"],[181,"drop=2"],[213,"drop=2"],[224,"drop=2"],[228,"effort=9.84"],[235,"effort=5.11"],[244,"drop=1"]]

-- ok, so this race does finish ok BUT there is defo a bug: drop instrucitons are being ignored.

-- ok ok... looks like the instructions are ignored because the rider never hits that gap that I've defined as the drop-zone. I've said: switch if distance into lap is between points A and B, but at a certain speed it might never be between them. Need to fix this formula...

if Distance_covered > A and Distance_covered < B
OR Distance_covered > B and (Distance_covered - distance_covered_last_move) < A
would this not catch where the distance moved skips over the A-B gap?

the damn IF statement now loks hideous:
  if ((lead_rider_distance_on_lap > race.bend1_switch_start_distance && lead_rider_distance_on_lap < race.bend1_switch_end_distance) || (lead_rider_distance_on_lap > race.bend1_switch_end_distance && (lead_rider_distance_on_lap-distance_travelled_last_step)<=race.bend1_switch_start_distance) || (lead_rider_distance_on_lap > race.bend2_switch_start_distance && lead_rider_distance_on_lap < race.bend2_switch_end_distance) || (lead_rider_distance_on_lap > race.bend2_switch_end_distance && (lead_rider_distance_on_lap-distance_travelled_last_step)<=race.bend2_switch_start_distance) )
  
-- ok, seeeems to work. But the changes are taking too long. real race has them done on the bed. bend. but yes, bed needed.

-- first copy to GA code then commit.

wednesday JUly 1

-- rerun basic tests and write something up, also need to go back over reinforcement learning

-- physics limitation examples: switches take too long and cost too much effort- irl they are very smooth and can be timed very exactly on each lap. Teams tend to change a LOT. Power is miles off at the beginning as this is where a BIG effort to get up to speed is needed.


tuesday August 18 

long tangent into RL plus lots of nothingtime. nothign gets done. duel, deul

-- wrote a bit more and added a diagram graph

-- need to finsih writing a draft

-- need to add more references

-- how to draw the fatigue thingy as a formula for latex?

-- Fr * (output-threshold/max-threshold)^fatigueExp
-- Fr * ((Po-Pt)/(Pm-Pt)^Fe)

-- why isn't the effort to power mapping not just always linear? I get it has to pass through the threshold at a given Et = Pt but is there not a better way whereby a line is drawn from 0 - Pm through Pt at x=Et? 

-- no i don't think it's possible as there are three points, two of which vary: 0, Pt, and Pm. can have, as designed straights from 0 to Pt and from Pt to Pm. Might not be perfect but ok for now

-- add an image of the race in action.

-- add formulas for recovery and accumulated fatigue 

- huh, I don't have an excel graph for recover. I should express it as a formula at least

recovery   race_rider.endurance_fatigue_level -= race_rider.recovery_rate* Math.pow(( (race_rider.threshold_power- race_rider.power_out)/race_rider.threshold_power),recovery_power_rate);

-- Rr*((Pt-Pc)/Pt)^Re
  
  fatigue_failure_level = Ff*((Fm - Fa)/Fm);
  
-- problem. same race is getting different times- like, off by 1 issues. 258 and 259. why would it sometimes take an extra timestep? something not being reset? but such a small difference.

-- tuesday 25th august 

-- try to fix problem where we have different finsi8h times -offbyone- for game and ga races.

example: all strong riders, start order: 2,0,3,1 Intructions: [[50,"effort=6.3"],[77,"drop=1"],[79,"drop=1"],[116,"drop=2"],[142,"effort=6.36"],[146,"drop=2"],[152,"drop=1"],[180,"drop=3"],[182,"effort=6.95"],[188,"drop=2"],[194,"drop=3"],[209,"drop=3"],[235,"drop=2"],[242,"effort=9.72"],[252,"drop=1"]]

ga gives 259, sim 258. why? do i always return +1?

-- ok, so there is a discrepancy whereby the race clock gets ++ before the result is returned even on the timespte in which the race finishes. So for the GA version I need to only ++ the race clock if the race is not finished. The sim version doesn't return a value so is ok.

-- kewl.. buttt this doesn't really solve the initial issue where the ga returned 2 different results for the same start order and instructions. 

-- run the same ga test again and see if it happens again

-- chest rub from vinny, 2 * olive oil from evergreen moycullen. ouro de portugal brand

-- found one example of disimprovement in 4 tests: result from 1st generation is 263 but when i actually run it I gets 271 (same in sim and ga). why would this happen? next gen result seems fine. smells like another bug.

-- almost seems like it's possible that the wrong race time is used? or there's a mixup setting the best race from gen 0?

-- if i could generate the power graph from the sim i could compare it to the one in the results- maybe the race is actually not finished but for some reason is being cut short?

what data do i need to collect to draw this graph?
best_race_rider_power

-- christ that took too long. i give up. it draws now, and it is different- the power graphs do not sync up BUT they do seem to begin the same: could be something to do with fatigue?

-- found another example where the ga race differs and gets 260 instead of 261. if i rerun it i get 261. the power diagram has defo a tiny difference so something has happened. how the fukk do i find out what's going wrong? thousands of races are running.

-- can I run the same race 10000 times and try to detect it? does it happen for all instructions eventually? is something not being reset?

-- idea: have another test like the Robustness one, but just run the same race over and over, and return a set of unique finish times and the number of times they occured: a counter thingy.

-- robustness check is NOT working, doesn't seem to load the riders

-- finally got robustness to work again, and consistency check now there as well, but it seems to get the same result every time. now running it 50k times to see.

-- all 50k finish with 261. so how are races differing? something not reset when running the ga?

let one_fifth = Math.floor(settings_r.robustness_check_population_size/5);
  let one_fifth_count = 0;
  
    if (i % one_fifth == 0){
      console.log(one_fifth_count*25 + "% done");
      one_fifth_count++;
    }
	
	-- generalize timer outputs to use in ga
	
	let segment_size = 10;
	let one_segment = Math.floor(TOTAL/segment_size);
	let one_segment_count = 0;
  
    if (i % one_segment == 0){
      console.log(one_segment_count*(100/segment_size) + "% done");
      one_segment_count++;
    }
-- what if the  issue is a really marginal one, like, the rounding of (x > race distance)?
-- current example; looks like it just adds an extra timestep/cuts one off

-- hmmmm... race step 260 finishes with 2nd last rider at 3999.83540739257. so, a TINY discrepancy would throw it off. I would need to log the completed race distance of the 2nd last rider at the 2nd last timestep to check this? does look sus.

-- noticable diff between SIM and GA- chasing rider power oscillating more in GA.

-- can't always be happening- what setting has a sporadic effect? effort/power conversion. fatigue. recovery. power oscillates, for chasing riders. no rider is dropped.

-- now the conssitency check for
start: 0,2,1,3
insructions: [[39,"effort=6.7"],[58,"drop=2"],[68,"drop=2"],[106,"drop=3"],[138,"drop=2"],[176,"effort=9.49"],[177,"drop=2"],[192,"drop=1"],[201,"drop=1"],[214,"drop=3"],[229,"drop=3"],[236,"effort=9.56"],[240,"effort=8.530000000000001"],[244,"effort=9.74"],[254,"drop=1"]]

goes 257,288,257,288 over and over again. does it do this for all races now?

-- looks like it :-( not resetting somefink?

-- yikes, problem seems in a lot of places. defo a big bug. need to fix. possible I'm not resetting fatigue/etc of riders? how would that make them quicker tho? the race before it affects it, somehow... how? i've made it way too complex- too much resetting/etc going on

-- output level is being marginally changed... not 6 but 6.000000002368021. a rounding issue? i did add a bit for this lately. if I reset it will this help?

-- add start_output_level in riders. set to 6. reset to this for each race.

-- defo a difference between ga and sim. somethign in how power of chasers is worked out. must have forgotten to copy somthing?

-- fukk. identical log files for a race from both GA and SIM. time to give up for today. mutherfukker.

august 27th
-- right, back at it. different finish time sometimes and the power of chasers differs but i don't know why. it happens in the ga but not when using the ga race code seperate from the ga itself.

-- built a thing that generates an id of each race and checks for dupes 

-- getting some of these issues where the race goes way over 4000m
###### warning: min_distance_travelled 6006.749165424945 ######
race_function_no_vis.js:1586 Start order [2,3,1,0]
race_function_no_vis.js:1587 Instructions [[60,"effort=6.57"],[90,"drop=1"],[91,"effort=4.77"],[116,"drop=3"],[121,"effort=8.23"],[143,"drop=3"],[173,"effort=8.629999999999999"],[179,"effort=5.4"],[209,"effort=8.969999999999999"],[213,"drop=1"],[226,"drop=2"],[243,"drop=1"],[254,"drop=2"]]

race_function_no_vis.js:1585 ###### warning: min_distance_travelled 6008.609434184566 ######
race_function_no_vis.js:1586 Start order [1,3,0,2]
race_function_no_vis.js:1587 Instructions [[3,"drop=3"],[14,"drop=3"],[100,"drop=2"],[161,"drop=1"],[186,"effort=8.809999999999999"],[217,"drop=2"],[251,"drop=1"],[257,"effort=4.93"]]

-- much weird, can't seem to trigger the error now that I'm tracking the finish times of races. all i'm doing is searchign for cases where the same race runs with different outcomes

multiple tests run now with no error, even with a population of 4000

could i have fixed it with the few setting resets I added yesterday?

-- after  more attempts and still no probs- maybe worth trying to reverse yesterday's changes in the reset area and see if they then ocur? right now i have no proof of any fix

-- woah

-- commented out load_rider.distance_from_rider_in_front=0; 
-- suddennly there are tons of races getting different times. this must be it. Most of the changes are worse; in the test I ran no best race got worse so results looked normal, but in the background lots of races were getting different finish times. sons of beaches.

-- uncomment and try comment out load_rider.output_level=load_rider.start_output_level; instead

-- ok, good, the issue is not there. sooooo, it seems that for chasing riders the distance to the rider in front was not starting at 0, and this immediately affects them- i imagine in some cases they would have been way behind, depending on what happened in the previous race. i could actually test this int he sim by manually setting values?

-- should this distance actually be initialised to 0 if they are supposed to start in a line?

-- still getting some of these
###### warning: min_distance_travelled 6012.629823245844 ######
race_function_no_vis.js:1594 Start order [3,2,1,0]
race_function_no_vis.js:1595 Instructions [[28,"effort=7.79"],[47,"drop=2"],[87,"drop=3"],[93,"drop=3"],[119,"effort=6.22"],[133,"drop=2"],[158,"drop=1"],[189,"drop=1"],[191,"drop=2"],[206,"effort=8.71"],[217,"drop=2"],[234,"drop=2"]]

-- huh. still a difference in the graphs for rider power- chasers oscillate in ga but not sim. how can i compare them? just scroll them both side by side ya dummie

-- can't see any diff from eyeballing

-- guess i should also be able to graph the power from the GA one-off runs to see if the issue could be another specific to the ga over generations

-- ah fuck. graph for gen 48 is way off- ga has best race at 255 but it's 264 when you run it separate- 
-- turns out that this race seems to go way over 4000m. need to debug again. FFS!

-- friday 28th. 

-- first, bug in sim, can keep steppign on with the >> button after race has finished: it doesn't look at the continue_racing bool?

-- done. add a message saying RACE FINISHED when it does finish in the status bar

-- ok, so bug looks to be this. 2nd last rider gets DROP-3 just before it crosses line. race does not finish until it is in 3rd place even if by then all 3 key riders are well over the 4k. so need to only keep racing if a rider that should be ahead is behind and has not reached the distance: we are waiting for it; it is chasing.

-- ok, so now much improved but still offByOne: 256 in SIM, 255 in GA.

-- need to understand why GA ends at 255? seems to be 256 when run alone?

-- can't figure out why it would end at 255 when the standalone doesn't

-- added same bit as in SIM
&& race_r.riders_r[race_r.current_order[x]].distance_covered <= race_r.distance

-- huh, uncovered something here

  let min_distance_travelled = race_r.riders_r[0].distance_covered;
    for (let xi = 1; xi<race_r.riders_r.length;xi++){
      if(race_r.riders_r[xi] < min_distance_travelled){
        min_distance_travelled = race_r.riders_r[xi];
      }
    }
	
	how am I comparing an object race_r.riders_r[xi] with a scalar min_distance_travelled?
	what happens if i set min_distance_travelled = race_r.riders_r[xi] and then run
	  if (min_distance_travelled > (race_r.distance + over_travelled_maximum)){  ????
	  or is min distance travelled always just set to the first rider?
	  
	  changed it to 
	  
	  let min_distance_travelled = race_r.riders_r[0].distance_covered;
    for (let xi = 1; xi<race_r.riders_r.length;xi++){
      if(race_r.riders_r[xi].distance_covered < min_distance_travelled){
        min_distance_travelled = race_r.riders_r[xi].distance_covered;
      }
    }
	
	-- but I'm not sure this will fix anything.
	
	-- in any case let's try run another 50 gens and see what we gets
	
	-- so bit better but still offByONe
	
	-- need to understand why the SIM and GA graphs differ- this might help
	
	-- the ga gives us 255(3987.5515070262,4003.54455893307) for finish time (2nd last timestep distance, last timestep distance)
	
	-- first, get the GA standalone to draw the power graph as well
	
	-- ok, done. aaaaand, same graph as SIM. 
	
	-- sssss0000000ooooo, the GA when running as ga (many gens) has differing results, soooo something small differs, and again we are back looking at chasing riders and why the power oscillates. could it be the shelter calculation?
	
	-- let's rteturn to the idea yday to look for any differences from race to race in the three settings objects: global/race/riders. Surely something is off?
	
	-- ok, have new machanism trying to compare settings before once off with GA. fukking bug where GA doesn't output results for last gen now causing trouble. FFS! 
	
	-- last gen data not saved cos for last gen you do NOT create a new generation at all... 
	
	-- attempt to get a blow by blow log of the best race in the final gen failed... too memory-hungry
	
	-- nope, can't run that- must not be resetting the message
	
	-- need to use a regex replace in notepad++ to add line breaks
	-- regex: (\|\|\|\|\s\s\d\s\|\sSTRONG\s\d\sLEAD)
	-- replace with: \n\1
	-- note the \1 puts in the match inside the (). It finds e.g. ||||  1 | STRONG 3 LEAD
	
	-- saved event sfile but run-single race no longer works
	
-- monday 31st, try to investigate log files

-- gen 99 chasing riders have different gap/speed tho lead is the same
-- gen 1 all identical
-- gen 25 nOT identical, last rider is going a little faster in the SIM: power is 474.33, 474.32 in ga
-- step 22 is the first diff I can find- last rider ends up with a gap of 2.13 NOT the target 2. warum?
-- is everything identical in step 21? YUP
-- in 21, the last rider in both cases has power 474.3. But speed in GA is 60.06 kph while in SIM is 60.54 kph
-- soooooo we are workign out the same power BUT when converting this to speed there's an issue
-- newton lookup stuff? can i turn this off?
-- put in a bool to switch off the lookups. not much else happening when you have power and need velocity. why only wrong for the last rider tho?

-- woah

-- that

-- worked

-- fukk should have tried that before. 

-- for chasers i work out the velocity first by looking at the rider in front, and trying to get to -2m of it
-- then i work out the power needed for this velocity with 
  let target_power = (target_velocity * race_rider.aero_tres + target_velocity * tv * tv * A2Eff) / settings_r.transv;
 -- but this power might nor be possible, so adjustments may be made
 -- after adjustments, the newton() is called: if the target power was possible in the first place this should return the same value again.
 
 -- why does it not affect the other riders? always seemed to be the chasers oscillating after going 'off'
 -- could build a testing mech that would add to the table and report back if it found anything odd
 -- remember this doesn't happen with the SIM, so some other race is putting an entry into the table that is being used and is different
 
 -- tuesday sep 1
 
 -- run more sims- make one really weak rider and see if it gets dropped. surely?
 
 -- make 2 riders weak and then 3 and then all. everything else equal. save graphs of fastest race gen 50.
 
 
 -- hmmm, maybe i need a separate type of drop instruction that tells a rider to just drop away totally- rather than continuing to try and chase. issue is that if a ridr is dropped and the leader gets a 'drop to back' command it tots screws up the race. but i guess it should evolve to a drop to back-1. But this is brittle- it would be daft to hear a drop back instruciton and go all the way back behind a dropped rider. 

-- tuesday sep 8th

-- 8 days since i updated the paper. ook. 

-- find out how weak the weak rider needs to be to have it dropped. ask yourself why dropping a rider is not happening more often. if i rejigged the drop instructions it might help: 

0 = drop to back
1 = drop to 2nd last
etc 

and then, IGNORE any rider that has been dropped by more than some fixed distance.

-- hmmm, maybe I could just add somethign simpler to ignore a dropped rider? the issue is not that riders can't be dropped but that if a rider does get dropped, any drop-3 instructions later in the race will screw it up. it would take too many mutations to find all drop=3 and change them to drop=2. But if it is simpler like GO TO BACK OF GROUP and the group can be any size and a rider may be dropped from the group.

-- yup, needs something like this.

-- how about. Drop back X spaces OR until the back of the group. This means I can just take the drop=3 and check what the actual group size is, and if it is less than 3, change the drop instruction?

-- I could even make this optional, add a switch setting, and test both: can put in a paragraph. 

-- "limit_drop_to_contiguous_group":1 

-- let's default it to 0. where in the code does the actual order get changed?
-- switchLead() function. but need to track the contiguous_group_size. This would be a property of the race? This would need to be checked for every chaser? here's how: each timestep, you reset race.contiguous_group_size to 1, and for each chaser you add 1 IF they are less than a set settings_r.contiguous_group_drop_distance OR if contiguous_group_size is less than their place in the order: this would indicate that a rider further ahead of them has been dropped.

This means that the lead rider might break away, drop the rest, and drop instructions will do nothing? I guess so, but in this case an effort instruction might work.

-- "contiguous_group_drop_distance":10
--race_r.contiguous_group_size

-- counting group not working
--  TypeError: Cannot read property 'requestContent' of undefined

-- it seems to 'work' in that stuff gets logged and the races run... but how do I know it really works?

-- Wednesday.

-- le's rerun the four tests one more time.
-- hmmm, have an issue where sim differs from ga... did i forget to put some part of the new code in the sim?

-- ah fuck, another difference- race where the GA gets 256 but sim and singleshot ga get 305
1,0,2,3
[[18,"effort=6.49"],[44,"drop=2"],[54,"drop=2"],[61,"drop=1"],[70,"drop=3"],[89,"drop=3"],[113,"drop=2"],[133,"drop=1"],[172,"effort=9.28"],[174,"drop=2"],[191,"drop=2"],[207,"drop=2"],[227,"drop=2"],[236,"drop=2"]]

-- thursday, 10th
-- COlm emailed. need to figure out the latest errory stuff.
-- issue is with the TWO-WEAK one. run it again a few times and see does it happen again
-- why does the power drop so- is it fatigue?
-- hmmmm, i wonder is it possibel that the GA ran with 3 actual strong riders, not 2, i.e. that rider 3 had 550/1200 and not 400/1000 as I expected? could test this by manually updating the mongodb
-- hmmm, tried this but still fails... but, looks like in the ga rider 4 gets dropped early, so maybe the settigns actually used were from the one-very-weak, which is actually the one I would have tested previous. 
-- very weak is 250/800 

-- Awesome, found it- the GA was supposedly using TWO_WEAK but was actually running with the previously loaded settings, which was with one-very-weak. If I run the problematic result with one-ver-weak I get identical 256 finish time and graph. the weak rider gets dropped early and is ignored from then on.

-- note, issue is with 5f58c9b8690f2a05f418dfe8 results- do not use this.

--actually, need to be able to delete resultsets and clean out the old ones, plus edit the notes of existing ones.

-- could potentially add more sophistication for dropped riders, i.e. that they realise they have been dropped, and ride at a steady pace home rather than trying to chase and then fatiguing. 

-- l ooks to me like the rider at the back is saving too much (too much shelter)

-- i could also work out the time as a float, i.e. make it more accurate: what time EXACTLY did the 2nd last rider cross the line?

-- tuesday 15th sep 202020202020
-- an i get it to give me the finish time to say, a tenth or a hundredth of a second?
-- get timestep where 2nd-to-last rider crosses finish distance
-- get velocity of s2l rider
-- this v = distance in 1 second. get td, the total distance, which will be race distance rd + X. get X. 
-- if we did v in 1 second, how long did X take? (X < v). X/v? woudl this not give me the correct part of the second?
-- try it in a google doc.

-- jeepers, this is what happens when you try to round() in JavaSCript: https://stackoverflow.com/questions/11832914/round-to-at-most-2-decimal-places-only-if-necessary/55521592#55521592
--waoh, 1.005 = .005 = 0.9999999999 (try it in the console). i so dumb.
-- more rabbit home stuff https://softwareengineering.stackexchange.com/questions/101163/what-causes-floating-point-rounding-errors
-- hmmm, maybe just use the DecimalPrecision function from that SO page linked above?

-- if this works ok should I not replace ALL round() refs to this?

-- oh, it's an Object, not a function. DecimalPrecision.round(x,3)
-- fukker won't run, 

-- took different version from the same SO page, DecimalPrecision4 by AMr Ali. seems to work.

-- right, so will this work in the GA?

-- wednesday sep 16
-- running more GAs again. new timing seems to work. need to test tho. 
-- do i need to replace all the graphs again? fook
-- 

-- friday 18th. sep tenny twenny.

-- finish running updates time tests, maybe update images in overleaf?

-- start running robustness testing.

-- work out perdentage improvements for different scenarios.

-- try to add a paragraph of new text

-- google scholar ga's again

-- ah fuck, a bug in the new timing. Race finished: 260.854 seconds, (4016.725228663958m after 262 seconds). how is this possible? it can't go back below 261 seconds, surely. 

-- ah balls.. it's possible for the lead rider to be dropped before the race fnishes and have the 2nd last rider go past the finish but not actually finish cos... well cos it thinks it is ahead of the lead rider, which it is. but it it still 2nd last. but, this shoudl not happen if the 2nd last rider is set purely on the distance travelled, not on the team order?

-- try changing so that after a race timestep i order the riders based on distance travelled?

-- added code to sort the riders based on distance... created a separate new array of objects to do this. seems to work, need to copy into GA 

- monday 21st 9 20

-- copy changes made on Friday from game into ga

-- then, commit the code to git

-- ok, one bug but now distance-based 2nd-last-rider selection seems to work.
-- committed and pushed to github

-- very slight difference in finish time between ga and sim... 263.796 in sim, 263.744 in ga. I get 263.744 when I run ga once-off so have I a bug in the sim this time?

-- defo somethign going on here, ga goes to 4034.76m before finishing... then uses a slighlty different velocity to work out the actual time it crossed the line, which takes off over 2 seconds... yikes. but at least it can be debugged without running the whole GA.

-- wait, i had to make another change about how to itrate through the riders ahead. fart. need to copy this across. 

-- yup. now getting 263.796 for both. but this fecks up those resent runs, so run them again.

-- tuesday 22nd sep

-- run all-weak again and then create a new one-strong. need to look at slowly increasing the stength of one rider and watching what emerges. 

-- 1: all weak
-- 2: one stronger, 410/1020
-- 3: one stronger, 420/1040
-- 4: one stronger, 430/1060
-- 5: one stronger, 440/1080
-- 6: one stronger, 450/1100
-- 7: one stronger, 460/1120
-- 8: one stronger, 470/1140
-- 9: one stronger, 480/1160
-- 10: one stronger, 490/1180
-- 11: one stronger, 500/1200

-- 12: one stronger, 520/1240
-- 13: one stronger, 540/1280
-- 14: one stronger, 560/1320
-- 15: one stronger, 580/1360
-- 16: one stronger, 600/1400

700/1700

massively stronger
-- 17: one stronger, 800/2000

900/2300

1000/3000

-- taking a long time to run. I was supposed to automate this. didn't. maybe run less than 50 gens or with a smaller pop?

-- thursday 24th. ah jeez. where does... nvrmnd
-- run the rest of the test above. look through the results. 

-- ok so have a bunch run and there are results. how do i represent them? maybe write a paragraph?

-- "Unlike the traditional statistical and mathematical programming techniques such as discriminant analysis, linear and logistic regression, linear and quadratic programming, or decision trees; intelligent systems have proven their ability to overcome different challenges in financial research areas, specially in banking loan portfolio optimization" oh dear

-- possible graph = % of time at front of stronger rider (best race after 50 gens) as power increases

-- could output this in the game version then copy into notepad, mebbie use python to graph? would need threshold power as X and % of time at front as y. 

-- add a time_on_front property to riders. need to incremenet this at each timestep. might be an issue on the last timestep? need to use the physical ordering and not the logical ordering

-- ok. so have the graph, mapplt, need to add a couple more data points but it will help this paragraph.

-- friyay Sep25th. fukk where doth time go?

-- need to prep for possible meeting. read what I added yesterday. Look at adding back the robustness check. Does robustness improve from generation to generation? does it differ from scenario to scenario? It's like a form of noise no?

-- The riskiness of a strategy in this context may be related to the brittleness of performance when instructions fail or are tweaked. Here, two different concepts of robustness to noise are considered. In the first case, a set of instructions is compared to a large number of copies of itself, all of which undergo the same mutation process used by the GA. Instructions may be added, altered in time or intensity, or be deleleted. The performance of these mutants can then be compared to that of the original.

The second approach modifies the race model itself, introducing an element of noise into the application of instructions. This noise is designed as a simplified model of failure under pressure: when a rider is highly fatigued or performing at high intensity, there is a higher risk of mishearing an instruction or failing to carry it out. This is therefore not random noise but designed noise/failure. It is interesting to consider what strategies the GA will favour in this case, though it makes the process more complex as there is a degree of randomness introcued to the performance itself, thus making it difficult to re-enact. 

-- so, let's bound the work with those three aspects:
- noise v1: robsutness, noise v2: performance failure, and 3... comparing solutions and finding was to describe them? Like, working out how different one strategy is from another? or is the noise enough?

-- mondee 28th. get somethign done today so you can chilla bit during the week and get back in next week as disc starts again

-- robustness. run the test for every gen. what needs to be saved? avg. finish time. best. worst. std dev.
-- get the robustnesss check to run again. add 
generation_results.robustness_check_standard_dev,  similar to average_mutant_time_taken

-- run this for an all-weak set of riders. build some kind of graph

-- right, seeeeems to work- add the std. dev. to the graph i rleady had for robsutness

-- oct 12.

-- maybe 13th?

-- oct 14 wednesday
-- need to get back to work on this :-( 
-- add a mechanism for applying failure under pressure, plus a means to record everything so that it can be re-enacted in the game.

-- where exactly does the failure happen? when given an instruction?
-- let's say
-- whaen a rider gets an instruciton there is some probabilty of it either mishearing it, delaying its application, or being unable to carry it out.
-- 1: rider may delay carrying out the instruciton by some amount of time.
-- 2: rider may attempt to carry out a stronger or weaker version of the instruction (random)
-- 3: rider may carry out a weaker version of a power instruction (due to fatigue/effort)

-- could aim for 2 and 3 as time steps are a bit large for mucking with.
-- when an instruction is issued there is some prob. that it will be changed (noise)
-- when a rider gets the instruction there is a stress-affected probability that it will fail to carry out the effort required.

-- thursday 15th
-- add new properties to control new stochastic behaviour
-- global switch? "enable_instruction_noise_1_random": 1
-- "enable_instruction_noise_2_failure": 1
-- "noise_1_probability_instruction_misheard":0.01 runs for every instruction, so 1 in 100 here will be out
-- if this passes the instruction must be tweaked but by how much?
-- try it with pure random changes within a range- e.g. change a drop instruction to be a drop-X where X >= 1 and X < Team Size
-- for effort, try a totally random value from a range. Rider can fail by a little but mishear by a lot, i.e. mishearing is actually random, while failure is not.
-- pick random value between 2 and 9 for effort. though it seems more logical that instruciton noise would be more likely to be close to the target as that


-- 27th OCT. fugg.
-- should each rider have its own propensity to failing under pressure?
-- easy to put a setting in the rider info so sure
-- "noise_2_propensity_to_fail_under_pressure":0.01 -- put this in the rider properties

-- wednesdat 28th
-- added 2 global properties
"enable_instruction_noise_1_random":1,
"noise_1_probability_instruction_misheard":0.01

-- need another property to control whether an instruciton is delayed 

"noise_1_probability_instruction_delayed": 0.2 (0 to 1). if it is being alered, an instruciton is either delayed or has its value changed

-- also need to know by how many timesteps the delay might be.
"noise_1_probability_instruction_delay_range":3

-- put in lots of code, it's more complex than it looks
-- need glovbals as well for the range to move effort and possibly drop_positions
-- "noise_1_probability_instruction_effort_range":2
-- "noise_1_probability_instruction_drop_range":2
-- can i simplify Math.random() * (( effort_value + noise_1_probability_instruction_effort_range) - ( effort_value - noise_1_probability_instruction_effort_range)) + ( effort_value - noise_1_probability_instruction_effort_range)

R*(( x + y) - ( x - y)) + ( x - y)
R*(( 5 + 3) - ( 5 - 3)) + ( 5 - 3)

-- naw, don't try to simp it, should work as is

-- ah shit, changed already to 
let effort_adjustment = Math.random() * (noise_1_probability_instruction_effort_range*2) + (0- noise_1_probability_instruction_effort_range); 

-- now need to know what the max effort value can be. 9? I remember it not being 10.
-- should really replace that 9 with a constant

-- hmmm, can't just add a random int to the drop instruciton as drop=3 will become drop = 3 as it is the max, and also the most common. we want it to randomly select a different valuye. so really should use the teamsixe, which can be found... where?

-- ok, added ton of code, awful complex really. feck. assume it will break but enough done for now.

-- thursday oct 29
-- code from yesterday actually runs. bugs will be there but at least it rolls. need to work on the mechanism to store the adjustments so that they can be re-enacted by the game

-- each race will need to store its own instruction_noise_alterations. this will need to be returned and stored (for the winning races in any gen)

-- note: thigns might go awry if there are two instructions for one timestep, but this er, shouldn't happen?

  race_r.instruction_noise_alterations[race_r.race_clock] = noise_alteration;
  
 -- need two additions to generation_results
 generation_results.best_race_instruction_noise_alterations
 and
 generation_results.worst_race_instruction_noise_alterations
 
 -- try to display the noise alterations in the GA table of results
 
 -- likely that there will be NO noise in the best race
 -- but there may be dis-improvement- the best race may underperform so the fitness may get worse, unlike the no-noise scenario where it is fully deterministic
 
 -- will surely need to add some more metrics on the noise?
 
 
 -- first get the GA to store, and the Results to display, any noise in the worst and best races. We need an example with noise to apply in the game view.
 
 -- note, the game view will now have to either apply noise or replay existing noise. it would be dump to do both.
 
 -- why is worst time undefined/undefined in Results? fix this first
 --ga_results.generations[g].worst_race_time and ga_results.generations[g].final_worst_race_start_order are UNDEFINED
 
 -- ok, so the worst race properties are worked out, but are they saved in the db?
 
 -- huh, in the db we appear to have the time and the alterations but missing the original instructions and start order
 "worst_race_time":525.888,"worst_race_instruction_noise_alterations":{"331":{"original_instruction":[331,"drop=2"],"altered_instruction":[331,"drop=1"]}}
 
 -- cool, so somethign worked. need to add the type to the drop and effort noises
 
 -- oh, the worst race data IS in the db. just not being displayed?
 
 ga_results.generations[g].final_worst_race_properties_index / ga_results.generations[g].worst_race_id
 
 -- ok, that id now seems to be saving
 
 -- now display the altered instructions for both best and worst
 
 worst_race_instruction_noise_alterations and best_race_instruction_noise_alterations
 
 -- ok, so it now displays. 
 
 -- run a much longer ga and see if that saves ok	
 
 -- friday 30th
 
 -- need to work on getting the game to re-run the noise alterations.
 -- first off, they need to be sent from the results page (for both best and worst races)
 
 -- adding a new param noise_alterations to add to the uri that calls the game race from results
 
 -- also add to worst race and check that both work
 
 - example url http://127.0.0.1:3003/tpgame.html?source=results&results_id=5f9aee5be4367c0b38a39d3f&startorder=2,1,3,0&instructions=%5B%5B44,%22effort=6.2%22%5D,%5B45,%22drop=2%22%5D,%5B112,%22drop=2%22%5D,%5B150,%22effort=9.54%22%5D,%5B163,%22drop=1%22%5D,%5B225,%22effort=9.38%22%5D,%5B245,%22drop=3%22%5D,%5B272,%22drop=1%22%5D,%5B350,%22drop=3%22%5D,%5B356,%22drop=3%22%5D%5D&noise_alterations=%7B%7D
 
 -- what's %7B%7D ? ah, it's {} 
 
 -- here's an example worst race URI that contains alterations:
 http://127.0.0.1:3003/tpgame.html?source=results&results_id=5f9aee5be4367c0b38a39d3f&startorder=2,1,3,0&instructions=%5B%5B47,%22effort=2.37%22%5D,%5B59,%22effort=1.21%22%5D,%5B110,%22drop=2%22%5D,%5B183,%22drop=3%22%5D,%5B246,%22drop=3%22%5D,%5B260,%22effort=6.25%22%5D,%5B292,%22drop=2%22%5D%5D&noise_alterations=%7B%2259%22:%7B%22original_instruction%22:%5B59,%22effort=1.21%22%5D,%22altered_instruction%22:%5B59,%22effort=0%22%5D,%22type%22:%22random_effort%22%7D%7D
  
 -- now need to decode them
 
 -- create a new variable: instruction_noise_alterations
 
 -- to check if an object x is an empty objec, i.e. x = {}, use
 
 Object.keys(x).length === 0 && x.constructor === Object
 
 -- finally have it showing but alterations look muck in the textarea... from the stringify? I see
 
 "{\"59\":{\"original_instruction\":[59,\"effort=1.21\"],\"altered_instruction\":[59,\"effort=0\"],\"type\":\"random_effort\"}}"
 
 -- took out the stringify, now have
 
 {"59":{"original_instruction":[59,"effort=1.21"],"altered_instruction":[59,"effort=0"],"type":"random_effort"}}
 
 -- now need to look at update_race_settings() to READ this from the new textarea and then move on to applying it
 -- huh, update_race_settings() does basically nothing, the work must be all in load_race()?
 
 -- added property instruction_noise_alterations_r to race and tried to set it from the textarea.
 
 -- Monday Nov 2nd. Still haven't finished much. fukk.
 
 -- first, commit to git. ahven't done this in a while.
 
 -- now load noise altertions again and go from there.
 -- seems to load alterations once for each rider- must be in a loop?
 -- yup- move both instructions and alteration settings outside the rider-loading loop
 -- works, now need to actually apply the alterations
 -- i guess handle race.instruction_noise_alterations_r like race.race_instructions_r
 
 -- Monyay Nov 9th. added few lines trying to tell if the alteration is a delay and if so to set the original instruction.
 
 -- need to sketch out how to handle the potential for there being multiple instructions on the one timestep. It shouldn't happen but I have 0 code controlling this and can't 100% assume that there will be just the one instruciton?
 
 -- montag nov 16th
 -- have to get the game to run those instrucitons and move on to the performance failure ones
 -- so, I've set delay_instruction = true but how do I apply this given that there MAY be multiple instructions for the one timestep. Or maybe I should just throw an error if there are > 1 for the same timestep? It shouldn't happen, right?
 
 -- need to use array.splice(index,0=add,1=replace,value) to remove an instructoin from new_instructions IF it has been delayed, but will this break the loop   for(i_i=0;i_i<new_instructions.length;i_i++){ ??
 -- test
 let a = [1,2,1,3,1,1,1,1,1,1,4,5,6,1,7,8];
 for(i = 0;i<a.length;i++){
	if(a[i]==1){
		a.splice(i,1);
		i--; //will otherwise skip the next element as it has been moved back a space
	}
 }
 
 -- ok, have added this, and removed the delay_instruction variable.
 
 -- ok, now it will try to make adjustments for delay/effort/drop types of noise, but needs to be tested and is probably buggy as fook
 
 -- works BUT in my test the effort is set to zero. This explains why it was the slowest race :-) 
 -- need to prevent effort being set to zero, and also need to handle it : I think the lowest allowed value shoudl be 1?
 
 -- added code to prevent 0 from being set in game. need to also adjust where it actually sets the noise.
 
 -- but first need to verify the lowest allowed effort level : it appears that the formula requires > 0 but that could be 0.1
 00 I guess look at where the effort instructions are created?
 -- seems like I use a setting called settings_r.minimum_power_output
 -- this is set to 1, so use this. why haven't i an equivalent setting for the max, and why is it such a shit name? should be settings_r.minimum_effort_level 
 
-- ok, updated
-- test some other alterations 
{"59":{"original_instruction":[59,"effort=1.21"],"altered_instruction":[59,"effort=6"],"type":"random_effort"}}

{"59":{"original_instruction":[59,"effort=1.21"],"altered_instruction":[61,"effort=1.21"],"type":"random_delay"}}

-- shocking- the delay worked seemingly first time

{"59":{"original_instruction":[59,"effort=1.21"],"altered_instruction":[61,"effort=1.21"],"type":"random_delay"},"110":{"original_instruction":[110,"drop=2"],"altered_instruction":[110,"drop=3"],"type":"random_drop"},"246":{"original_instruction":[246,"drop=3"],"altered_instruction":[246,"drop=1"],"type":"random_drop"}}

-- weird, seesm that instruction_noise_alterations gets set to the wrong element
-- how can this line break?
let instruction_noise_alterations = race.instruction_noise_alterations_r[race.race_clock];
-- oh wait, my actual instruction is poo

-- test with a fast race (add a new fake alteration) 

{"153":{"original_instruction":[153,"drop=3"],"altered_instruction":[153,"drop=1"],"type":"random_drop"}}

-- 290.07 with change, same without :-( though it does seem to work, how could it make zero to the finish time?
-- try a more dramatic change to the effort

{"186":{"original_instruction":[186,"effort=8.02"],"altered_instruction":[186,"effort=5"],"type":"random_effort"}}

-- ok so this made a big difference, finish time now 316.596 seconds

-- time to commit changes

-- next up need to look at performance failure

-- sketched out the idea for how the performance failure would work. idea is to have two functions
-- first takes in effort/fatigue/rider_failure property, and returns a 0-1 prob of failure.
--if this is passed via random number selection
-- second function takes more or less the same properties but returns a % to fail by. 
-- this % will be used to adjust the power output
-- details of each failure will need to be stored in the results so that they can be replayed as with the random noise
-- can each rider fail on every timestep? what happens if a chasing rider fails?

-- Tuesday 17th

-- finish basic forumlas on Excel and try to incorporate into code

-- sketched out how to store the performance failures for replay
-- e.g. performance_failures={
								"101_0":0.12,
								"241_3":0.241
							}
-- should be relatively easy to apply but what's crucial to know is exactly WHERE this happens in the power calcualtion process
-- currently think AFTER fatigue and step-size limits are applied.
-- seems like the power failres will be wobbles as opposed to longer problems, i.e., a rider fails by % in step 4, but unlikely to fail again in step 5. Could potentially make a failure less of a poitn and more of a trough? Or increase likelyhood of failure if you have just failed? Seems like wayyy too much guewtimating of physical processes here. Again.

-- in cany case build it. The two functions are crucial

-- wednesday 18th novembre
-- create dumb versions of the functions and add the required props
-- each rider gets
-- "performance_failure_rate": 4
-- "performance_failure_multiplier": 6
 
-- global settings gets 
-- "main switch performance_failure_enabled":0
-- "performance_failure_probability_exponent":1 -- used in formula to skew effect of formula arguments. e.g. 1 = linear, 2 is a square so lower values have less effect
-- "performance_failure_amount_exponent":1
-- "performance_failure_base_max_percentage":0.1 -- max percentage that the rider can fail by (will be limited in any case by the step-down size unless I update how that is applied)
-- "rider_performance_failure_rate_max": 10,
-- "performance_failure_multiplier_max": 10

-- now create two funciton stubs
-- 1: calculate_rider_performance_failure_probability(effort, current_fatigue, accumulated_fatigue, rider_performance_failure_rate, performance_failure_exponent)

-- 2: calculate_rider_performance_failure_percentage_amount(effort, current_fatigue, accumulated_fatigue, rider_performance_failure_multiplier, performance_failure_base_max_percentage)


-- adding "maximum_effort_value":9 to global settings, as it should really be already there, rather than embedding 9 in the code


-- Thursday 19th
-- check the calculate_rider_performance_failure_percentage_amount function, seems to be failing, debugger it
-- blast, was missing a = , e.g. let x (1 + 2)
-- now seems to run but is spitting out some pile of messages.
-- just output the rider failure % as it seems to be bigger than it should?

-- ok, it does seem to work, just trying some different settign values to watch waht happens

-- see an example of high fial % with a low power - this should be really unlikely even with a lot of fatigue? 
-- high fatige + high acumulated fatigue + low effort can still result in a big failure- is that ok or should I tweak the formula. For example I could make the effort have twice the effect as the other properties? would just need to multiply it by 2 and add 1 to the divisor?

(effort*A + y + z)/3+(A-1)

-- e.g. (1*2 + 1 + 1)/3 + (2-1) = 1, (1*2 + 0 + 0)/3 + (2-1) = 0.5


will this still give me a 0-1 range for any A?

-- could have A as a global property "performance_failure_effort_importance_multiplier":1
-- i guess add it to both formulas (same prop). though same % on bigger power is already going to be a bigger drop: but still, we want to shrink the % drop for small effort, or even just make failure at small effort less likely. 

-- still getting a high failure amount for low effort in some cases, e.g.
RIDER FAILURE 48.40815144032922% target_power updated from 266.6666666666667 to 137.57826282578876

-- guess I could log more info and see what the actual props values are in a case like that?

-- will also need to do the logging and replaying aspects before doing any biger tests

-- ideally I need to be able to run this in the race sim itself, as well as the random noise, so that I can play races a few times and get different results. It woudl help test things. I'd need a switch to enable/disable it, like a replay mode and a regular mode. I guess it will always replay whatever it find in the inputs? so would just need one switch/setting, or maybe one each for enable_random_noise_in_game_sim and enable_performance_failure_in_game_sim ? bit of coding there, too. can you for example have noise ON a noise instruction? seems to me that it wouldn't make any sense 

-- game_sim is currently crashing cos nothing in the noise alteration textarea- does this ever run now from the GA page?

-- first need to start storing the failures in a new data structure performance_failures
-- ok, it seems to add to the dict but this is not visible in mongo when I save the results. why is it not there?

--ok, tis there now, was missing a line. mebbie should round the failure % to two decimals places, is currently v. long

-- done, used the DecimalPrecision.round(X,2) function that I've used elsewhere

-- now get them to display on the game page

-- back up. step 1: show them on the results page

-- huh, somethign seems wrong here, final_worst_race_instruction_noise_alterations only gets used once in the code, how can it be returned?

-- changed that, now need to add tabs in the game page to organise the text areas and be able to fit 3- over to bootstrap/css

-- now load in the performance failures from the url data

-- right, do I now have race.performance_failures_r available to use in the race?
-- nope, bug 
performance_failures_string = "[object HTMLDivElement]"
somethign being set wrong

-- friday 20th november 2020
-- need to get the replay goigng and work towards proper testing
-- what's going on with the rounding?
RIDER FAILURE 7.000000000000001% target_power updated from 400 to 372,

ah, so if we round 0.03432112 to 2 places we get 0.03, i.e. 3%. If we want 3.43% here we need to round to 4 places. try that.

oh, looks like the failures are only being applied to the lead rider. oops

-- hmmm, not reading array cos a  DOM element is also called 'performance_failures'

-- hmmmmm, not sure if the failures are working- see, they apply to target power, but actual power output is already limited to the steposize and the target power will be reset in any case for the next timestep. I guess it should have an effect sometimes, but only when the target power is close to the current power.

-- ah balls, so far the performance failues seem to have zero effect- if I take them out and rerun the race there is NO change in the finish time. will have to rethink- it must be to do with the note above, how the failure is affectign the target power but not the actual power and NO failure really happens.

{"26_2":0.741,"26_0":0.741,"26_1":0.741,"26_3":0.741,"71_0":0.741,"90_2":0.741,"107_3":0.0741,"119_2":0.0815,"166_0":0.082,"186_2":0.0779,"195_3":0.0772,"253_2":0.0779,"274_3":0.0772}

-- what if I add really huge failures? ooh, it changed the finish time by a few tenths of a second.

-- Montag Nov 23rd

-- need to use debug tools to step through what happens when there IS a performance failure. WHy does the change have no effect?

-- ok. so target_power is 267.5874202315783 and performance_failure_percentage is 0.0741. target_power gets updated to 247.75919239241833. powerv is also 267.58 (note rounding diff). power_adjustmentgets set to -19.820807607581656. So there IS an effect here, surely?

-- maybe the issue going on is that the GA generation winner is simply the varient that fails the least? Like maybe other races have failures that have a big effect, therefore they don't win?

-- performance_failure_percentage seems to be 0.0741 a lot. strange.

-- try setting riders to have a ton of failures ( "performance_failure_rate": 10,
               "performance_failure_multiplier": 10 for all riders)
here's what the best race performance_failures from gen 1 looks like
{"0_1":0.0741,"5_2":0.0741,"5_0":0.0741,"7_0":0.0741,"7_3":0.0741,"10_0":0.0741,"10_1":0.0741,"13_3":0.0741,"14_3":0.0741,"17_2":0.0741,"20_1":0.0741,"21_1":0.0741,"22_3":0.0741,"26_2":0.0741,"27_3":0.0741,"30_0":0.0741,"32_0":0.0741,"33_3":0.0741,"35_2":0.0741,"37_0":0.0741,"37_3":0.0741,"41_1":0.0741,"41_3":0.0741,"44_2":0.0741,"46_3":0.0741,"49_3":0.0741,"51_3":0.0741,"52_3":0.0741,"53_2":0.0741,"54_3":0.0741,"62_2":0.0741,"63_2":0.0741,"65_2":0.0741,"66_2":0.0741,"67_0":0.0741,"68_0":0.0741,"68_3":0.0741,"70_2":0.0741,"70_1":0.0741,"70_3":0.0741,"71_0":0.0741,"72_3":0.0741,"74_1":0.0741,"76_1":0.0741,"78_2":0.0741,"81_0":0.0741,"81_3":0.0741,"84_3":0.0741,"88_2":0.0741,"89_3":0.0741,"90_2":0.0741,"90_1":0.0741,"92_2":0.0741,"96_1":0.0741,"98_0":0.0741,"99_1":0.0741,"100_3":0.0741,"103_1":0.0741,"104_2":0.0741,"104_0":0.0741,"105_2":0.0741,"106_0":0.0741,"107_0":0.0741,"110_3":0.0741,"113_0":0.0741,"113_3":0.0741,"117_2":0.0741,"120_1":0.0741,"122_2":0.0741,"123_0":0.0741,"124_1":0.0741,"124_3":0.0741,"126_3":0.0741,"129_1":0.0741,"130_2":0.0741,"131_0":0.0741,"132_3":0.0741,"133_2":0.0741,"136_3":0.0745,"137_1":0.0741,"137_3":0.0745,"138_1":0.0741,"140_2":0.0741,"141_1":0.0741,"142_2":0.0741,"142_3":0.0741,"144_1":0.0741,"144_3":0.0741,"147_1":0.0741,"147_2":0.0741,"148_1":0.0741,"149_2":0.0741,"153_2":0.0741,"153_3":0.0741,"154_0":0.0741,"154_1":0.0741,"154_3":0.0741,"155_3":0.0741,"156_2":0.0741,"157_0":0.0741,"160_0":0.0741,"160_3":0.0741,"166_2":0.0741,"169_3":0.0741,"171_3":0.0741,"173_2":0.0741,"175_2":0.0741,"176_3":0.0741,"177_1":0.0741,"178_2":0.0741,"186_1":0.0741,"189_0":0.0414,"189_3":0.0741,"190_2":0.0741,"191_0":0.0414,"193_1":0.0741,"197_1":0.0741,"197_2":0.0741,"198_1":0.0741,"198_2":0.0741,"199_1":0.0741,"201_0":0.0414,"201_3":0.0741,"203_1":0.0741,"204_3":0.0741,"206_1":0.0741,"210_2":0.0741,"213_2":0.0741,"217_2":0.0741,"218_3":0.0741,"220_1":0.0411,"221_3":0.0741,"223_1":0.0411,"231_2":0.0411,"232_3":0.0741,"235_2":0.0411,"235_3":0.0741,"239_0":0.0414,"242_3":0.0741,"244_2":0.0411,"246_1":0.0411,"247_3":0.0741,"249_3":0.0741,"250_3":0.0741,"254_3":0.0741,"254_0":0.0414,"255_0":0.0414,"256_2":0.0411,"263_3":0.0741,"264_0":0.0414,"267_2":0.046,"268_3":0.0741,"269_2":0.046,"271_1":0.0411,"272_1":0.0411,"275_2":0.046,"279_0":0.0414,"288_0":0.0414,"292_2":0.046,"295_3":0.0741,"296_1":0.0411,"300_1":0.0411,"302_3":0.0741,"305_0":0.0414,"309_3":0.0741}

 311.396 seconds
 
 -- if i take out all those failures, how fast are they?
 
 -- huh- performance failures still happen when I hit the STOP button a few times?
 -- ok, needed to add a few more lines to reset the data structs
 -- no failures now but the time is 310.58. that's a tiny difference for maximum failure settings.
 
 -- try amp up the failure % and see what happens.
 
 -- huh, "performance_failure_base_max_percentage":0.5 but I get 0.74? surely it would be max of 0.5? need to keep pokign about here to make sure things work ok
 
 -- huh, the results DO seem to be < 0.5 so why are the logged values more? am i logging thw rong thing?  i.e. probbaility instread of amount? it seems I am logging the right value but I can still see tons of .0741 in the results. cen fÃ¡th?
 
 -- ah, sure it's 0.5 NOT 0.05 and I'm getting 0.07 not 0.7, so this may just be dumb.
 
 -- so set to 1 ( max right?) do I get more dramatic failures?
 307.394 with failures, 298.837 without. that's better, right?

-- here's a test. all else being equal, will a team where one rider fails less make that rider do more work?
-- will need to have a decent amount of failure, a good few gens, reasnable size of pop. turn off the logging?
-- ran 20 gens of 1000 with all 400/1000 but one rider fialing far less than others
-- hmm, less faily rider starts at front but does not spend any wxtra time there- of course riders can fail in any position.
-- best race finish t 288.553 seconds. take out failures and it is 294.498 seconds. whaaaa? ARe the instructions being inflated to balance out the failures? 

-- from looking at that example and playing both fail/nofail versions it seems that yes, the combination of instruction and failures is key: in this example there is one phase where a rider goes close to failure but because of performance failures jsut about gets to swtich and recover. So, a performance failure is actually part of the strategy. That's with a high level of failure, such that if riders have long turns they will reliably record some level of failure during it.

-- run the same ga with NO performance failure and compare the best results with the last. more instructions? different kind of result?

-- hard to read much intot he single race from so many gens. defo quicker without the failure but how is it affecting the search- would need to seed the process with an identical starting population? 

-- for kicks, try run a process with tons of noise and see what that does.

what would a conservative strategy look like? and how would it not disappear being replaced by ones with finer margins? does the blunt fatigue-failure mechanism have too much of an impact on behaviour? 

-- need a few paragraphs and a couple of images or a graph to explain the effect of the npise and failure.how does each affect the GA? are the effects different or similar? why does a rider that does not fail not get prioritsed?

-- do ai need to try to shift the application of the failure? 

-- so with more noise, here's an e.g. 288.832 seconds with a lot of noise, all weak.
instruction_noise_alterations:
{"102":{"original_instruction":[102,"effort=6.5"],"altered_instruction":[102,"effort=6.214388160783767"],"type":"random_effort"},"135":{"original_instruction":[136,"drop=2"],"altered_instruction":[136,"drop=2"],"type":"random_delay"},"234":{"original_instruction":[234,"drop=2"],"altered_instruction":[234,"drop=1"],"type":"random_drop"},"272":{"original_instruction":[272,"effort=8.74"],"altered_instruction":[272,"effort=7.676728792877347"],"type":"random_effort"},"277":{"original_instruction":[277,"drop=1"],"altered_instruction":[277,"drop=2"],"type":"random_drop"},"283":{"original_instruction":[283,"effort=8.83"],"altered_instruction":[283,"effort=9"],"type":"random_effort"}}

-- if I remove the noise it is 302.915 seconds, so again SLOWER. mad. or is it? the GA is just searching for improvements and this must be a strategy that is amenable to a crucial piece of noise. with no noise one rider fails and causes a big slowdown about halfway through- the noise works in its favour.

-- error in the graphing code: ReferenceError: graph_data_5 is not defined
`
-- lotsa noise AND lotsa failure 292.6 seconds, 293.763 seconds instructions only.

-- Mondee 14/12. so much undone. Run the noise again and open overleaf. at least add the paragraphs desribing it.

-- so what happens with tons of performance failure and I remove it?
-- with p. failure, best race after 20 gens> 295.735
-- with p. failure removed (same instructs and noise)> 326.262 
-- with p.failure and nise removed:339.127 
-- with p.failure included and noise removed: 355.179 

-- but I must be getting worse best-race-scores than when I have NO p.failure?
-- run the same thing with noise and NO p.failure. 
--hmm, swithcing performance_failure_enabled:0 does not seem to actually disable ti :-(

-- ok so it does seem to work after all, reran the test
-- after final gen: 290.078. so quicker, but not by a whole ton at all
-- does the power curve look much different?

-- acshully, the version with noise AND failure gets down to 291.345s in the final gen

-- ok, so it is quicker when there is no noise/failure, but maxxing them out is not nearlyu as damaging as I would have thought. Perhaps I need to make them fail by more?

-- try noise first, make it so that there is tons of noise and its effects are HUGE, like wild changes

-- 2021

-- monday jan 18
-- huge gaping gap but can't get that time back. only go on

-- reade last few notes to try pick things up again
-- so, noise and failure does not have the effect 'desired'? 

-- rerun that test: no failure then + max noise/no failure, then no noise/max failure, then max noise/max failure, and see what you dend up with.

-- note: with noise there is no thin-air-noise, i.e. no randomly created new ones, just abberrations to exiting ones
-- the noise coudl actually make the strategy do BETTER, not just worse. But the noise does not get pushed into the next generation. Noise is just changes, not specifically disimprovements. so the fitness is based on instructs+noise, but in the next generation there will be different noise. does the avg. fitness of the population improve more slowly?

-- on the failure end, it seems that if tyhe failures are 'regular' then they become mechanistic and essentially part of the strategy: instructions + failure. Ones that perform best are those that, when they fail, approximate better solutions. This means you end up with solutions that will actually get WORSE if you run them without the failure!

-- might be able to fidn a better way to implement failure to reduce/remove this?

-- but first need to understand it properly and write somethign about it

-- run 1 done: no noise/failure. 
-- run 2 done: lots of noise/no fialure
-- run 3 : no noise/lots of failure
-- run 4: lots of noise: no failure

-- put these results in a spreadsheet to show the differences between
first-last gen best/average 
% improvement

-- ok, added data but have of course hit a disrapancy that throws it all out
-- if I play the best race from gen. 20 in test case 2 (lots of noise/no failure), I get a different result to the GA. But how can I compare the GA/game versions where noise is applied? One generates it and the other replays it. Will have to do long slow testing of the noise feature in BOTH versions to try dig out where it has gone wrong.

result in GA: 290.906, result in game: 291.284

have a quick look at the power graphs

-- huh, in the noise there is an entry to delay instruciton from 275 to 278, then one already at 278.
-- which one actually gets run at 278? this is where the power graphs start to differ.
-- NOPE, misread, the delay is actually for ZERO seconds: what does a zero second delay do? perhaps it is run in one and not the other?

{"123":{"original_instruction":[123,"drop=2"],"altered_instruction":[123,"drop=3"],"type":"random_drop"},"153":{"original_instruction":[153,"effort=5.71"],"altered_instruction":[153,"effort=6.26850943436085"],"type":"random_effort"},"157":{"original_instruction":[157,"drop=3"],"altered_instruction":[157,"drop=2"],"type":"random_drop"},"181":{"original_instruction":[181,"drop=2"],"altered_instruction":[181,"drop=3"],"type":"random_drop"},"229":{"original_instruction":[229,"drop=2"],"altered_instruction":[229,"drop=3"],"type":"random_drop"},"257":{"original_instruction":[257,"drop=1"],"altered_instruction":[257,"drop=2"],"type":"random_drop"},"270":{"original_instruction":[275,"effort=2.99"],"altered_instruction":[275,"effort=2.99"],"type":"random_delay"},"278":{"original_instruction":[278,"effort=9.95"],"altered_instruction":[278,"effort=9"],"type":"random_effort"}}

-- seems possible that the game is running an insturciton that has a delay of ZERO, while the ga is not?

-- first bug to fix: pressing stop button in game after editing noise does not apply the change.

-- progress. what seems to happen is that in the GA the instruction is NOT run as noise is added, but that noise is a delay with offset 0, which will NEVER run. In the Game, the instruction runs and the 0-offset noise delay does nothing at all.

-- fix: need to edit the ga code to never assign a delay of 0. This means I have to rerun the same tests though.

-- it seems that the delay offset cannot be zero as it uses this:
let timestep_delay =  Math.floor(Math.random() * (noise_1_probability_instruction_delay_range) + 1) ; 
-- but below this we have:
noise_alteration["original_instruction"] = new_instructions[i];
              new_instructions[i][0] += timestep_delay; //actually add the delay

              noise_alteration["altered_instruction"] = new_instructions[i];
              noise_alteration["type"] = "random_delay";
-- note that we use = with arrays BUT it is the references that will be used. SO this means that the original instruction will also include the cursed offset and will be wrong. 

-- evidence for this would be that all delays have the same original and altered timestep, and that there is no corrosponding instruction for the original.

-- can fix this posisbly with a slice() to force a COPY to be used, but need to verify that my hypothesis is correct

-- huh, comparing noise to instrucitons and looks verrrrry dodge.

-- e.g., it seems that delayed instructions have noise applied
-- there are noise entries for timesteps that do NOT exist.
-- delays seem messed up in multiple ways. are the original instrucitons being moved, and then these are what is logged as the actual instructions?

-- also, we have this as a set of instructions:
[[110,"drop=1"],[202,"drop=3"],[233,"effort=8.74"],[258,"drop=1"],[292,"effort=8.559999999999999"],[280,"effort=9.68"],[283,"drop=2"],[288,"effort=9"],[298,"drop=2"]]

note how 292 precedes 280. wtf!

-- are instructions out of order if there is NO noise?

-- i don't see this with no noise or with p. failure only.

-- have to change the delay algorithm then see if that adresses the other issues. it should NOT change the race instructions as noise is supposed to be separate. instead, at each timestep check some kind of delays array for any waiting instructions. it just needs to know [delayed_timestep, original_timestep] or even {"delayed_timestep": original_timestep}. have to be very sure that it doesn't break anythign.

-- ooh, the timesteps are NOT out of sync if I turn off the delays. so fixing that should sort them.

- tuesday 19th.
-- rebuild the delay mechanism (both ga and game need changes)

-- tried writing out a new mechanism for finding a free target timestep to delay until, which handles the case when timesteps are already 'occupied'. this is way more complex to me than it first seems
-- need to add instruction_noise_delays to race_r

-- so now need to NOT run an instruction if it is marked for a delay.

-- Wednesday Jan 20
-- only did a tiny tiny bit, fixed one bug with an else statement

-- Thursday Jan 21
-- fixed some bugs to get it to actually run, but so far it has loggeed nothing about delays at all.

-- yikes, we get log message slike
NOISE 1: DELAY instruction [120,"drop=2"] to {"original_instruction":[120,"drop=2"],"altered_instruction":[4,"drop=2"],"type":"random_delay"} actual_timestep 4

-- so, the actual_timestep makes no sense; it shuld always be bigger than the original timestep

-- ok, so the issues was in the original non-collision setting of actual_timestep
-- now, it looks like the delayed instrucitons array is blank
***DELAY***58: delayed_instructions []

-- ok, so the GA ran and results can be saved. currently only delay noise, very high. instructions are NOT out of order. 

GA time: 291.921 Game time: 296.265

balls, very far apart. 

-- ah crap, one array is just a reference to an old one, ned to use slice()



-- ok, there was another bug. now tho it does seem to run . will be easier to check in the Game when checking to see if the results make sense

even with slice it still IS the original. odd.

need to deeeeep copy: https://stackoverflow.com/questions/122102/what-is-the-most-efficient-way-to-deep-clone-an-object-in-javascript

-- Friday 22 01 2021
-- ok let's at least try this method
JSON.parse(JSON.stringify(obj))

-- may need to review more sections in the code as this is the first time I've actually tried to deep copy as opposed to a shallow copy or an = operation

-- ok, so nowww it seems to remove the delay instruction BUT BUT BUT
-- it gets even SLOWER
GA time: 291.921 Game time: 298.704

#monday jan 25
--ok, need to figure out what went wrong. why is it slower.
-- here's a test- I can manually construct the instructions that should run, i.e. that should be identical to the original instructions + the delays.

-- with delays added in we get
[[16,"effort=8.629999999999999"],[44,"drop=2"],[37,"drop=2"],[93,"drop=1"],[139,"drop=2"],[196,"drop=1"],[208,"effort=3.79"],[219,"drop=2"],[225,"effort=6.18"],[256,"drop=1"],[291,"effort=6.4"],[276,"effort=9.22"],[273,"effort=8.2"]]

note how the order is broken, i.e. 291, 276, 273
Time: 298.705. Huh, almost exaclty 298.704 but must be some teeny difference 

Do I get the same time IF I put these instructions in the correct/sorted order?
[[16,"effort=8.629999999999999"],[37,"drop=2"],[44,"drop=2"],[93,"drop=1"],[139,"drop=2"],[196,"drop=1"],[208,"effort=3.79"],[219,"drop=2"],[225,"effort=6.18"],[256,"drop=1"],[273,"effort=8.2"],[276,"effort=9.22"],[291,"effort=6.4"]]

Time: 298.705. SO the order is not he issue. Good. In fact, it seems the problem is in the GA, not here.

Back to the GA. Review how the delays work. 

I wonder what time we get (game) if we ignore every delayed instruction? Maybe this is what the GA does? 
[[16,"effort=8.629999999999999"],[37,"drop=2"],[139,"drop=2"],[196,"drop=1"],[219,"drop=2"],[256,"drop=1"],[273,"effort=8.2"]]

Time: 291.921 Gotcha! GA is threfore probs NOT running the delayed instructions at all!

-- frig, there was a bug in the code adding the delayed instruction

ok, made changes, found and fixed a bug, ran 20 gens of 1000 again 
-- compare last best race. same time in GA and game?
ga time: 287.26 game time: 287.26 
-- phew. this seems like progress?
-- try it again

-- test 2, GA gen 20 best time: 285.889. Game time: 285.889

-- good.

-- now rerun the earlier set

-- no noise
-- small delays only 
		"noise_1_probability_instruction_delay_range":4,
-- lots of noise/no failure
-- no noise/lots of failure
-- lots of noise/lots of failure

-- Tuesday, Feb. 2nd, 2021

-- redo those experiments above- use the same Google sheet as before to record some results and create a few graphs

-- want to be able to produce pure noise results, i.e. a GA that does not improve at all

-- call these 
-- Feb 2 Tests: pop 1000, 20 gens NO NOISE/NO FAILURE
-- Feb 2 Tests: pop 1000, 20 gens DELAYS ONLY/ NO FAILURE
	"enable_instruction_noise_1_random":1,
	"noise_1_probability_instruction_misheard":0.5,
	"noise_1_probability_instruction_delayed": 1,
	"noise_1_probability_instruction_delay_range":5,

-- Feb 2 Tests: pop 1000, 20 gens LOTS OF NOISE/NO FAILURE
"enable_instruction_noise_1_random":1,
"noise_1_probability_instruction_misheard":1,
"noise_1_probability_instruction_delayed": 0.3,
"noise_1_probability_instruction_delay_range":5,
"noise_1_probability_instruction_effort_range":5,
"noise_1_probability_instruction_drop_range":3,

-- note here we have noise on every timestep: surely this will have a big impact on the GA and on how much it can improve?

-- Feb 2 Tests: pop 1000, 20 gens NO NOISE/LOTS OF FAILURE
-- what exactly tunes the level of failure again?
This seems key: (rider_performance_failure_rate/rider_performance_failure_rate_max)
"performance_failure_enabled":1,
"performance_failure_probability_exponent":2,
"performance_failure_effort_importance_multiplier":1,
"performance_failure_amount_exponent":2,
"performance_failure_base_max_percentage":1,
"rider_performance_failure_rate_max": 10,
"performance_failure_multiplier_max": 10,
"maximum_effort_value":9

-- ah fukk.
GA time gen 19 best race: 289.368. Game time: 289.334
GA time gen 18 best race: 288.463. Game time: 289.799 
GA time gen 17 best race: 289.545. Game time: 289.545 
GA time gen 16 best race: 290.278. Game time: 290.278 

huh.

-- very hard to spot anywhere where the game would differ from the ga, but somethign is defo amiss :-( 
-- 1 possible theory: failures at timestep 0 are being ignored?
-- nope, there is no timestep 0 in the example 


-- so, setting these to both be 10 will cause maximum failure? Try it?
-- Feb 2 Tests: pop 1000, 20 gens LOTS OF NOISE/LOTS OF FAILURE
-- power graphs very similar tho the GA goes to higher power right at the end, wheras the game seems to fail a bit. is this fatigue?

- key instruction [260,"effort=9.83"]. i wonder what happens if you have an instruiton to fail on this same go?
model3.js:442 Performance failure 260_2 of 0.3989 reducing power from 1000 to 601.1
-- i wonder what happens if I run it without this one failure?

rider seems to hit the fatigue wall at 170 while trying to get to 1000 watts. the failures here don't seem to change much? 

-- wednesday feb 3rd
-- plan to fix latest bug
-- add function to display the raw power data that is behind the graph, and use this to pinpoint where things start to differ between ga and game: check for anything odd at this timestep

-- theory: in ga, failure on same timestep as instruction is handled differently than in game (e.g. runs or does not run)

-- add nea textarea at bottom of results page to put the data into (easy to copy from)
-- add a new column with a button that calls a function to find and put the power data in the textarea
-- will need a new function : show_power_data()

-- works though the data is hard to read, might add code to show it twice- 2nd time formatted vertically to make it easier to compare (1 line per timestep)

-- can use "40".padEnd(6) to pad out the length of short values

-- done, now need to do the SAME thing for the game; start by adding a textarea

-- done, now can compare the data in notepad

-- fugg, the entries have different orderings. why? need to look at where I add to the power data arrays in each setup
game:
rider_power_data[race.current_order[i]].push(powerv); line 501
ga:
  rider_power[race_r.current_order[i]].push(powerv); line 1733
  
  huh, no obvious issues here.
  
  -- so, start order should be 0, 3,2,1. which looks correct in the GA. yet the game data seems to be ordered 0,1,2,3?
  
  -- ah shit, I may have been running the wrong one :-( 
  
  -- ok can now compare: ga/game identical until ts 186, then there's a 0.1 diff in 3rd rider
  -- but they later line up again and it doesn't totally diverge until ts 274
  
  there is no failure or instruction at ts 186
  
  -- ts 265 lso significant, here is where the leader first goes out of sync in a big way. try taking out this failure in the same and see if the data gets closer?
  
  -- huh, now I get 288.463: exactly the same time as the ga.
  -- 1: why is this failure so BIG, and 2: why does it NOT have the same effect in the ga?
  
  -- looks like the GA ignores the failure. lead rider, increasing power
  
  Game: 265	259.1 	448.69	582.1 	265.08
  GA:	265	259.09	448.69	651.28	265.08
  
  failure = "265_2":0.4179
  
  formula =   target_power = target_power - (target_power*performance_failure_percentage);
which will be 1000 - (1000*0.4179) = 582.1

Ga creates failure BUT ignores it. warum?
-- maybe the power effort is actually > 9 and this has a knock on effect? would it be enough to cancel out the reduction in target power?
power_from_effort = 400 + (1000 - 400) *((9.83-6)/(9-6));
== 1166
 == 1166-(1166*0.4179) = 678.7286
 -- this COULD explain it?
 -- found error checking in Game that is NOTTTT in GA!!!
 -- comment it out and see if you then get the same answer
 -- new game time: 288.463
 
 -- this seems like the cause then? muthafunka
 
 -- ok so ran GA again and first check finds the minor discrepancies but not the majors. will have to figure out both tbh.

-- thursday 4th feb 2021. 

-- do i get the same discrepancies when there is NO noise or failures? RUn a new batch to check since I did change code.

-- ok so they are there- it is not related to failures or noise
-- seems to happen to the chasing tiders... off by .01, both higher and lower. doesn't seem to be enough to put the finish time off but still annoying. rounding?

GA
race_rider.aero_A2 = Math.round((race_rider.aero_A2 - race_rider.aero_A2*(shelter_effect_strength*level_of_shelter))*10000)/10000;
let A2Eff = (tv > 0.0) ? race_rider.aero_A2 : -race_rider.aero_A2; // wind in face, must reverse effect
let target_power = (target_velocity * race_rider.aero_tres + target_velocity * tv * tv * A2Eff) / settings_r.transv;
GAME
race_rider.aero_A2 = Math.round((race_rider.aero_A2 - race_rider.aero_A2*(shelter_effect_strength*level_of_shelter))*10000)/10000;
let A2Eff = (tv > 0.0) ? race_rider.aero_A2 : -race_rider.aero_A2; // wind in face, must reverse effect
let target_power = (target_velocity * race_rider.aero_tres + target_velocity * tv * tv * A2Eff) / settings.transv;

-- only diff I've found (so far) is that the newton lookup feature was disable in the GA but NOT in the game. 

-- disable it and see if you get the same results

-- same issue, no change

- Friday 5th.
-- ok, need to sort this fugging power discrepancy.
-- so the power goes off

GA
11 | WEAK 2 LEAD | 130.19m | 48.61 kph | 400 / 400 / 1000 watts | -1 m | 0/0 ||||  11 | WEAK 1 FOLLOW | 128.19m | 48.61 kph | 294.01 / 400 / 1000 watts | 2 m | 0/0 ||||  11 | WEAK 4 FOLLOW |F| | 126.19m | 48.61 kph | 267.58 / 400 / 1000 watts | 2 m | 0/0 ||||  11 | WEAK 3 FOLLOW | 124.19m | 48.61 kph | 262.14 / 400 / 1000 watts | 2 m | 0/0 |||| 
GAME
 11 | WEAK 2 LEAD | 130.19m | 48.61 kph | 400 / 400 / 1000 watts | -1 m | 0/0 ||||  11 | WEAK 1 FOLLOW | 128.19m | 48.61 kph | 294.01 / 400 / 1000 watts | 2 m | 0/0 ||||  11 | WEAK 4 FOLLOW |F| | 126.19m | 48.61 kph | 267.58 / 400 / 1000 watts | 2 m | 0/0 ||||  11 | WEAK 3 FOLLOW | 124.19m | 48.61 kph | 262.15 / 400 / 1000 watts | 2 m | 0/0 |||| 
 
 -- only difference is 262.15 to 262.14 
 -- there are distance discrepos by the end of the race, tho they are v. small, 0.01m 
 
 Game log message uses
 Math.round(display_rider.power_out * 100)/100
 GA uses the same
 Math.round(display_rider.power_out * 100)/100
 
 -- huh, I turned off the lookups for the LEAD but not the following rider. add this
 
   if (use_lookup_velocity)
      {
	  ...
	  ...
	  }
      else {      
        race_rider.velocity = newton(race_rider.aero_A2, settings.headwindv, race_rider.aero_tres, settings.transv, powerv);
    }
	
-- hmmm, too may differences- am i running it right?

all weak 400/1000 with no noise or failure

[[58,"effort=6.6"],[75,"drop=2"],[82,"drop=1"],[101,"drop=2"],[103,"drop=2"],[113,"drop=2"],[134,"drop=3"],[142,"drop=2"],[153,"drop=2"],[158,"drop=2"],[190,"effort=7.27"],[193,"drop=3"],[197,"drop=2"],[226,"effort=7.29"],[239,"drop=2"]]

starting order 1,0,3,2

-- ran the ga again and still have the large numbers of differences
-- soooo, where is it going wrong?
-- maybe add another attribute to the rider to store info like powerv for each step and add this to the log?

-- add step_info to rider
-- waht do we want to log?
target_power
powerv
aero_A2
accumulated_fatigue
endurance_fatigue_level
output_level

in that order
-- logging but getting undefined for some parts

-- now have to also add this to the ga

-- huh, added all this info and nowwww they seem to be identical? was it the newton thing?

-- run the whole thign again- GA then compare last gen best via logged power values from graph.

-- good- they are identical. that means the damn thing WAS the newton lookup mechanism, which I had disabled properly in the ga but NOT in the game. bah!

-- run these again (againagainagain)
-- Feb 5/8 Tests: pop 1000, 30 gens NO NOISE/NO FAILURE
-- Feb 5/8 Tests: pop 1000, 30 gens DELAYS ONLY/ NO FAILURE
-- Feb 5/8 Tests: pop 1000, 30 gens LOTS OF NOISE/NO FAILURE
-- Feb 5/8 Tests: pop 1000, 30 gens NO NOISE/LOTS OF FAILURE
-- Feb 5/8 Tests: pop 1000, 30 gens LOTS OF NOISE/LOTS OF FAILURE

-- Monday Feb 8th. Do those tests again.
-- huh, took 566.665 to run the 230 gens. did I leave something dumb in the code?

-- Feb 5/8 Tests: pop 1000, 30 gens LOTS OF NOISE/NO FAILURE
	"enable_instruction_noise_1_random":1,
"noise_1_probability_instruction_misheard":1,
"noise_1_probability_instruction_delayed": 0.3,
"noise_1_probability_instruction_delay_range":5,
"noise_1_probability_instruction_effort_range":5,
"noise_1_probability_instruction_drop_range":3,
"performance_failure_enabled":0,
-- so that's a lot of noise- should have a big effect? 	

-- Feb 5/8 Tests: pop 1000, 30 gens DELAYS ONLY/ NO FAILURE
"enable_instruction_noise_1_random":1,
"noise_1_probability_instruction_misheard":1,
"noise_1_probability_instruction_delayed": 1,
"noise_1_probability_instruction_delay_range":5,
"noise_1_probability_instruction_effort_range":5,
"noise_1_probability_instruction_drop_range":3,
"performance_failure_enabled":0,

-- Feb 5/8 Tests: pop 1000, 30 gens NO NOISE/LOTS OF FAILURE

-- performance failure is too dterministic: needs to have a stochastic aspect. but continue ahead and run the current batch in any case before rewriting anything

"performance_failure_enabled":1,
"performance_failure_probability_exponent":2,
"performance_failure_effort_importance_multiplier":1,
"performance_failure_amount_exponent":2,
"performance_failure_base_max_percentage":1,
"rider_performance_failure_rate_max": 10,
"performance_failure_multiplier_max": 10,


-- Feb 5/8 Tests: pop 1000, 30 gens LOTS OF NOISE/LOTS OF FAILURE


"noise_1_probability_instruction_misheard":1,
"noise_1_probability_instruction_delayed": 0.3,
"noise_1_probability_instruction_delay_range":5,
"noise_1_probability_instruction_effort_range":5,
"noise_1_probability_instruction_drop_range":3,
"performance_failure_enabled":1,
"performance_failure_probability_exponent":2,
"performance_failure_effort_importance_multiplier":1,
"performance_failure_amount_exponent":2,
"performance_failure_base_max_percentage":1,
"rider_performance_failure_rate_max": 10,
"performance_failure_multiplier_max": 10,

-- would these tests not be better if each started with the same (random) population? I.e. I could save/reuse that population rather than recreate a new one every time? 

-- ok, entered results in the spreadsheet and all the times i tested match up, but how do I interpret them now?

-- tueday 9th
-- check what happens in each test to the best-after-30 race when I remove the noise/failure.

-- ok, go to overleaf and add a word

-- need to formalise the noise and failure expressions
=((POW(H5,H9)/POW($E5,H9)*H10 + POW(H6,H9)/POW($E6,H9) + POW(H7,H9)/POW($E7,H9))/(3+(H10-1))*(H8/$E8)

=((((POW(J5,J9)/POW($E5,J9))*J10 + POW(J6,J9)/POW($E6,J9) + + POW(J7,J9)/POW($E7,J9))/3))*(J8/$E8)

=(((POW(H5,H9)/POW($E5,H9)*H10 + POW(H6,H9)/POW($E6,H9) + POW(H7,H9)/POW($E7,H9))/(3+(H10-1)))*(H8/$E8))


E= current effort level , E_Max = max effort level
FE= Failure Exponent
Em = effort multiplier
Fc = current fatigue, Fc_Max = max fatigue level
Fa = accumulated fatgiue, Fa_Max = maxiumum accumulated fatigue
PFr = rider Performance Failure rate, PFr_MAx = maximum rider performance failure rate

Probability of Failure PFail =(((E^FE/Max_E^FE)*Em + (Fc^FE/Fc_Max^FE) + (Fa^FE/Fa_Max^FE))/(3+(Em-1))) * (PFr/PFr_Max)	

-- Monday Feb 15

-- also need the formula for the amount applied, which is currently the same (no randomness)
huh, it's basically the same (not in the excel so taking it from the code)
  let rider_performance_failure__percentage_amount = (
        (
            (
              (Math.pow(effort,performance_failure_amount_exponent)/Math.pow(effort_max,performance_failure_amount_exponent))*performance_failure_effort_importance_multiplier +
              (Math.pow(current_fatigue,performance_failure_amount_exponent)/Math.pow(current_fatigue_max,performance_failure_amount_exponent)) +
              (Math.pow(accumulated_fatigue,performance_failure_amount_exponent)/Math.pow(accumulated_fatigue_max,performance_failure_amount_exponent))
            )/(3+(performance_failure_effort_importance_multiplier-1))

        )
        * (rider_performance_failure_multiplier/rider_performance_failure_multiplier_max)
      );

FAE = Failure Amount Exponent
PFrA = Performance Failure rider amount, PFrA_MAX = maximum rider performance failure rate

Amount of Failure AFail =(((E^FAE/Max_E^FAE)*Em + (Fc^FAE/Fc_Max^FAE) + (Fa^FAE/Fa_Max^FAE))/(3+(Em-1))) * (PFrA/PFrA_MAX)

-- see can I build this into the overleaf doc
-- use fatigue level example for format
 \[ Fatigue\_level \mathrel{+}= F_r * ((P_c-P_t)/(P_m-P_t))^{F_e} \]
 
 failure prop: \[\frac{((E^{FE}/E\_max^{FE})*Em + (Fc^{FE}/Fc\_max^{FE}) + (Fa^{FE}/Fa\_max^{FE}))}{(3+(Em-1))} * (PFr/PFr\_max)\]
 
 failure amount: \[\frac{((E^{FE}/E\_max^{FAE})*Em + (Fc^{FAE}/Fc\_max^{FAE}) + (Fa^{FAE}/Fa\_max^{FAE}))}{(3+(Em-1))} * (PFrA/PFrA\_max)\]

-- ok, so have added these in, very awkward. now what? need to discuss what actually happens when the noise and failure are applied.

-- right, so one thign I need is a graph that has best-race-finish-time for each gen for a bunch of different noise settings (the ones I ran): might need a new page for this, or some way to select multiple results and get it to draw lines for all selected on the one display?

-- probs better to try extend the existing results page rather than a manual one, as it might be useful later on... 

-- also add a means to update the description of an experiment. at some stage also need delete powers

-- add a checkbox to the results list
-- add a second dropdown for multi-result graphs
-- add a function that spits out the selected ids (or error if none)

-- ok, after a goose chase, now have the ids loaded into an array - next will be to go get data for each and plot them all on the once graph. easy peasy :-)

-- Tuesday 16th Feb.

-- split into loading data and drawing graphs: assemble the data in an array piece by piece

-- will have to do some work to figure out the Y axis (max of all data points?)

-- could add a new endpoint in the node side that maps to the graph name and returns exactly what it needs (in one mongo call)?

-- ok, now it is calling an endpoint http://127.0.0.1:3003/best_fitness_per_generation/ for but gets back a 404 and displays the error: SyntaxError: Unexpected token < in JSON at position 0

-- now how do I get results for multiple IDs out of MongoDb?
-- from https://stackoverflow.com/questions/32264225/how-to-get-multiple-document-using-array-of-mongodb-id
-- db.getCollection('feed').find({"_id" : {"$in" : [ObjectId("55880c251df42d0466919268"), ObjectId("55bf528e69b70ae79be35006")]}});

-- but I only want part of the data, so need to do more wrapping here. let's first just hardcode in an id that works and try get back just the best fitness data for it

-- need to get ga_results . "generations":[{"best_race_time":1234.12,"stats_average_time":344.43}]

-- following https://docs.mongodb.com/manual/reference/method/db.collection.find/

-- testing using sample id in Robo3T
-- currently have db.getCollection('experiment_results').find({_id : ObjectId("60214201f3c3a51ad80674ba")},{_id:1,'ga_results':1})

-- huh, accessing nested objects in JS: https://www.tutorialspoint.com/safely-accessing-deeply-nested-values-in-javascript

-- Wednesday 17th Feb. Need to finish this graph muckery

-- only want to return best_race_time for each generation (for each id given)

-- ObjectId() not working, seems to be a Mongoose thing, which I am not using?

-- can access the ga_results but can't seem to get at the generations. console.log(Object.keys(documents[i])); works but console.log(Object.keys(documents[i].ga_results)); seems to contain half a million values starting with 0,1,2,...!

-- waiiittt a second- the muthafukka is a godamn string! ga_results, a big huge string, i.e. an array or chars, which is where all the keys ceomfrom. I have to convert the damn thing to an object using JSON.parse().
-- get rid of all the error checking (see how Object.keys() works
      if(documents[i].ga_results){
          console.log(i + " has ga_results property");
          if(i==0){
            console.log(Object.keys(documents[i]));
            console.log("race_settings keys");
            let rs = documents[i].race_settings;
            console.log(rs);
            //try6 to get start order
            let so = JSON.parse(rs);
            console.log(Object.keys(so));

            let ga_results = documents[i].ga_results;
            if (ga_results.generations){
              console.log(i + " has ga_results['generations'] property");
            }
          }

        }

-- ok, finally have data back on front end, tho it is not graphed and it is for a fixed set of two ids 
-- get these to graph before goign back to the node/mongo mess

-- now it draws two lines. but the object ids are actually hardcoded, and it is limited to 5 lines

-- yaya, it now uses the IDs that were sent. getting there

-- hard to see anything so change the min setting to be the min of the data mebbie minus 5 or 10?

-- big improvement with that, much more readable- should do the same for the old ones :-o 

-- to finish this graph I need headers, i.e. short bits of text to name each line. These should really be in the DB and shoud be editable from the page. Would need a simple enough endpoint that would just set the value
-- short_title:"No Noise/Lots of Failure"

-- Thursday 18th Feb

-- create new short title for graph, and make the notes editable

-- create a form in the results page that shows up when you click a results id
-- done, now need to populate the notes and short_title (new) line 894
-- create a new function updateResults() - first just get it to spit out the entries in the two new inputs

-- nice, this is now saving. need to display these in the main results table. note, after the update there is no refresh

-- ok, so they are in the table and I've set some, now need to return these short titles when graphing
-- added short_titles as new array at beginning of data returned, but need to remove this before tryign to draw the graph
-- use Array.from() to copy then x.splice(1) to take out the first element in x
-- woah, seemed to work first time

-- right, have a version of the graph now, put it into OverLeaf and finish that paragraph/section

-- added some lines, sent email, need to go back and add a basic conclusion and mebeeie a closer look at one of the best races with a form of noise, e.g. compare the final ones from failure only and noise only. could also redo the other graphs to flatten them a bit (start the y not at 100 but at min-10)

-- Mondee Feb 22nd

-- need to figure out that final section on overleaf where I describe the noise findings

-- are my notes on explaining the strategies in the noise/failure environments way out? look at the non-noise version. what if they differ little from it?

-- huh, the no noise race has an interesting piece - rider 1 accelerates early until it fails, then gets dropped, and at some point another rider takes the lead. note, this rider leads at a lower effort level as it takes the lead rider's power at point-of-switch as its target, and this is lower than the effort instruction dictates since that rider is failing now and slowing down to recover

-- run the no noise again for 30 gens and see is there any difference

-- a visual clue int eh game to show that a rider is failing/recovering would be useful. 

-- Tuesday 23rd.

-- ran multiple no noise GAs and they all drop in similar ways

-- run the Lots of Failure/No Noise GA again.

-- huh, the best race after 30 gens has a rider doing no time on the front at all.

-- try run 100 generations with lots of failure/no noise to see if it converges gradually on more equal leadership

-- wednesday 24th
-- 100 gens didn't converge much. try write up a conclusion then can do a lap of the whole paper aga9in	

-- ok, basic one written. leave it for a few minutes before re-reading

-- need to add the word 'elitist' into the description of the GA (elitism + tournament selection)? Elitism here means I am keeping the best chromosomes with no mutations.

-- what is Blotzmann selection? What is simulated annealing? : Approximate an optimum, when discovering it completely is too difficult.

-- moved the caveat about the power calculation and race start to the future directions section

-- Thursday 25th.

-- add elitism. 

- done. do the crossover new races also have mutation applied?

-- I have a setting there, crossover_apply_mutation_probability:0.5, so it's mutating 50% of the crossover children

-- Monday March 1. broken wrist 

-- need to try add more references about GAs

dota 2 
overwatch

C:\ProgramData\Anaconda3\Scripts\jupyter notebook

-- friday 9th

-- was supposed to work on this this week but did mostly data mining and the time just fecked off as usual

-- need to rejig the 'paper

-- added line numbers

-- added a bibtex file, 

-- copy those initial 2 refs into bibtex, leave in the samples

Craig, Neil \& Norton, Kevin. (2001). Characteristics of Track Cycling. Sports medicine (Auckland, N.Z.). 31. 457-68. 10.2165/00007256-200131070-00001. 
`
Craig NP, Norton KI. Characteristics of track cycling. . 2001;31(7):457-68. doi: 10.2165/00007256-200131070-00001. PMID: 11428683.

Whitley, D. A genetic algorithm tutorial. Stat Comput 4, 65â€“85 (1994). https://doi.org/10.1007/BF00175354


@article{craig,
    author = "Craig, N. P. \& Norton, K.I.",
    title = "Characteristics of track cycling",
    journal = "Sports medicine (Auckland, N.Z.)",
    volume = "31",
    number = "7",
    pages = "457-468",
    year = "2001",
    DOI = "10.2165/00007256-200131070-00001",
    keywords = "track cycling"
}


@article{whitley,
    author = "Whitley, D.",
    title = "A genetic algorithm tutorial",
    journal = "Statistics and Computing",
    volume = "4",
    number = "2",
    pages = "65-85",
    year = "1994",
    DOI = "10.1007/BF00175354",
    keywords = "genetic algorithm"
}



