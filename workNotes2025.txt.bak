-- June 4 2025.

- starting on Noise chapter.

- added text from Overleaf paper

- fixed issues with the grid of figures, but did that cause a problem elsewhere, 

-- issue was a clash between 
\usepackage{caption}
\usepackage{subcaption}

and

\usepackage{subfig}

- image refs not working, though other side-by-side images do display.

- do the citations work?

- citations ok, image refs nokay

- change all cite to parencite in the new chapter 


- can is use ground effect as an example of when a design that performs 'well' shoudl not be used due to other issues in the wider context?

"The Lotus 79, on the other hand, went on to win six races and the world championship for Mario Andretti and gave teammate Ronnie Peterson a posthumous second place, demonstrating just how much of an advantage the cars had. In the following years other teams copied and improved on the Lotus until cornering speeds became dangerously high, resulting in several severe accidents in 1982; flat undersides became mandatory for 1983.[14] Part of the danger of relying on ground effects to corner at high speeds is the possibility of the sudden removal of this force; if the underside of the car contacts the ground, the flow is constricted too much, resulting in almost total loss of any ground effects. If this occurs in a corner where the driver is relying on this force to stay on the track, its sudden removal can cause the car to abruptly lose most of its traction and skid off the track."


- robustness paper/section:

- 15 pages in Springer format, by June 26th,

- percolation and perturbation, useful context?

- notes from meeting June 5th 2025

- 1: create a 15 page paper on robustness material by June 26th 

- 2: email Colm next Monday with a shell of the document, and ask about meeting later next week about it. 

- 3: research the conference. ECTA. https://ecta.scitevents.org/ October 22-24, Marbella, Spain. 

- 


- starting paper. what email address should I use? My UG one is not a-working, so I can't use that to sign up?

-- Munday work on robustness 

- 1: add code to count and report on the number of mutant clones that actually have no mutations : compare their instructions and starting orders.

- count any change to the start order as 1 change. 

- checking to see if an array is inside an array usign includes() doesn't seem to do what I want it to, returns False, e.g. is [1,1] in [[1,1],[2,2]]

- write my own loop here?

- ok, it now counts changes, but I needs to test this. 

- also, this seems wrong: Average % that times worsens: 1

- should I keep or remove the clones? or only include actual variants? I think the latter? But do they need to be UNIQUE variants? or could i have copies, but not clones?

- adding new properties to use for the systematic instruction-by-instruction set of variations 

"ga_robustness_check_mutation_per_instruction_systematic":1,
"systematic_effort_values":[-5,-4,-3,-2,-1,-0.5,-0.25,-0.125,0,0.125,0.25,0.5,1,2,3,4,5],
"systematic_drop_values":[0,1,2,3],
"systematic_timestep_values":[-8,-7,-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8],
		
		
- should I be varying the starting order????
- should be an option?? 


archive of our own 
spy x family

- issue when trying to create the new arrays, getting confused, I guess my [...x] method doesdn't work 2 levels deep, so i need to use 
https://stackoverflow.com/questions/597588/how-do-you-clone-an-array-of-objects-in-javascript
const newArray = myArray.map(a => ({...a}));
	
-- that seemed to work, but does the test work in general?
0,1,2,3
[[5,"effort=8"]]


variations 
[instruction num,new value,start_order,instructions]

[[0,1,[0,1,2,3],[{"0":5,"1":"effort=7"}]],
[0,2,[0,1,2,3],[{"0":5,"1":"effort=9"}]],
[0,1,[0,1,2,3],[{"0":4,"1":"effort=8"}]],
[0,2,[0,1,2,3],[{"0":6,"1":"effort=8"}]]]

- inclue the type, and run for the full set of schedules 
- hmmm
Average % that times worsens: 1.01

[["drop",0,-5,[0,1,2,3],[[5,"effort=3"]]],["drop",0,-4,[0,1,2,3],[[5,"effort=4"]]],["drop",0,-3,[0,1,2,3],[[5,"effort=5"]]],["drop",0,-2,[0,1,2,3],[[5,"effort=6"]]],["drop",0,-1,[0,1,2,3],[[5,"effort=7"]]],["drop",0,-0.5,[0,1,2,3],[[5,"effort=7.5"]]],["drop",0,-0.25,[0,1,2,3],[[5,"effort=7.75"]]],["drop",0,-0.125,[0,1,2,3],[[5,"effort=7.875"]]],["drop",0,0,[0,1,2,3],[[5,"effort=8"]]],["drop",0,0.125,[0,1,2,3],[[5,"effort=8.125"]]],["drop",0,0.25,[0,1,2,3],[[5,"effort=8.25"]]],["drop",0,0.5,[0,1,2,3],[[5,"effort=8.5"]]],["drop",0,1,[0,1,2,3],[[5,"effort=9"]]],["drop",0,2,[0,1,2,3],[[5,"effort=10"]]],["drop",0,3,[0,1,2,3],[[5,"effort=11"]]],["drop",0,4,[0,1,2,3],[[5,"effort=12"]]],["drop",0,5,[0,1,2,3],[[5,"effort=13"]]],["drop",0,-8,[0,1,2,3],[[-3,"effort=8"]]],["drop",0,-7,[0,1,2,3],[[-2,"effort=8"]]],["drop",0,-6,[0,1,2,3],[[-1,"effort=8"]]],["drop",0,-5,[0,1,2,3],[[0,"effort=8"]]],["drop",0,-4,[0,1,2,3],[[1,"effort=8"]]],["drop",0,-3,[0,1,2,3],[[2,"effort=8"]]],["drop",0,-2,[0,1,2,3],[[3,"effort=8"]]],["drop",0,-1,[0,1,2,3],[[4,"effort=8"]]],["drop",0,0,[0,1,2,3],[[5,"effort=8"]]],["drop",0,1,[0,1,2,3],[[6,"effort=8"]]],["drop",0,2,[0,1,2,3],[[7,"effort=8"]]],["drop",0,3,[0,1,2,3],[[8,"effort=8"]]],["drop",0,4,[0,1,2,3],[[9,"effort=8"]]],["drop",0,5,[0,1,2,3],[[10,"effort=8"]]],["drop",0,6,[0,1,2,3],[[11,"effort=8"]]],["drop",0,7,[0,1,2,3],[[12,"effort=8"]]],["drop",0,8,[0,1,2,3],[[13,"effort=8"]]]]


-- have to make sure that no instruction 'overtakes' or 'undertakes' another, or goes over or under maximum allowed values


[["effort",0,-5,[0,1,2,3],[[5,"effort=3"]]],["effort",0,-4,[0,1,2,3],[[5,"effort=4"]]],["effort",0,-3,[0,1,2,3],[[5,"effort=5"]]],["effort",0,-2,[0,1,2,3],[[5,"effort=6"]]],["effort",0,-1,[0,1,2,3],[[5,"effort=7"]]],["effort",0,-0.5,[0,1,2,3],[[5,"effort=7.5"]]],["effort",0,-0.25,[0,1,2,3],[[5,"effort=7.75"]]],["effort",0,-0.125,[0,1,2,3],[[5,"effort=7.875"]]],["effort",0,0,[0,1,2,3],[[5,"effort=8"]]],["effort",0,0.125,[0,1,2,3],[[5,"effort=8.125"]]],["effort",0,0.25,[0,1,2,3],[[5,"effort=8.25"]]],["effort",0,0.5,[0,1,2,3],[[5,"effort=8.5"]]],["effort",0,1,[0,1,2,3],[[5,"effort=9"]]],["effort",0,2,[0,1,2,3],[[5,"effort=10"]]],["effort",0,3,[0,1,2,3],[[5,"effort=10"]]],["effort",0,4,[0,1,2,3],[[5,"effort=10"]]],["effort",0,5,[0,1,2,3],[[5,"effort=10"]]],["timestep",0,-8,[0,1,2,3],[[0,"effort=8"]]],["timestep",0,-7,[0,1,2,3],[[0,"effort=8"]]],["timestep",0,-6,[0,1,2,3],[[0,"effort=8"]]],["timestep",0,-5,[0,1,2,3],[[0,"effort=8"]]],["timestep",0,-4,[0,1,2,3],[[1,"effort=8"]]],["timestep",0,-3,[0,1,2,3],[[2,"effort=8"]]],["timestep",0,-2,[0,1,2,3],[[3,"effort=8"]]],["timestep",0,-1,[0,1,2,3],[[4,"effort=8"]]],["timestep",0,0,[0,1,2,3],[[5,"effort=8"]]],["timestep",0,1,[0,1,2,3],[[6,"effort=8"]]],["timestep",0,2,[0,1,2,3],[[7,"effort=8"]]],["timestep",0,3,[0,1,2,3],[[8,"effort=8"]]],["timestep",0,4,[0,1,2,3],[[9,"effort=8"]]],["timestep",0,5,[0,1,2,3],[[10,"effort=8"]]],["timestep",0,6,[0,1,2,3],[[11,"effort=8"]]],["timestep",0,7,[0,1,2,3],[[12,"effort=8"]]],["timestep",0,8,[0,1,2,3],[[13,"effort=8"]]]]

-- need to include the actual original instructions here in this raw_data? make it an object? otherwise it is too confusing?

{
	data_type: "systematic_variations",
	time_created: "2025-06-11 17:44 00",
	original_instructions: [],
	variations: []
}

-- seeeems to work, but oh so much to do 

original time 359.672

-- ooh, I need to inclue the TIME of each variation in the raw data


{"data_type":"systematic_variations","time_created":"2025-6-11 17:54:53","original_start_order":[0,1,2,3],"original_instructions":[[5,"effort=8"]],"variations":[["effort",0,-1,[0,1,2,3],[[5,"effort=7"]],358.701],["effort",0,1,[0,1,2,3],[[5,"effort=9"]],359.708],["timestep",0,-1,[0,1,2,3],[[4,"effort=8"]],359.283],["timestep",0,1,[0,1,2,3],[[6,"effort=8"]],360.041]]}

[[5,"effort=6"],[100,"drop=3"]]

- we want an instruction movement (timestep variation) to REPLACE another instruction if there is one already at its destination timestep.

- to delete an element from an array we can use splice()
splice(start, deleteCount)
e.g., 
let x = [1,2,3]
x.splice(1,1);
//x is now [1,3]

- changed it to first flag then delete in case it breaks array access 
- test 
[[5,"effort=6"],[4,"effort=4.3"]]

{"data_type":"systematic_variations","time_created":"2025-6-12 12:35:45","original_start_order":[0,1,2,3],"original_instructions":[[5,"effort=6"],[4,"effort=4.3"]],"variations":[[0,"effort",-1,[0,1,2,3],[[5,"effort=5"],[4,"effort=4.3"]],307.692],[0,"effort",1,[0,1,2,3],[[5,"effort=7"],[4,"effort=4.3"]],358.727],[0,"timestep",-1,[0,1,2,3],[[4,"effort=6"]],355.853],[0,"timestep",1,[0,1,2,3],[[6,"effort=6"],[4,"effort=4.3"]],355.831],[1,"effort",-1,[0,1,2,3],[[5,"effort=6"],[4,"effort=3.3"]],356.013],[1,"effort",1,[0,1,2,3],[[5,"effort=6"],[4,"effort=5.3"]],355.668],[1,"timestep",-1,[0,1,2,3],[[5,"effort=6"],[3,"effort=4.3"]],355.451],[1,"timestep",1,[0,1,2,3],[[5,"effort=4.3"]],324.953]]}

-- add the original finish time to the results object


- why is the rider so slow with [[5,"effort=6"]], that's no a huge effort, but they fail really quickly.

-- hmm, well they DO recover BUT they are not told to go fast again.

Average % that times differ by is not quote the right label... it's the average Time diff, not the average % diff. could include both?

- updated, ran all equal test, best in final 50 gen is 


let's compare first and last generation 

generation 1

2,0,3,1

[[0,"effort=5"],[19,"effort=6.36"],[24,"effort=6.6"],[33,"effort=3.8"],[35,"effort=6.62"],[49,"drop=3"],[63,"drop=1"],[67,"drop=3"],[94,"drop=1"],[113,"effort=6.24"],[125,"drop=3"],[142,"drop=1"],[153,"drop=3"],[154,"effort=6.38"],[156,"drop=2"],[201,"drop=1"],[227,"drop=3"],[264,"drop=1"]]


Instruction Mutation tests (version 2, SYSTEMATICK)
Original race finsih time: 276.446
Total variations run: 469
Average race time: 282.52n
% of races that are slower: 0.51
Average amount that times differ by: 6.35
Average % that times differ by: 0.02
Best strategy found: [2,0,3,1] / [[0,"effort=5"],[19,"effort=6.36"],[24,"effort=6.6"],[33,"effort=3.8"],[35,"effort=6.62"],[49,"drop=3"],[63,"drop=1"],[67,"drop=3"],[94,"drop=1"],[113,"effort=6.24"],[125,"drop=3"],[142,"drop=1"],[153,"drop=3"],[154,"effort=6.38"],[156,"drop=2"],[201,"drop=2"],[227,"drop=3"],[264,"drop=1"]] / 273.735
Worst strategy found: [2,0,3,1] / [[0,"effort=5"],[19,"effort=6.36"],[24,"effort=6.6"],[33,"effort=3.8"],[35,"effort=6.62"],[49,"drop=3"],[63,"drop=1"],[67,"drop=3"],[94,"drop=1"],[113,"effort=6.24"],[125,"drop=3"],[142,"drop=1"],[153,"drop=3"],[154,"effort=1.38"],[156,"drop=2"],[201,"drop=1"],[227,"drop=3"],[264,"drop=1"]] / 358.133


generation 50 

start order 
2,1,0,3

[[0,"effort=5.97"],[1,"effort=6.58"],[24,"effort=7.43"],[33,"effort=3.8"],[35,"effort=6.62"],[39,"drop=3"],[49,"drop=3"],[68,"drop=3"],[110,"drop=3"],[113,"effort=8.6"],[125,"drop=3"],[134,"effort=6.71"],[143,"drop=3"],[176,"drop=3"],[188,"drop=1"],[218,"drop=3"],[224,"drop=3"],[228,"effort=8.6"],[251,"drop=1"],[256,"effort=6.77"]]



instruction Mutation tests (version 2, SYSTEMATICK)
Original race finsih time: 262.212
Total variations run: 537
Average race time: 273.8
% of races that are slower: 0.64
Average amount that times differ by: 11.6
Average % that times differ by: 0.04
Best strategy found: [2,1,0,3] / [[0,"effort=5.97"],[1,"effort=6.58"],[24,"effort=7.43"],[33,"effort=3.8"],[35,"effort=6.62"],[39,"drop=3"],[49,"drop=3"],[68,"drop=3"],[110,"drop=3"],[113,"effort=8.6"],[125,"drop=3"],[134,"effort=6.71"],[143,"drop=3"],[176,"drop=3"],[188,"drop=1"],[218,"drop=3"],[224,"drop=3"],[228,"effort=8.1"],[251,"drop=1"],[256,"effort=6.77"]] / 261.884
Worst strategy found: [2,1,0,3] / [[0,"effort=5.97"],[1,"effort=6.58"],[24,"effort=10"],[33,"effort=3.8"],[35,"effort=6.62"],[39,"drop=3"],[49,"drop=3"],[68,"drop=3"],[110,"drop=3"],[113,"effort=8.6"],[125,"drop=3"],[134,"effort=6.71"],[143,"drop=3"],[176,"drop=3"],[188,"drop=1"],[218,"drop=3"],[224,"drop=3"],[228,"effort=8.6"],[251,"drop=1"],[256,"effort=6.77"]] / 323.544


-- renaming fittest_mutant_time_taken to best_mutant_time_taken
and smae for unfittest_mutant_time_taken to worst_mutant_time_taken

ran it for 200 gens 



GEN 1
3,2,1,0
[[0,"effort=5"],[12,"effort=6.12"],[29,"drop=2"],[92,"drop=3"],[164,"drop=3"],[185,"drop=2"],[192,"drop=2"],[200,"drop=1"],[201,"drop=2"]]

Random Mutant Robustness Check
Original race time taken 278.296
Mutants Created 2000
No. of direct clones 0
Mean instruct. changes made = 1.209
Max. instruct. changes made = 4 Strategy: Starting_order: [3,2,1,0], Instructions [[0,"effort=5"],[12,"effort=6.12"],[29,"drop=2"],[51,"effort=2.9"],[92,"drop=3"],[99,"drop=3"],[134,"drop=3"],[164,"drop=3"],[179,"drop=1"],[185,"drop=2"],[192,"drop=2"],[200,"drop=1"],[201,"drop=2"]]
Average race time 299.73881149999477
Std. Dev. of mutant race times 28.588499788008626
% of races that are slower: 0.6325
Average amount that times differ by: 21.489388499999965
Average % that times differ by: 0.07721774118205049
Best strategy found: [3,2,1,0] / [[0,"effort=5.78"],[12,"effort=6.12"],[29,"drop=2"],[92,"drop=3"],[131,"drop=1"],[164,"drop=3"],[192,"drop=2"],[200,"drop=1"],[201,"drop=2"]] / 276.906
Worst strategy found: [3,2,1,0] / [[0,"effort=5"],[12,"effort=6.12"],[24,"effort=1.05"],[29,"drop=2"],[92,"drop=3"],[164,"drop=3"],[185,"drop=2"],[192,"drop=2"],[200,"drop=1"],[201,"drop=2"]] / 517.432

Instruction Mutation tests (version 2, SYSTEMATICK)
Original race finish time: 278.296
Total variations run: 215
Average race time: 301.33
Std. deviation of variation race times: 31.23
% of races that are slower: 0.49
Average amount that times differ by: 23.05
Average % that times differ by: 0.08
Best strategy found: [3,2,1,0] / [[0,"effort=5"],[12,"effort=6.12"],[29,"drop=2"],[92,"drop=3"],[164,"drop=3"],[192,"drop=2"],[200,"drop=1"],[201,"drop=2"]] / 277.997
Worst strategy found: [3,2,1,0] / [[0,"effort=5"],[12,"effort=1.12"],[29,"drop=2"],[92,"drop=3"],[164,"drop=3"],[185,"drop=2"],[192,"drop=2"],[200,"drop=1"],[201,"drop=2"]] / 522.101


GEN 200 
2,0,1,3
[[0,"effort=4.28"],[1,"effort=6.96"],[3,"effort=7"],[5,"drop=1"],[27,"drop=3"],[41,"drop=3"],[46,"drop=3"],[76,"drop=3"],[93,"drop=2"],[119,"effort=6.88"],[126,"drop=3"],[148,"drop=3"],[164,"effort=7.28"],[167,"drop=3"],[174,"effort=7.11"],[177,"drop=3"],[194,"drop=3"],[200,"effort=8.42"],[208,"drop=3"],[229,"drop=3"],[231,"effort=9.52"],[235,"drop=1"]]

Random Mutant Robustness Check
Original race time taken 256.387
Mutants Created 2000
No. of direct clones 0
Mean instruct. changes made = 1.415
Max. instruct. changes made = 5 Strategy: Starting_order: [2,0,1,3], Instructions [[2,"effort=4.28"],[1,"effort=6.96"],[3,"effort=7"],[5,"drop=1"],[27,"drop=3"],[46,"drop=3"],[76,"drop=3"],[93,"drop=2"],[126,"drop=3"],[148,"drop=3"],[164,"effort=7.28"],[167,"drop=3"],[174,"effort=7.11"],[194,"drop=3"],[200,"effort=8.42"],[208,"drop=3"],[229,"drop=3"],[231,"effort=9.52"],[235,"drop=1"]]
Average race time 271.8458439999985
Std. Dev. of mutant race times 16.520881982105667
% of races that are slower: 0.862
Average amount that times differ by: 15.459354999999928
Average % that times differ by: 0.060296953433676574
Best strategy found: [2,0,1,3] / [[0,"effort=4.28"],[1,"effort=6.96"],[3,"effort=7"],[5,"drop=1"],[27,"drop=3"],[41,"drop=3"],[46,"drop=3"],[76,"drop=3"],[93,"drop=2"],[119,"effort=6.88"],[126,"drop=3"],[148,"drop=3"],[162,"effort=7.28"],[167,"drop=3"],[174,"effort=7.11"],[177,"drop=3"],[194,"drop=3"],[200,"effort=8.42"],[208,"drop=3"],[229,"drop=3"],[231,"effort=9.52"],[235,"drop=1"]] / 256.334
Worst strategy found: [2,0,1,3] / [[0,"effort=4.28"],[1,"effort=6.96"],[3,"effort=7"],[5,"drop=1"],[26,"effort=1.55"],[27,"drop=3"],[41,"drop=3"],[46,"drop=3"],[76,"drop=3"],[93,"drop=2"],[119,"effort=6.88"],[126,"drop=3"],[148,"drop=3"],[164,"effort=7.28"],[167,"drop=3"],[174,"effort=7.11"],[177,"drop=3"],[194,"drop=3"],[200,"effort=8.42"],[208,"drop=3"],[229,"drop=3"],[231,"effort=9.52"],[235,"drop=1"]] / 330.611

Instruction Mutation tests (version 2, SYSTEMATICK)
Original race finish time: 256.387
Total variations run: 566
Average race time: 265.35
Std. deviation of variation race times: 14.7
% of races that are slower: 0.71
Average amount that times differ by: 8.96
Average % that times differ by: 0.03
Best strategy found: [2,0,1,3] / [[0,"effort=4.28"],[1,"effort=6.96"],[3,"effort=7"],[5,"drop=1"],[27,"drop=3"],[41,"drop=3"],[46,"drop=3"],[76,"drop=3"],[93,"drop=2"],[119,"effort=6.88"],[126,"drop=3"],[148,"drop=3"],[164,"effort=7.28"],[167,"drop=3"],[174,"effort=7.11"],[177,"drop=3"],[194,"drop=3"],[200,"effort=8.42"],[208,"drop=3"],[229,"drop=3"],[231,"effort=9.645"],[235,"drop=1"]] / 256.287
Worst strategy found: [2,0,1,3] / [[0,"effort=4.28"],[1,"effort=6.96"],[3,"effort=2"],[5,"drop=1"],[27,"drop=3"],[41,"drop=3"],[46,"drop=3"],[76,"drop=3"],[93,"drop=2"],[119,"effort=6.88"],[126,"drop=3"],[148,"drop=3"],[164,"effort=7.28"],[167,"drop=3"],[174,"effort=7.11"],[177,"drop=3"],[194,"drop=3"],[200,"effort=8.42"],[208,"drop=3"],[229,"drop=3"],[231,"effort=9.52"],[235,"drop=1"]] / 332.904

- this could be a useful example, the early effort instruction is where the worst results are coming from... whereas the first effort instruction effect is protected, like Korean being protected by Japan from quakes?

- could use the example of needing different building regulations if close to the edge of a tectonic plate considered at risk of earthquakes.

- add another tidbit: the number of BETTER instructions found- many variants will be the same, phenotypically neutral. maybe include all three- they should sum to 1, a kind of check.


- what has the best mutant/variant done to improve?

original: [[0,"effort=4.28"],[1,"effort=6.96"],[3,"effort=7"],[5,"drop=1"],[27,"drop=3"],[41,"drop=3"],[46,"drop=3"],[76,"drop=3"],[93,"drop=2"],[119,"effort=6.88"],[126,"drop=3"],[148,"drop=3"],[164,"effort=7.28"],[167,"drop=3"],[174,"effort=7.11"],[177,"drop=3"],[194,"drop=3"],[200,"effort=8.42"],[208,"drop=3"],[229,"drop=3"],[231,"effort=9.52"],[235,"drop=1"]] / 256.387
mutant: [[0,"effort=4.28"],[1,"effort=6.96"],[3,"effort=7"],[5,"drop=1"],[27,"drop=3"],[41,"drop=3"],[46,"drop=3"],[76,"drop=3"],[93,"drop=2"],[119,"effort=6.88"],[126,"drop=3"],[148,"drop=3"],[162,"effort=7.28"],[167,"drop=3"],[174,"effort=7.11"],[177,"drop=3"],[194,"drop=3"],[200,"effort=8.42"],[208,"drop=3"],[229,"drop=3"],[231,"effort=9.52"],[235,"drop=1"]] / 256.334 difference is [162,"effort=7.28"], moved it back from 164
variant: [[0,"effort=4.28"],[1,"effort=6.96"],[3,"effort=7"],[5,"drop=1"],[27,"drop=3"],[41,"drop=3"],[46,"drop=3"],[76,"drop=3"],[93,"drop=2"],[119,"effort=6.88"],[126,"drop=3"],[148,"drop=3"],[164,"effort=7.28"],[167,"drop=3"],[174,"effort=7.11"],[177,"drop=3"],[194,"drop=3"],[200,"effort=8.42"],[208,"drop=3"],[229,"drop=3"],[231,"effort=9.645"],[235,"drop=1"]] / 256.287 difference is [231,"effort=9.645"]

if I run it for 500 generations will these improvements disappear?

500 gen experiment is not saving 
  errmsg: 'BSONObj size: 17,149,943 (0x105AFF7) is invalid. Size must be between 0 and 16,793,600(16MB) First element: insert: "experiment_results"',
  code: 10334,
  
 - doesn't seem like something I can easily change :-( 
 
 "The maximum document size helps ensure that a single document cannot use an excessive amount of RAM or, during transmission, an excessive amount of bandwidth. To store documents larger than the maximum size, MongoDB provides the GridFS API. For more information about GridFS, see mongofiles and the documentation for your driver" 
 
 limit is probs between 400 and 450 gens? pop is 2000. 
 
 - final strat after 500 gens is this:
 
 2,1,0,3
 [[1,"effort=7.37"],[22,"drop=3"],[26,"drop=2"],[39,"drop=2"],[40,"drop=2"],[60,"drop=3"],[61,"drop=3"],[65,"effort=7.42"],[76,"drop=3"],[83,"effort=8.24"],[90,"drop=1"],[92,"drop=2"],[97,"effort=9.57"],[98,"effort=9.91"],[102,"effort=6.81"],[103,"effort=6.99"],[105,"effort=6.99"],[113,"drop=2"],[114,"drop=3"],[124,"drop=3"],[142,"drop=1"],[171,"drop=3"],[175,"drop=2"],[206,"drop=3"],[218,"drop=3"],[224,"effort=9.9"],[231,"effort=4.8"],[232,"effort=10"],[235,"drop=1"],[236,"effort=7.54"],[237,"effort=9.37"],[246,"effort=9.22"],[247,"drop=2"],[249,"drop=1"],[253,"drop=3"]] 254.995
 
 nice, so the robustness tests can no longer really improve things. 
 
 Check results:
Random Mutant Robustness Check
Original race time taken 254.995
Mutants Created 2000
No. of direct clones 0
Mean instruct. changes made = 1.6635
Max. instruct. changes made = 6 Strategy: Starting_order: [0,1,2,3], Instructions [[1,"effort=7.37"],[22,"drop=3"],[26,"drop=2"],[39,"drop=2"],[40,"drop=2"],[60,"drop=3"],[61,"drop=3"],[65,"effort=7.42"],[76,"drop=3"],[83,"effort=8.24"],[90,"drop=1"],[92,"drop=2"],[97,"effort=9.57"],[104,"effort=6.81"],[103,"effort=6.99"],[107,"effort=6.99"],[113,"drop=2"],[114,"drop=3"],[124,"drop=3"],[142,"drop=1"],[171,"drop=3"],[175,"drop=2"],[206,"drop=3"],[218,"drop=3"],[231,"effort=4.8"],[232,"effort=10"],[236,"effort=7.54"],[237,"effort=9.37"],[246,"effort=9.22"],[247,"drop=2"],[249,"drop=1"],[253,"drop=3"]]
Average race time 289.41942800000027
Std. Dev. of mutant race times 26.979523899391207
% of races that are slower/the same/faster (total): 0.88 / 0.12 / undefined (NaN %)
Average amount that times differ by: 34.42442799999983
Average % that times differ by: 0.1350004039294881
Best strategy found: [0,1,2,3] / [[1,"effort=7.37"],[22,"drop=3"],[26,"drop=2"],[36,"drop=2"],[40,"drop=2"],[60,"drop=3"],[61,"drop=3"],[65,"effort=7.42"],[76,"drop=3"],[83,"effort=8.24"],[90,"drop=1"],[92,"drop=2"],[97,"effort=9.57"],[98,"effort=9.91"],[102,"effort=6.81"],[103,"effort=6.99"],[105,"effort=6.99"],[113,"drop=2"],[114,"drop=3"],[124,"drop=3"],[142,"drop=1"],[171,"drop=3"],[175,"drop=2"],[206,"drop=3"],[218,"drop=3"],[224,"effort=9.9"],[231,"effort=4.8"],[232,"effort=10"],[235,"drop=1"],[236,"effort=7.54"],[237,"effort=9.37"],[246,"effort=9.22"],[249,"drop=1"],[253,"drop=3"]] / 254.995
Worst strategy found: [0,1,2,3] / [[22,"drop=3"],[26,"drop=2"],[39,"drop=2"],[40,"drop=2"],[60,"drop=3"],[61,"drop=3"],[65,"effort=7.42"],[76,"drop=3"],[83,"effort=8.24"],[90,"drop=1"],[92,"drop=2"],[97,"effort=9.57"],[98,"effort=9.91"],[102,"effort=6.81"],[103,"effort=6.99"],[105,"effort=6.99"],[113,"drop=2"],[124,"drop=3"],[142,"drop=1"],[153,"effort=1.04"],[171,"drop=3"],[175,"drop=2"],[206,"drop=3"],[218,"drop=3"],[224,"effort=9.9"],[231,"effort=4.8"],[232,"effort=10"],[235,"drop=1"],[236,"effort=7.54"],[237,"effort=9.37"],[246,"effort=9.22"],[247,"drop=2"],[249,"drop=1"],[253,"drop=3"]] / 364.382

Instruction Mutation tests (version 2, SYSTEMATICK)
Original race finish time: 254.995
Total variations run: 1001
Average race time: 288.95
Std. deviation of variation race times: 26.74
% of races that are slower/the same/faster (total): 0.86 / 0.14 / 0(100 %)
Average amount that times differ by: 33.96
Average % that times differ by: 0.13
Best strategy found: [0,1,2,3] / [[1,"effort=7.37"],[22,"drop=3"],[26,"drop=2"],[39,"drop=2"],[40,"drop=2"],[60,"drop=3"],[61,"drop=3"],[65,"effort=7.42"],[76,"drop=3"],[83,"effort=8.24"],[90,"drop=1"],[92,"drop=2"],[97,"effort=9.57"],[98,"effort=9.91"],[102,"effort=6.81"],[103,"effort=6.99"],[105,"effort=6.99"],[113,"drop=2"],[114,"drop=3"],[124,"drop=3"],[142,"drop=1"],[171,"drop=3"],[175,"drop=2"],[206,"drop=3"],[218,"drop=3"],[224,"effort=9.9"],[231,"effort=4.8"],[232,"effort=10"],[235,"drop=1"],[236,"effort=7.54"],[237,"effort=9.37"],[247,"effort=9.22"],[249,"drop=1"],[253,"drop=3"]] / 254.994
Worst strategy found: [0,1,2,3] / [[1,"effort=2.37"],[22,"drop=3"],[26,"drop=2"],[39,"drop=2"],[40,"drop=2"],[60,"drop=3"],[61,"drop=3"],[65,"effort=7.42"],[76,"drop=3"],[83,"effort=8.24"],[90,"drop=1"],[92,"drop=2"],[97,"effort=9.57"],[98,"effort=9.91"],[102,"effort=6.81"],[103,"effort=6.99"],[105,"effort=6.99"],[113,"drop=2"],[114,"drop=3"],[124,"drop=3"],[142,"drop=1"],[171,"drop=3"],[175,"drop=2"],[206,"drop=3"],[218,"drop=3"],[224,"effort=9.9"],[231,"effort=4.8"],[232,"effort=10"],[235,"drop=1"],[236,"effort=7.54"],[237,"effort=9.37"],[246,"effort=9.22"],[247,"drop=2"],[249,"drop=1"],[253,"drop=3"]] / 341.881

- look at the storage of generation-by-generation results.

- these are the current robustness check properties saved:
		generation_results.robustness_check_number_of_mutants = settings_r.robustness_check_population_size;
generation_results.robustness_check_average_mutant_time_taken = robustness_check_results.average_mutant_time_taken;
generation_results.robustness_check_standard_dev = robustness_check_results.robustness_check_standard_dev;
generation_results.robustness_check_best_mutant_time_taken = robustness_check_results.best_mutant_time_taken;
generation_results.robustness_check_worst_mutant_time_taken = robustness_check_results.worst_mutant_time_taken;

generation_results.robustness_single_mutation_qty = robustness_result.robustness_single_mutation_qty;
generation_results.robustness_single_mutation_average = robustness_result.robustness_single_mutation_average;
generation_results.robustness_single_mutation_times = robustness_result.robustness_single_mutation_times;

- need to save a lot more, for both kinds of robustness measure. 

- hmmmm, so the robustness results object has two parts now,
robustness_result.mutations.original_time_taken = original_time_taken;
robustness_result.mutations.average_mutant_time_taken = mutantMeanTime;
robustness_result.mutations.average_mutant_changes = mutantMeanChanges; //donalK25: june, added to also track some view of variation
robustness_result.mutations.worst_mutant_time_taken = worst_mutant_time_taken;
robustness_result.mutations.best_mutant_time_taken = best_mutant_time_taken;
robustness_result.mutations.robustness_check_standard_dev = mutantStdDev;
robustness_result.mutations.robustness_percentage_of_slower_mutants = DecimalPrecision.round(robustness_count_of_slower_mutants/population_stats.length,2);
robustness_result.mutations.robustness_percentage_of_equal_time_mutants = DecimalPrecision.round(robustness_percentage_of_equal_time_mutants/population_stats.length,2);
robustness_result.mutations.robustness_percentage_of_faster_mutants = DecimalPrecision.round(robustness_percentage_of_faster_mutants/population_stats.length,2);
robustness_result.mutations.robustness_mutant_average_time_difference = sum_of_mutant_time_differences/population_stats.length;
robustness_result.mutations.robustness_mutation_average_percentage_difference = sum_of_mutant_percentage_differences/population_stats.length;
robustness_result.mutations.best_mutant_start_order = best_mutant_start_order;
robustness_result.mutations.best_mutant_instructions = best_mutant_instructions;
robustness_result.mutations.worst_mutant_start_order = worst_mutant_start_order;
robustness_result.mutations.worst_mutant_instructions = worst_mutant_instructions;
robustness_result.mutations.mutant_times = population_stats;
	
	and
	
	
	robustness_result.variations.original_time_taken = return_data.original_time_taken;
  robustness_result.variations.robustness_variations_run = robustness_single_mutation_times_systematic.length;
  robustness_result.variations.robustness_average_variation_time = average_variation_time;
  robustness_result.variations.robustness_best_variation_time = best_found_time;
  robustness_result.variations.robustness_worst_variation_time = worst_found_time;
  robustness_result.variations.variationStdDev = variationStdDev;
  robustness_result.variations.robustness_percentage_of_slower_variants = DecimalPrecision.round(count_of_slower_variants / robustness_single_mutation_times_systematic.length,2);
  robustness_result.variations.robustness_percentage_of_faster_variants = DecimalPrecision.round(count_of_faster_variants / robustness_single_mutation_times_systematic.length,2);
  robustness_result.variations.robustness_percentage_of_equal_time_variants = DecimalPrecision.round(count_of_equal_time_variants / robustness_single_mutation_times_systematic.length,2);
  robustness_result.variations.robustness_single_mutation_average_time_difference = average_time_difference;
  robustness_result.variations.robustness_single_mutation_average_percentage_difference = average_percentage_difference;
  robustness_result.variations.robustness_single_mutation_times_systematic = JSON.stringify(robustness_single_mutation_times_systematic);
  robustness_result.variations.best_found_start_order = best_found_start_order;
  robustness_result.variations.best_found_instructions = best_found_instructions;
  robustness_result.variations.worst_found_start_order = worst_found_start_order;
  robustness_result.variations.worst_found_instructions = worst_found_instructions;

- maybe I can just add these entire objects? 

- added 
		generation_results.robustness_mutation_results = {};
  generation_results.robustness_variation_results = {};
  generation_results.message = "";

		
		
- runs, i think, but very slow, too many console log lines

- ok, it kinda wurks.

- needs to include the average fitness per generation 
- the y scale is off 

- need to get the min value to set a useful y axis 

e.g. 


var min_all_data = d3.min(data, function(array) {
  return d3.min(array);
});
// y axis scale from min of data
graph_data_1.y_scale_from = min_all_data-5;
			

names of the two graphs (in the code)
- best_fitness_robustness_check
- robustness_instruction_variation_times

- where is the best race time per gen stored?

selected_ga_results.generations[i].best_race_time

- add this to the robustness_instruction_variation_times graph

in the test, there's a big improvement in average mutant/variant scores in generation 49. could be worth exploring what happens?

gen 48
time:
263.643

start order:
2,1,0,3

instructions:
[[0,"effort=9.46"],[24,"drop=2"],[26,"drop=3"],[27,"effort=6.07"],[38,"drop=3"],[41,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[97,"drop=3"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=2"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]]

results:
	Random Mutant Robustness Check
	Original race time taken 263.643
	Mutants Created 2000
	No. of direct clones 0
	Mean instruct. changes made = 1.4075
	Max. instruct. changes made = 4 Strategy: Starting_order: [2,1,0,3], Instructions [[24,"drop=2"],[26,"drop=3"],[27,"effort=6.07"],[38,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=1"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]]
	Average race time 284.94021649999985
	Std. Dev. of mutant race times 19.174048597508733
	% of races that are slower/the same/faster (total): 0.78 / 0.2 / undefined (NaN %)
	Average amount that times differ by: 21.30328649999998
	Average % that times differ by: 0.08080353546272813
	Best strategy found: [2,1,0,3] / [[0,"effort=9.46"],[24,"drop=2"],[26,"drop=3"],[27,"effort=6.39"],[38,"drop=3"],[41,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[97,"drop=3"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=2"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]] / 262.481
	Worst strategy found: [2,1,0,3] / [[0,"effort=9.46"],[24,"drop=2"],[26,"drop=3"],[27,"effort=6.07"],[34,"effort=9.58"],[38,"drop=3"],[41,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[97,"drop=3"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=2"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]] / 327.2

	Instruction Mutation tests (version 2, SYSTEMATICK)
	Original race finish time: 263.643
	Total variations run: 576
	Average race time: 286.59
	Std. deviation of variation race times: 20.74
	% of races that are slower/the same/faster (total): 0.77 / 0.19 / 0.04(100 %)
	Average amount that times differ by: 22.97
	Average % that times differ by: 0.09
	Best strategy found: [2,1,0,3] / [[0,"effort=9.46"],[24,"drop=2"],[26,"drop=3"],[27,"effort=6.32"],[38,"drop=3"],[41,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[97,"drop=3"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=2"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]] / 262.717
	Worst strategy found: [2,1,0,3] / [[0,"effort=9.46"],[24,"drop=2"],[26,"drop=3"],[27,"effort=1.0700000000000003"],[38,"drop=3"],[41,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[97,"drop=3"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=2"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]] / 332.264

gen 49
time:
262.546

start order:
3,1,0,2

instructions:
[[0,"effort=5"],[3,"effort=6.51"],[34,"drop=2"],[48,"effort=6.25"],[52,"drop=3"],[63,"effort=7.11"],[83,"drop=3"],[86,"drop=3"],[125,"drop=3"],[136,"drop=2"],[150,"effort=6.64"],[156,"drop=2"],[179,"drop=2"],[189,"drop=2"],[207,"drop=1"],[216,"effort=9.62"],[220,"drop=3"],[230,"effort=6.71"],[232,"drop=3"],[247,"effort=6.56"],[253,"effort=6.41"],[262,"drop=1"]]	

results:
	Random Mutant Robustness Check
	Original race time taken 262.546
	Mutants Created 2000
	No. of direct clones 0
	Mean instruct. changes made = 1.4075
	Max. instruct. changes made = 5 Strategy: Starting_order: [3,1,0,2], Instructions [[0,"effort=5"],[34,"drop=2"],[48,"effort=6.25"],[52,"drop=3"],[63,"effort=7.11"],[83,"drop=3"],[86,"drop=3"],[104,"drop=2"],[136,"drop=2"],[150,"effort=6.34"],[156,"drop=2"],[179,"drop=2"],[189,"drop=2"],[207,"drop=1"],[216,"effort=9.62"],[220,"drop=3"],[230,"effort=6.71"],[232,"drop=3"],[262,"drop=1"]]
	Average race time 272.66472249999856
	Std. Dev. of mutant race times 10.928411278428976
	% of races that are slower/the same/faster (total): 0.82 / 0.09 / undefined (NaN %)
	Average amount that times differ by: 10.144790500000049
	Average % that times differ by: 0.03864004974366405
	Best strategy found: [3,1,0,2] / [[0,"effort=5"],[3,"effort=6.51"],[34,"drop=2"],[48,"effort=6.31"],[52,"drop=3"],[63,"effort=7.11"],[83,"drop=3"],[86,"drop=3"],[125,"drop=3"],[136,"drop=2"],[150,"effort=6.64"],[156,"drop=2"],[179,"drop=2"],[189,"drop=2"],[207,"drop=1"],[216,"effort=10"],[220,"drop=3"],[230,"effort=6.71"],[232,"drop=3"],[247,"effort=6.56"],[253,"effort=6.41"],[262,"drop=1"]] / 262.068
	Worst strategy found: [3,1,0,2] / [[0,"effort=5"],[3,"effort=7.36"],[34,"drop=2"],[48,"effort=6.25"],[52,"drop=3"],[63,"effort=7.11"],[83,"drop=3"],[86,"drop=3"],[125,"drop=3"],[136,"drop=2"],[150,"effort=6.64"],[156,"drop=2"],[179,"drop=2"],[189,"drop=2"],[207,"drop=1"],[216,"effort=9.62"],[220,"drop=3"],[230,"effort=6.71"],[232,"drop=3"],[247,"effort=6.56"],[253,"effort=6.41"],[262,"drop=1"]] / 323.816

	Instruction Mutation tests (version 2, SYSTEMATICK)
	Original race finish time: 262.546
	Total variations run: 633
	Average race time: 269.94
	Std. deviation of variation race times: 8.95
	% of races that are slower/the same/faster (total): 0.76 / 0.13 / 0.11(100 %)
	Average amount that times differ by: 7.44
	Average % that times differ by: 0.03
	Best strategy found: [3,1,0,2] / [[0,"effort=5"],[3,"effort=6.51"],[34,"drop=2"],[48,"effort=6.25"],[52,"drop=3"],[63,"effort=7.11"],[83,"drop=3"],[86,"drop=3"],[125,"drop=3"],[136,"drop=2"],[150,"effort=6.64"],[156,"drop=2"],[179,"drop=2"],[189,"drop=2"],[207,"drop=1"],[216,"effort=9.62"],[220,"drop=3"],[230,"effort=6.71"],[232,"drop=3"],[247,"effort=10"],[253,"effort=6.41"],[262,"drop=1"]] / 261.666
	Worst strategy found: [3,1,0,2] / [[0,"effort=5"],[3,"effort=1.5099999999999998"],[34,"drop=2"],[48,"effort=6.25"],[52,"drop=3"],[63,"effort=7.11"],[83,"drop=3"],[86,"drop=3"],[125,"drop=3"],[136,"drop=2"],[150,"effort=6.64"],[156,"drop=2"],[179,"drop=2"],[189,"drop=2"],[207,"drop=1"],[216,"effort=9.62"],[220,"drop=3"],[230,"effort=6.71"],[232,"drop=3"],[247,"effort=6.56"],[253,"effort=6.41"],[262,"drop=1"]] / 306.938


Something is dramatically improving in terms of robustness, but what- if I can visualize the instruction-by-instruction view then maybe that would be a result?

- bug, delte flag thingy in variations is trying to delete itself, doesn't check for that case.


- hmmmmmm, seems to work, kinda. run it for a simple test strategy 



0,1,2,3
[[5,"effort=6"]]

add a drop 

[[5,"effort=6"],[45,"drop=3"]]


-- % of races that are slower/the same/faster (total): 0.78 / 0.21 / undefined (NaN %) hmmmmmmmmmm, maybe not being set to 0 props?

- spend one hour writing, if possible

- reading about robustness, e.g., https://en.wikipedia.org/wiki/Robust_optimization

- "The term “robust optimization” has come to encompass several approaches to protecting the decision-maker against parameter ambiguity and stochastic uncertainty. " from "Recent advances in robust optimization: An overview", 2014

- "The main paradigm relies on worst-case analysis: a solution is evaluated using the realization of the uncertainty that is most unfavorable."

- could i mention redundancies in the biological world, i.e., mechanisms to improve the stability of key genotype-to-phenotype relationships under the pressure of variance.

- run a one-strong race and see if the robustness looks any different

- but first, try and figure out the weird uppy downy irreuglar times with the robustness tests

- run the graph for the first few instructions? 

- shite, i get different answer than the data :-( something be UP 

- edit the 2nd effort instruction

- run from the interface
[[0,"effort=9.46"],[24,"drop=2"],[26,"drop=3"],[32,"effort=6.07"],[38,"drop=3"],[41,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[97,"drop=3"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=2"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]], 310.137	

- the result from the automated tests
[[0,"effort=9.46"],[24,"drop=2"],[26,"drop=3"],[32,"effort=6.07"],[38,"drop=3"],[41,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[97,"drop=3"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=2"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]],311.959

- tey another
- from interface 
[[0,"effort=9.46"],[24,"drop=2"],[26,"drop=3"],[33,"effort=6.07"],[38,"drop=3"],[41,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[97,"drop=3"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=2"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]]	  309.965

- from results 
[[0,"effort=9.46"],[24,"drop=2"],[26,"drop=3"],[33,"effort=6.07"],[38,"drop=3"],[41,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[97,"drop=3"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=2"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]],309.965

debug the darn thing with a specfic catch IF
- in the debug I get 311.959. I feel like... something is NOT being reset or something?
collect the start order and array and double-check the discrepancy 

2,1,0,3

[[0,"effort=9.46"],[24,"drop=2"],[26,"drop=3"],[32,"effort=6.07"],[38,"drop=3"],[41,"drop=3"],[53,"drop=2"],[59,"drop=3"],[79,"effort=6.91"],[97,"drop=3"],[109,"drop=3"],[135,"drop=1"],[136,"drop=2"],[166,"drop=1"],[196,"effort=5.72"],[212,"drop=2"],[216,"drop=2"],[217,"drop=2"],[234,"effort=9.84"],[240,"effort=7.81"],[241,"drop=2"],[262,"drop=2"]] 310.137

so, something not reset??

--hmmmmm 

  "endurance_fatigue_level": 152.40261952900374,
        "accumulated_fatigue": 877.3492328353756,
		
		    "distance_covered": 4008.114278076573,

- naw, these are reset.... frontal_area_adjusted_for_shelter isn't... should remove it altogether tbh.


-nope, still 311.959

- ok, logging everything. it is running a DROP = 2 instruction at timestep 5... where the heck is this coming from??

- ok, so race_r.drop_instruction = drop_value; is run but it is NOT being rest, and the previous run of the race finishes with an un-run drop=2 instruction, sooooooo, i think i found the problem.

- 310.137
- got it. nasty murk of a bug :-( 

- now, remove the specific debugging code, but first test a few other alterations?

- or, first, generate the graph again... still oscillating?

- run another run of the main experiment, maybe the stats were OFF because of that problem?

Best R.M. label is wrong on the R.R/I.V graph

Align the colours better in both graphs 

- still finding improvements in the robustness tests 
original
[[0,"effort=5"],[3,"effort=5.87"],[21,"effort=7.84"],[38,"drop=2"],[40,"effort=6.31"],[74,"drop=3"],[85,"effort=7.65"],[91,"effort=6.81"],[104,"drop=3"],[133,"drop=2"],[134,"drop=2"],[176,"drop=2"],[209,"drop=3"],[224,"effort=8.06"],[235,"drop=2"]]	
best I.V. a timestep change at [78,"effort=7.65"]
[[0,"effort=5"],[3,"effort=5.87"],[21,"effort=7.84"],[38,"drop=2"],[40,"effort=6.31"],[74,"drop=3"],[78,"effort=7.65"],[91,"effort=6.81"],[104,"drop=3"],[133,"drop=2"],[134,"drop=2"],[176,"drop=2"],[209,"drop=3"],[224,"effort=8.06"],[235,"drop=2"]]  262.46



new call to get data for selected generation of both robustness times 
let selectedGeneration = parseInt($('#selectedGeneration').val());

what data am I looking for 

robustness_mutation_results.mutant_times = population_stats;
robustness_variation_results.robustness_single_mutation_times_systematic

- data being returned now - add the generation 

- graph now showing... would be good to include the actual best time.




University of Galway,
University Road,
Galway, Ireland
H91 TK33
T. +353 91 524411

woah, "7) Have you ever been denied a U.S. visa you applied for with your current or previous passport, or have you ever been refused admission to the United States or withdrawn your application for admission at a U.S. port of entry?"

8) Have you traveled to, or been present in Cuba, Iran, Iraq, Libya, North Korea, Somalia, Sudan, Syria or Yemen on or after March 1, 2011?

I have read and understand that I hereby waive for the duration of my travel authorization obtained via ESTA any rights to review or appeal of a U.S. Customs and Border Protection Officer's determination as to my admissibility, or to contest, other than on the basis of an application for asylum, any removal action arising from an application for admission under the Visa Waiver Program.

In addition to the above waiver, as a condition of each admission into the United States under the Visa Waiver Program, I agree that the submission of biometric identifiers (including fingerprints and photographs) during processing upon arrival in the United States shall reaffirm my waiver of any rights to review or appeal of a U.S. Customs and Border Protection Officer's determination as to my admissibility, or to contest, other than on the basis of an application for asylum, any removal action arising from an application for admission under the Visa Waiver Program.


gen 1 time 		281.716
gen 199 time 	257.128 

difference = 281.716 - 257.128 = 24.588 

- make a table 

\begin{table}[h]
\caption{Caption text}\label{tab1}%
\begin{tabular}{@{}llll@{}}
\toprule
Measure & Gen. 1 & Gen. 10 & Gen. 199\\
\midrule
Original Race Time    & data 1   & data 2  & 257.128  \\
Mean instruct. changes    & data 4   & data 5\footnotemark[1]  & 1.4555  \\
Max. instruct. changes made    & data 7   & data 8  & 5  \\
Average race time & XXXX & YYY & 275.8 \\
Std. Dev. e & XXXX & YYY &  17.27 \\
% of slower races  & XXXX & YYY &  0.81 \\
% of equal-time races  & XXXX & YYY &  0.17  \\
% of faster races  & XXXX & YYY &  0.02  \\
Average amount that times differ by  & XXXX & YYY &  18.67  \\
Average % that times differ by  & XXXX & YYY &  0.073  \\
Best Time found  & XXXX & YYY &  256.749  \\
Worst Time found  & XXXX & YYY &  336.322  \\

\botrule
\end{tabular}
\end{table} 

- added wost RM to graph, but its a bit tooo scale-warpy, can't read anything else now.

- need to compare 2 gens where robustness changes a lot 

- experiment id: 
-gen 105
time 246.039
0,1,3,2
[[0,"effort=5"],[4,"effort=7.12"],[22,"drop=1"],[37,"effort=5.98"],[43,"drop=1"],[64,"drop=2"],[78,"drop=2"],[81,"drop=1"],[83,"effort=6.92"],[85,"effort=9.67"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=1"],[111,"drop=2"],[121,"drop=3"],[144,"drop=3"],[147,"effort=9.24"],[149,"effort=6.49"],[167,"drop=2"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[207,"drop=1"]]	

Random Mutant Robustness Check
Original race time taken 246.039
Mutants Created 2000
No. of direct clones 0
Mean instruct. changes made = 1.443
Max. instruct. changes made = 5 Strategy: Starting_order: [0,1,3,2], Instructions [[0,"effort=5"],[4,"effort=7.12"],[22,"drop=1"],[37,"effort=5.98"],[43,"drop=1"],[78,"drop=2"],[81,"drop=1"],[83,"effort=6.92"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=1"],[111,"drop=2"],[121,"drop=3"],[144,"drop=3"],[148,"effort=9.24"],[149,"effort=6.49"],[186,"drop=1"],[202,"effort=7.3"],[207,"drop=1"]]
Average race time 267.012368
Std. Dev. of mutant race times 18.31228082054703
% of races that are slower/the same/faster (total): 0.85 / 0.13 / 0.02 (100 %)
Average amount that times differ by: 20.975879000000045
Average % that times differ by: 0.08525428488979375
Best strategy found: [0,1,3,2] / [[0,"effort=5"],[4,"effort=7.12"],[22,"drop=1"],[37,"effort=5.98"],[43,"drop=1"],[64,"drop=2"],[78,"drop=2"],[81,"drop=1"],[83,"effort=6.92"],[85,"effort=9.67"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=1"],[111,"drop=2"],[121,"drop=3"],[144,"drop=3"],[147,"effort=9.24"],[149,"effort=6.49"],[167,"drop=2"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[207,"drop=1"],[224,"effort=8.48"]] / 245.817
Worst strategy found: [0,2,1,3] / [[4,"effort=7.12"],[22,"drop=1"],[37,"effort=5.98"],[43,"drop=1"],[64,"drop=2"],[78,"drop=2"],[81,"drop=1"],[83,"effort=6.92"],[85,"effort=9.67"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=1"],[111,"drop=2"],[121,"drop=3"],[144,"drop=3"],[147,"effort=9.24"],[149,"effort=6.49"],[167,"drop=2"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[206,"drop=1"]] / 324.061

Instruction Mutation tests (version 2, SYSTEMATICK)
Original race finish time: 246.039
Total variations run: 838
Average race time: 263.89
Std. deviation of variation race times: 17.52
% of races that are slower/the same/faster (total): 0.71 / 0.23 / 0.05(99 %)
Average amount that times differ by: 17.85
Average % that times differ by: 0.07
Best strategy found: [0,1,3,2] / [[0,"effort=5"],[4,"effort=7.12"],[22,"drop=1"],[37,"effort=5.98"],[43,"drop=1"],[64,"drop=2"],[78,"drop=2"],[81,"drop=1"],[83,"effort=6.92"],[85,"effort=9.67"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=1"],[111,"drop=2"],[121,"drop=3"],[144,"drop=3"],[147,"effort=9.24"],[149,"effort=6.49"],[167,"drop=2"],[186,"drop=1"],[188,"drop=3"],[191,"effort=7.3"],[207,"drop=1"]] / 245.572
Worst strategy found: [0,1,3,2] / [[0,"effort=5"],[4,"effort=10"],[22,"drop=1"],[37,"effort=5.98"],[43,"drop=1"],[64,"drop=2"],[78,"drop=2"],[81,"drop=1"],[83,"effort=6.92"],[85,"effort=9.67"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=1"],[111,"drop=2"],[121,"drop=3"],[144,"drop=3"],[147,"effort=9.24"],[149,"effort=6.49"],[167,"drop=2"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[207,"drop=1"]] / 328.07


-gen 106
time 245.406
1,0,2,3
[[0,"effort=5"],[4,"effort=7.46"],[22,"drop=1"],[37,"effort=6.16"],[42,"drop=1"],[64,"drop=2"],[75,"drop=2"],[76,"drop=2"],[81,"drop=1"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=3"],[121,"drop=3"],[144,"drop=3"],[149,"effort=6.49"],[167,"drop=1"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[207,"drop=1"]]	

Random Mutant Robustness Check
Original race time taken 245.406
Mutants Created 2000
No. of direct clones 0
Mean instruct. changes made = 1.362
Max. instruct. changes made = 4 Strategy: Starting_order: [1,0,2,3], Instructions [[0,"effort=4.98"],[4,"effort=7.46"],[22,"drop=1"],[37,"effort=6.16"],[42,"drop=1"],[64,"drop=2"],[75,"drop=2"],[81,"drop=1"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=3"],[121,"drop=3"],[149,"effort=6.49"],[167,"drop=1"],[186,"drop=1"],[202,"effort=7.3"],[207,"drop=1"]]
Average race time 260.4701890000004
Std. Dev. of mutant race times 14.917100820577668
% of races that are slower/the same/faster (total): 0.8 / 0.19 / 0 (99 %)
Average amount that times differ by: 15.064425000000027
Average % that times differ by: 0.061385724065426264
Best strategy found: [1,0,2,3] / [[0,"effort=5"],[4,"effort=7.46"],[22,"drop=1"],[38,"effort=6.16"],[42,"drop=1"],[64,"drop=2"],[75,"drop=2"],[76,"drop=2"],[81,"drop=1"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=3"],[121,"drop=3"],[144,"drop=3"],[149,"effort=6.49"],[167,"drop=1"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[207,"drop=1"]] / 245.327
Worst strategy found: [1,0,2,3] / [[0,"effort=5"],[4,"effort=7.46"],[7,"effort=9.27"],[22,"drop=1"],[37,"effort=6.16"],[42,"drop=1"],[64,"drop=2"],[75,"drop=2"],[76,"drop=2"],[81,"drop=1"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=3"],[121,"drop=3"],[144,"drop=3"],[149,"effort=6.49"],[167,"drop=1"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[207,"drop=1"]] / 322.313

Instruction Mutation tests (version 2, SYSTEMATICK)
Original race finish time: 245.406
Total variations run: 694
Average race time: 258.19
Std. deviation of variation race times: 15.47
% of races that are slower/the same/faster (total): 0.71 / 0.29 / 0(100 %)
Average amount that times differ by: 12.78
Average % that times differ by: 0.05
Best strategy found: [1,0,2,3] / [[0,"effort=5"],[4,"effort=7.46"],[22,"drop=1"],[38,"effort=6.16"],[42,"drop=1"],[64,"drop=2"],[75,"drop=2"],[76,"drop=2"],[81,"drop=1"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=3"],[121,"drop=3"],[144,"drop=3"],[149,"effort=6.49"],[167,"drop=1"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[207,"drop=1"]] / 245.327
Worst strategy found: [1,0,2,3] / [[0,"effort=5"],[4,"effort=10"],[22,"drop=1"],[37,"effort=6.16"],[42,"drop=1"],[64,"drop=2"],[75,"drop=2"],[76,"drop=2"],[81,"drop=1"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=3"],[121,"drop=3"],[144,"drop=3"],[149,"effort=6.49"],[167,"drop=1"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[207,"drop=1"]] / 327.481



---- compare side by side

[[0,"effort=5"],[4,"effort=7.12"],[22,"drop=1"],[37,"effort=5.98"],[43,"drop=1"],[64,"drop=2"],              [78,"drop=2"],[81,"drop=1"],[83,"effort=6.92"],[85,"effort=9.67"],[88,"effort=6.84"],[103,"drop=2"],[110,"drop=1"],[111,"drop=2"],[121,"drop=3"],[144,"drop=3"],[147,"effort=9.24"],[149,"effort=6.49"],[167,"drop=2"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[207,"drop=1"]]	

[[0,"effort=5"],[4,"effort=7.46"],[22,"drop=1"],[37,"effort=6.16"],[42,"drop=1"],[64,"drop=2"],[75,"drop=2"],[76,"drop=2"],[81,"drop=1"],                                       [88,"effort=6.84"],[103,"drop=2"],[110,"drop=3"],               [121,"drop=3"],[144,"drop=3"],[149,"effort=6.49"],[167,"drop=1"],[186,"drop=1"],[188,"drop=3"],[202,"effort=7.3"],[207,"drop=1"]]	
 ------
 
  - Colm meeting 19th June 
 
 1st sentence, too long. 
 - split into parts.
 
 - trade off between speed and robustness - mention earlier?
 
 - related work, needs a summary to lead into the model. Finding fit solutions with a robust measure, depending on circumstances. Narrow in on the main topic. Signpost what's coming up.
 
 - try and find my proceedings, can I cite this? 'building on previous work by Kelly' cite and pretend it is by somebody else. to maintain the anonymous review. if I can find a ref to the first paper. reviewer should not know who is submitting.
 - can't find anything tbh, emailed Colm about it. Selected proceedings were published. My stuff was just too weak?
 
 - "When run by the simulator, this race finishes in 257 seconds, more than 24 seconds faster than the best-in-generation time after the first generation" maybe clearer?
 - reworked it a bit to try and clarify it.
 
 - "little faster or slower, or earlier or later than asked, likely to lead to a large failure?" reflect this in the intro as well, the motivation 
 
 - "2000 Random Mutants (R.M.) for 4 generations" should be 4.
	- changed.
 
 - maybe change gen 10 to a later one in the table?
 - can i find gen. 10 easily? maybe use gen 20?
 
 
 BEFORE
 
 Best-in-Gen Race Time    & 281.716   & 272.208  & 257.128  \\
Mean Instruct. Changes    & 1.2635   & 1.2465  & 1.4555  \\
Max. Instruct. Changes    & 5   & 4  & 5  \\
Avg. R.M. Race Time &  291.95 & 291.776  & 275.8 \\
Std. Dev. of R.M. Times & 15.0 & 27.41  &  17.27 \\
\% Slower Races  & 63 & 61  &  81 \\
\% Equal-time Races  & 13  & 24   &  17  \\
\% Faster Races  & 24  & 15   &   2  \\
Avg. R.M./Best-in-Gen Diff (Time)  & 11.29 & 19.93   &  18.67  \\
Avg. R.M./Best-in-Gen Diff (\%)   & 0.04 & 0.073 &  0.073  \\
Best R.M. Time  & 270.333 & 268.904 &  256.749  \\
Worst R.M. Time  & 351.048 & 476.751  &  336.322  \\

AFTER. maybe use gen. 40?

Best-in-Gen Race Time    & 281.716   & 265.339  & 257.128  \\
Mean Instruct. Changes    & 1.2635   & 1.3265  & 1.4555  \\
Max. Instruct. Changes    & 5   & 5  & 5  \\
Avg. R.M. Race Time &  291.95 & 285.76  & 275.8 \\
Std. Dev. of R.M. Times & 15.0 & 25.15  &  17.27 \\
\% Slower Races  & 63 & 78  &  81 \\
\% Equal-time Races  & 1  & 16   &  17  \\
\% Faster Races  & 24  & 6   &   2  \\
Avg. R.M./Best-in-Gen Diff (Time)  & 11.29 & 20.45   &  18.67  \\
Avg. R.M./Best-in-Gen Diff (\%)   & 0.04 &  0.077 &  0.073  \\
Best R.M. Time  & 270.333 & 264.794 &  256.749  \\
Worst R.M. Time  & 351.048 & 391.035  &  336.322  \\



 
 - "The experimental results show th at strategies vary in the tolerance of their phenotypical performance to perturbation, but the relationship between particular instructions and specific alterations to this final result has not been addressed." confusing.
 
 "We can already note from the design of the simulator some expectations."
 
 "and conversely, an effort instruction"
 
 "neighbourhood of the I.V. search leads" make sure I.V. is clearly introduced before being used.
 done
 
 
 "and is smaller than the"
 
 degrade 
 
 update the image rm_iv_comparison_two_strong_200gens_Jun18 to include a circle around gens 105/106
 - DONE.
 
 
 
 -- how do i bring in the other team types in terms of robustness?
 
 -- how do i incorporate the core model? describe it or find some way to post/cite it?
 
 
 -- Wed. 25th, Mishawaka, going through changes.
 
 - I included one specific mutation rate value, and mentioned that they are all copied from the GA process. Is this ok?
 
 - added the  missing image
 
 - finished the Colm updates
 
 - need to
 
 - add section on other team types 
 
 - add discussion
 
 - add conclusion 
 
 - read through and look for issues 
 
 - email Colm 
 
 - are drop instructions more sensitive in strategies where the order DOES matter?
 
 - wait, have to reword, that, the previous section used 2 weak/2 strong team... 
 
 - compare 1sgrong/3weak with all equal?
 
 - shoot, that last diagram used gen 1 data! 
 - no no it didn't, I ran the test from the GA page. The graph data is for the fitness spread data?
 
 - one strong strat has NO early drop instruction, good comparison point  with an all-equal?
 
 - idea, show FOUR, one for each... then discuss a little. anything I can graph gen-by-gen here? can't fit that much tbh.
 
 0,3,1,2  252.771
 
 0,3,2,1  252.771
 0,2,1,3
 0,2,3,1
 0,1,2,3
 0,1,3,2
 
 1,2,3,0 281.148
 1,3,2,0 281.148
 
 1,0,3,2 288.045
1,2,0,3 286.702


(288.045-252.771)/252.771 = 0.13954923626
(281.148-252.771)/252.771 = 0.11226366948
(286.702-252.771)/252.771 = 0.13423612677

(0.13954923626 + 0.11226366948 + 0.13423612677)/3= 0.12868301083

((5 * 0) + (6*0.13954923626) + (6*0.11226366948) + (6*0.13423612677))/24 = 0.09651225812
 
  i should have added a case for I.V. where the instruction was taken out? but how would that be visualised??
  
  (253.48 - 238.58)/238.58 = 0.062452846
  
  
  
   -- need more references in the AI section, e.g. on search?
 
 - mention explainability? in the conclusion? in that 
 
 
 
 - get to the noise part... fix up the part written thus far?
 
 here to learn.
 
 - need to read some more on noise in optimization?
 
 @inproceedings{krink2004noisy,
  title={Noisy optimization problems-a particular challenge for differential evolution?},
  author={Krink, Thiemo and Filipic, Bogdan and Fogel, Gary B},
  booktitle={Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No. 04TH8753)},
  volume={1},
  pages={332--339},
  year={2004},
  organization={IEEE}
}
 
 "the performance of heuristics is notoriously problem dependent and parameter sensitive. "
 
 2005, Jin & Branke, four kinds of noise. 
 
 gradient-based searches can become trapped in a local minima introduced by noise. 
 
 lemma: subsidiary or intermediate theorem
 
 Paper "Noisy Optimization with Evolution Strategies"
 "We then empirically demonstrate that for a simple but nonetheless
nontrivial noisy objective function, an evolution strategy outperforms other optimization algorithms designed to be able to cope with noise"
 
 Need to move or remove "Exploring Discovered Instructions" section. could it go in the core model chapter?
 
 For now, put it in an offshoots section, maybe create a new chaper for now, for this kind of work, which may or may not be brought back in.
 
 - piece on robustness here needs to go, but could keep a little of it somehow? 
 
 - need to start running noise experiments. recreate those diagrams. review each of the functions
 
 - try mishearing every instruction
 
 - is it delay OR effort, or possibly delayed + possibly effort? 
 
 - possible diagram: increasing level of mishearing noise, show that the GA gets worse at finding better solutions?
 - run experiment varying 
 noise_1_probability_instruction_misheard (go up in .17 since we can only show 7 lines on the graph?)
 0,0.17,0.34,0.51,0.68, 0.85, 1
 
 {"iterations":[7,6,5,4,3,2,1],"type":"global","property":"noise_1_probability_instruction_misheard","values":[0,0.17,0.34,0.51,0.68, 0.85, 1]}
 
 
 
 {"iterations":7,"active":1,"variations":[{"iterations":[7,6,5,4,3,2,1],"type":"global","property":"noise_1_probability_instruction_misheard","values":[0,0.17,0.34,0.51,0.68, 0.85, 1]}],"experiments":[]}
 {"iterations":3,"active":0,"variations":[{"iterations":[3,2,1],"type":"global","property":"ga_tournament_selection_group_size","values":[2000,2000,2000]},{"iterations":[3,2,1],"type":"global","property":"ga_tournament_roulette_exponent_group_size_divisor","values":[2000,2000,2000]}],"experiments":[{"client_id":"86.45.238.255_2025_4_28_13_4_4","iteration":3,"status":"complete"},{"client_id":"86.45.238.255_2025_4_28_13_4_4","iteration":2,"status":"complete"},{"client_id":"86.45.238.255_2025_4_28_13_4_4","iteration":1,"status":"complete"}]}
 
 - why have multiple kinds of noise? is there any difference between them in terms of their effect on the GA convergence??
 
 - need to run it with all the different kinds of noise and produce some kind of graph
 
 - what happens if we incorporate the noise changes into the genotype? noise happens, record it, update the genotype.
 
 - example of total mishearing noise 
 
 {"0":{"original_instruction":[0,"effort=9.98"],"altered_instruction":[0,"effort=10"],"type":"random_effort"},"1":{"original_instruction":[1,"effort=9.77"],"altered_instruction":[1,"effort=10"],"type":"random_effort"},"2":{"original_instruction":[2,"effort=6.09"],"altered_instruction":[2,"effort=4.436185861757876"],"type":"random_effort"},"12":{"original_instruction":[12,"effort=6.42"],"altered_instruction":[16,"effort=6.42"],"type":"random_delay"},"15":{"original_instruction":[15,"drop=2"],"altered_instruction":[15,"drop=1"],"type":"random_drop"},"23":{"original_instruction":[23,"drop=3"],"altered_instruction":[23,"drop=2"],"type":"random_drop"},"60":{"original_instruction":[60,"drop=1"],"altered_instruction":[60,"drop=2"],"type":"random_drop"},"83":{"original_instruction":[83,"drop=3"],"altered_instruction":[83,"drop=2"],"type":"random_drop"},"85":{"original_instruction":[85,"effort=5.74"],"altered_instruction":[89,"effort=5.74"],"type":"random_delay"},"94":{"original_instruction":[94,"drop=3"],"altered_instruction":[94,"drop=2"],"type":"random_drop"},"112":{"original_instruction":[112,"drop=2"],"altered_instruction":[112,"drop=3"],"type":"random_drop"},"121":{"original_instruction":[121,"effort=6.55"],"altered_instruction":[123,"effort=6.55"],"type":"random_delay"},"145":{"original_instruction":[145,"drop=3"],"altered_instruction":[145,"drop=2"],"type":"random_drop"},"150":{"original_instruction":[150,"drop=3"],"altered_instruction":[150,"drop=2"],"type":"random_drop"},"169":{"original_instruction":[169,"drop=2"],"altered_instruction":[169,"drop=1"],"type":"random_drop"},"183":{"original_instruction":[183,"drop=3"],"altered_instruction":[186,"drop=3"],"type":"random_delay"},"200":{"original_instruction":[200,"drop=2"],"altered_instruction":[204,"drop=2"],"type":"random_delay"},"225":{"original_instruction":[225,"effort=4.9399999999999995"],"altered_instruction":[226,"effort=4.9399999999999995"],"type":"random_delay"},"240":{"original_instruction":[240,"drop=1"],"altered_instruction":[240,"drop=2"],"type":"random_drop"},"244":{"original_instruction":[244,"effort=9.49"],"altered_instruction":[248,"effort=9.49"],"type":"random_delay"},"252":{"original_instruction":[252,"drop=3"],"altered_instruction":[252,"drop=1"],"type":"random_drop"},"265":{"original_instruction":[265,"drop=2"],"altered_instruction":[270,"drop=2"],"type":"random_delay"}}
 
 there are lots more DELAYS here than effort changes, though they should only be 0.3 of the total. Is it a pattern for other generations or experiments?
 
 - need to set up experiments for the other kinds of noise.
 
 {"0":{"original_instruction":[0,"effort=7.85"],"altered_instruction":[0,"effort=5.1989856641316265"],"type":"random_effort"},"2":{"original_instruction":[2,"effort=8.42"],"altered_instruction":[2,"effort=9.527509962818524"],"type":"random_effort"},"7":{"original_instruction":[7,"effort=6.66"],"altered_instruction":[7,"effort=6.264235103751942"],"type":"random_effort"},"17":{"original_instruction":[17,"drop=2"],"altered_instruction":[17,"drop=3"],"type":"random_drop"},"36":{"original_instruction":[36,"drop=2"],"altered_instruction":[36,"drop=1"],"type":"random_drop"},"57":{"original_instruction":[57,"drop=3"],"altered_instruction":[57,"drop=1"],"type":"random_drop"},"68":{"original_instruction":[68,"drop=2"],"altered_instruction":[68,"drop=3"],"type":"random_drop"},"82":{"original_instruction":[82,"drop=2"],"altered_instruction":[82,"drop=1"],"type":"random_drop"},"85":{"original_instruction":[85,"drop=3"],"altered_instruction":[85,"drop=2"],"type":"random_drop"},"86":{"original_instruction":[86,"drop=3"],"altered_instruction":[86,"drop=2"],"type":"random_drop"},"96":{"original_instruction":[96,"drop=1"],"altered_instruction":[96,"drop=3"],"type":"random_drop"},"122":{"original_instruction":[122,"drop=3"],"altered_instruction":[122,"drop=2"],"type":"random_drop"},"145":{"original_instruction":[145,"drop=3"],"altered_instruction":[145,"drop=2"],"type":"random_drop"},"167":{"original_instruction":[167,"drop=2"],"altered_instruction":[172,"drop=2"],"type":"random_delay"},"185":{"original_instruction":[185,"drop=1"],"altered_instruction":[190,"drop=1"],"type":"random_delay"},"188":{"original_instruction":[188,"effort=6.89"],"altered_instruction":[189,"effort=6.89"],"type":"random_delay"},"228":{"original_instruction":[228,"drop=3"],"altered_instruction":[228,"drop=2"],"type":"random_drop"},"237":{"original_instruction":[237,"effort=6.87"],"altered_instruction":[237,"effort=3.156709004153217"],"type":"random_effort"},"240":{"original_instruction":[240,"effort=5.57"],"altered_instruction":[240,"effort=5.288973354646661"],"type":"random_effort"},"244":{"original_instruction":[244,"effort=9.92"],"altered_instruction":[244,"effort=10"],"type":"random_effort"},"251":{"original_instruction":[251,"effort=7.87"],"altered_instruction":[251,"effort=8.952392316983996"],"type":"random_effort"},"252":{"original_instruction":[252,"drop=1"],"altered_instruction":[252,"drop=2"],"type":"random_drop"},"255":{"original_instruction":[255,"effort=4.38"],"altered_instruction":[259,"effort=4.38"],"type":"random_delay"},"262":{"original_instruction":[262,"drop=1"],"altered_instruction":[262,"drop=2"],"type":"random_drop"}}
 
 
 - set up a sequence for performance failures 
 
 
 {"iterations":7,"active":1,"variations":[{"iterations":[7,6,5,4,3,2,1],"type":"rider","rider_no":0,"property":"performance_failure_rate","values":[0,1.7,3.4,5.1,6.8,8.5,10]},{"iterations":[7,6,5,4,3,2,1],"type":"rider","rider_no":1,"property":"performance_failure_rate","values":[0,1.7,3.4,5.1,6.8,8.5,10]},{"iterations":[7,6,5,4,3,2,1],"type":"rider","rider_no":2,"property":"performance_failure_rate","values":[0,1.7,3.4,5.1,6.8,8.5,10]},{"iterations":[7,6,5,4,3,2,1],"type":"rider","rider_no":3,"property":"performance_failure_rate","values":[0,1.7,3.4,5.1,6.8,8.5,10]}]}
 
 experiment is crashing... target_power < 0.
 - wierd, performance_failures has an entry that is > 1. surely this is impossible? {
    "8_1": 0.0122,
    ...,
	...,
    "306_1": 0.3909,
    "309_2": 1.1116
}

so, need to look at the calculate_rider_performance_failure_percentage_amount() function.

- what is settings_r.performance_failure_effect_type doing??

####****max_performance_failure_percentage breached****####
race_function_no_vis.js:207 max_performance_failure_percentage 1.1115879636846455 effort 8.51 effort_max 10 current_fatigue 299.8465601666667 current_fatigue_max 300
 accumulated_fatigue 1107.272585218885
 accumulated_fatigue_max 770 rider_performance_failure_multiplier 10 rider_performance_failure_multiplier_max 10
 performance_failure_base_max_percentage 1 performance_failure_amount_exponent 2
 performance_failure_effort_importance_multiplier 1 failure_type 2
 
 
 accumulated_fatigue_max is MORE than accumulated_fatigue_max... maybe this is the issue??
 - had previously fixed an issue where the current and max fatigue level 
 
   if (current_fatigue > current_fatigue_max){
      current_fatigue_max = current_fatigue; //current_fatigue/current_fatigue_max will now max out at 1
    }
	
so, add 
  if (accumulated_fatigue > accumulated_fatigue_max){
      accumulated_fatigue_max = accumulated_fatigue;
      console.log("***dk25: adjusting accumulated_fatigue_max  since it is < accumulated_fatigue");
    }
	
-- this appears to be working? but i want to restart everything now... and need to review how this fatigue works

- they can achieve 'perfect' failure, i.e., where rider_performance_failure__percentage_amount = 1.

-- still getting lots of this:
####****max_performance_failure_percentage breached****####
race_function_no_vis.js:217 max_performance_failure_percentage 0.9690563917794073 rider_performance_failure__percentage_amount 0.9709179831944444 p1 0.9980826481255273 effort 9.99 effort_max 10 current_fatigue 265.7015798333333 current_fatigue_max 300
 accumulated_fatigue 881.0145197642537
 accumulated_fatigue_max 881.0145197642537 rider_performance_failure_multiplier 10 rider_performance_failure_multiplier_max 10
 performance_failure_base_max_percentage 1 performance_failure_amount_exponent 1
 performance_failure_effort_importance_multiplier 2 failure_type 2
 
 where's max_performance_failure_percentage coming from??
 -- ok, so it;s tracking the max failure level and is being reset... for every race?
 
 -example of failures, after 30 gens, performance_failure_rate 10.
 
 {"4_2":0.3531,"5_2":0.0815,"10_0":0.1419,"11_1":0.1636,"11_0":0.1596,"12_0":0.168,"14_2":0.3644,"15_2":0.0432,"18_2":0.2209,"19_2":0.2261,"19_0":0.1594,"20_2":0.1233,"21_2":0.3872,"22_2":0.0208,"23_3":0.1452,"24_2":0.3072,"25_1":0.1675,"26_1":0.3084,"28_2":0.5012,"30_1":0.1087,"31_1":0.0721,"31_0":0.1311,"32_1":0.2372,"32_3":0.1287,"33_2":0.4867,"34_0":0.1332,"34_2":0.4667,"35_0":0.1317,"36_1":0.3484,"36_2":0.4925,"37_1":0.0821,"37_2":0.4966,"38_1":0.2318,"38_2":0.5006,"39_2":0.5045,"40_2":0.5081,"43_0":0.1355,"44_2":0.577,"44_1":0.5638,"45_3":0.0705,"45_2":0.5312,"46_2":0.4853,"47_3":0.4132,"47_1":0.4721,"49_3":0.2045,"49_2":0.4441,"49_1":0.4544,"50_2":0.4441,"50_1":0.4361,"51_2":0.4441,"52_3":0.2027,"53_3":0.2287,"53_0":0.1369,"54_0":0.1369,"58_3":0.0204,"58_0":0.144,"58_2":0.451,"58_1":0.5748,"59_3":0.2953,"59_0":0.1402,"59_1":0.5704,"60_3":0.0353,"60_0":0.1397,"60_1":0.5246,"61_3":0.1057,"61_0":0.1454,"62_3":0.2167,"62_1":0.47,"63_2":0.4504,"63_1":0.47,"64_0":0.1483,"64_1":0.47,"65_3":0.3678,"65_2":0.4615,"65_1":0.4748,"66_3":0.2122,"66_2":0.4535,"67_2":0.4535,"67_1":0.4828,"67_3":0.5796,"68_2":0.4535,"69_3":0.5337,"70_2":0.4756,"70_1":0.489,"71_3":0.513,"72_1":0.4783,"72_3":0.4917,"73_0":0.1041,"74_1":0.4886,"74_3":0.473,"75_0":0.1553,"76_0":0.4779,"76_2":0.4604,"76_3":0.4983,"77_0":0.2268,"77_2":0.4604,"78_0":0.4205,"78_1":0.481,"79_0":0.0312,"79_2":0.4642,"80_2":0.4615,"80_3":0.5679,"81_0":0.2487,"81_2":0.4615,"81_1":0.4824,"82_0":0.42,"82_2":0.4628,"82_3":0.5858,"84_1":0.4936,"84_0":0.5137,"85_2":0.3704,"85_0":0.4679,"86_1":0.4897,"86_0":0.4464,"87_1":0.4867,"88_2":0.1717,"88_1":0.4867,"88_0":0.4376,"89_2":0.1926,"89_0":0.4365,"89_3":0.4762,"90_2":0.1685,"90_3":0.4762,"91_2":0.3435,"91_0":0.4426,"91_3":0.4762,"92_2":0.4603,"92_1":0.4907,"92_0":0.4486,"92_3":0.4762,"93_2":0.3564,"93_1":0.4907,"94_1":0.4907,"95_1":0.4907,"96_3":0.5167,"97_1":0.5146,"97_3":0.52,"98_2":0.0417,"98_0":0.4994,"98_3":0.5231,"99_1":0.5054,"99_0":0.467,"100_2":0.146,"100_3":0.5444,"101_2":0.2927,"101_1":0.5044,"101_3":0.5466,"102_1":0.501,"103_0":0.4681,"104_2":0.1502,"104_1":0.5145,"104_3":0.5203,"105_2":0.1199,"105_1":0.5048,"106_2":0.4758,"106_0":0.472,"107_2":0.3711,"107_1":0.5103,"108_2":0.5942,"108_0":0.472,"109_3":0.5015,"110_2":0.396,"110_1":0.5063,"111_2":0.5525,"111_3":0.5015,"112_2":0.1888,"112_0":0.472,"113_1":0.5064,"113_3":0.5015,"114_2":0.306,"115_2":0.2938,"116_1":0.2949,"116_3":0.517,"117_0":0.4731,"117_3":0.5059,"117_2":0.5701,"118_2":0.5243,"119_0":0.4818,"119_3":0.5063,"119_2":0.5158,"120_2":0.5158,"122_2":0.5174,"123_0":0.4869,"123_2":0.5162,"124_1":0.2673,"124_0":0.4813,"124_2":0.5195,"126_0":0.4941,"126_2":0.5411,"127_1":0.0231,"127_0":0.4849,"127_3":0.5176,"128_1":0.0027,"128_0":0.4849,"129_1":0.6168,"129_0":0.4884,"129_3":0.5236,"129_2":0.5843,"130_2":0.5849,"131_2":0.5855,"132_1":0.4779,"132_3":0.5223,"133_0":0.1721,"133_1":0.6212,"133_2":0.602,"134_3":0.5219,"135_0":0.0629,"135_3":0.5219,"136_0":0.3249,"136_3":0.5222,"136_1":0.5769,"136_2":0.6403,"137_0":0.3643,"137_3":0.5233,"137_1":0.5524,"137_2":0.6357,"138_0":0.1778,"138_3":0.5222,"139_1":0.5488,"140_0":0.4868,"140_3":0.5316,"140_2":0.6688,"141_0":0.2006,"141_2":0.6609,"142_3":0.5249,"142_1":0.5531,"142_2":0.654,"143_3":0.5249,"143_2":0.6478,"144_3":0.5275,"144_1":0.5574,"144_2":0.6423,"145_0":0.2899,"145_1":0.5543,"146_0":0.0764,"146_3":0.5485,"146_1":0.5561,"146_2":0.6513,"147_3":0.533,"147_1":0.5577,"147_2":0.6454,"148_3":0.5315,"148_1":0.5594,"148_2":0.6402,"149_0":0.0887,"149_2":0.6356,"150_0":0.1353,"150_3":0.5469,"150_1":0.578,"150_2":0.6315,"151_0":0.3614,"151_3":0.5358,"151_2":0.6279,"152_0":0.5996,"152_3":0.5358,"153_3":0.5358,"153_1":0.6183,"153_2":0.6391,"154_0":0.1227,"154_3":0.5358,"154_1":0.5724,"154_2":0.6346,"155_2":0.6306,"156_0":0.5204,"156_3":0.5509,"156_1":0.5722,"156_2":0.6271,"157_0":0.0466,"157_1":0.5722,"157_2":0.624,"158_1":0.5722,"159_3":0.5477,"159_1":0.5725,"159_2":0.6358,"160_3":0.5422,"161_0":0.285,"161_3":0.5422,"161_1":0.5901,"162_0":0.0075,"162_3":0.5439,"162_1":0.5772,"163_1":0.5772,"163_2":0.692,"164_0":0.3771,"164_1":0.5781,"164_2":0.6815,"165_2":0.6722,"166_3":0.5482,"166_1":0.5952,"167_0":0.0162,"167_3":0.5482,"167_1":0.5823,"167_2":0.6765,"168_0":0.2144,"168_3":0.5482,"168_1":0.5823,"169_3":0.5482,"169_1":0.5823,"169_2":0.6803,"170_0":0.0861,"170_1":0.5823,"171_0":0.1682,"171_1":0.583,"172_3":0.5525,"172_1":0.5836,"173_3":0.5525,"173_1":0.5826,"173_2":0.7243,"174_0":0.6807,"174_2":0.7101,"175_3":0.4112,"175_1":0.5856,"176_1":0.5835,"176_0":0.6052,"176_2":0.7055,"177_3":0.2163,"177_1":0.5835,"177_0":0.5593,"178_0":0.5337,"178_2":0.7016,"179_1":0.5882,"181_2":0.6441,"182_3":0.0579,"182_1":0.5995,"182_0":0.5353,"183_1":0.5889,"183_0":0.5378,"184_3":0.3687,"184_1":0.5889,"184_2":0.6656,"185_3":0.3627,"185_1":0.5889,"185_0":0.5581,"185_2":0.6581,"186_2":0.6514,"187_3":0.0594,"187_0":0.5768,"187_2":0.6456,"188_1":0.5922,"188_2":0.6403,"189_1":0.5922,"190_3":0.5188,"190_0":0.5448,"191_3":0.3273,"191_1":0.6082,"191_0":0.5448,"191_2":0.6624,"192_0":0.5448,"192_2":0.6552,"193_0":0.5448,"193_2":0.6489,"194_3":0.0825,"194_0":0.5448,"194_2":0.6433,"195_0":0.5448,"195_2":0.6383,"196_0":0.5448,"196_2":0.6339,"197_3":0.3266,"197_1":0.5973,"197_0":0.5454,"197_2":0.6301,"198_3":0.4072,"198_2":0.6266,"199_3":0.1586,"199_0":0.5501,"200_1":0.5974,"200_2":0.6339,"201_1":0.5974,"201_2":0.63,"202_3":0.4898,"202_0":0.5464,"203_1":0.613,"203_2":0.6369,"204_0":0.5586,"205_1":0.6265,"205_0":0.5602,"205_2":0.6427,"206_3":0.5055,"206_1":0.6234,"206_0":0.5617,"206_2":0.6379,"207_1":0.6207,"207_2":0.6335,"208_3":0.2078,"208_0":0.5801,"208_2":0.6297,"209_3":0.1446,"209_2":0.6263,"210_1":0.6481,"211_1":0.6426,"211_0":0.5583,"212_3":0.2641,"212_2":0.6503,"213_3":0.0283,"213_1":0.6477,"213_0":0.5671,"214_3":0.0368,"214_1":0.6422,"214_0":0.5607,"214_2":0.6543,"215_3":0.579,"215_0":0.5607,"216_3":0.4502,"217_3":0.0168,"217_1":0.664,"217_0":0.5735,"217_2":0.6743,"218_3":0.9129,"218_1":0.6566,"219_3":0.2335,"219_0":0.5883,"219_2":0.6748,"220_3":0.4052,"220_1":0.6597,"221_3":0.0499,"221_1":0.6528,"221_0":0.5685,"221_2":0.6753,"222_3":0.5164,"222_1":0.6468,"222_0":0.5685,"222_2":0.6667,"223_3":0.6715,"223_0":0.5685,"223_2":0.659,"224_3":0.4702,"224_2":0.6523,"225_3":0.6965,"225_1":0.6679,"225_2":0.6463,"226_3":0.8546,"226_0":0.5983,"227_3":0.5328,"227_0":0.5757,"227_2":0.6508,"228_3":0.1489,"228_1":0.686,"228_2":0.645,"229_3":0.5642,"229_2":0.6398,"230_3":0.4814,"230_1":0.6849,"230_0":0.5745,"230_2":0.6353,"231_3":0.0498,"231_1":0.6752,"231_2":0.6312,"232_3":0.5671,"232_1":0.6665,"233_3":0.2852,"233_0":0.5745,"233_2":0.6379,"234_3":0.5868,"234_0":0.5745,"234_2":0.6335,"235_3":0.4246,"235_2":0.6297,"236_3":0.956,"236_1":0.7015,"236_0":0.587,"236_2":0.6263,"237_3":0.7628,"237_1":0.6899,"238_3":0.4342,"238_1":0.6796,"238_2":0.6337,"239_3":0.0426,"239_1":0.6705,"239_2":0.6298,"240_3":0.2136,"240_1":0.6624,"241_3":0.196,"241_0":0.5745,"242_3":0.453,"242_1":0.6646,"242_2":0.6533,"243_3":0.065,"243_1":0.6572,"243_2":0.6472,"244_3":0.2899,"244_1":0.6507,"244_0":0.5745,"245_3":0.0916,"245_1":0.6449,"245_0":0.5745,"245_2":0.6516,"246_3":0.4303,"246_1":0.6397,"246_0":0.5745,"247_3":0.6501,"247_1":0.6352,"247_0":0.5745,"247_2":0.6554,"248_3":0.4023,"248_1":0.6311,"248_2":0.649,"249_3":0.8248,"249_1":0.6276,"249_0":0.5761,"249_2":0.6434,"250_3":0.6638,"250_0":0.5745,"250_2":0.6384,"251_3":0.1967,"251_1":0.6347,"251_0":0.5745,"251_2":0.634,"252_3":0.43,"252_1":0.6308,"252_0":0.5752,"252_2":0.6302,"253_3":0.3099,"253_1":0.6272,"254_3":0.9636,"254_1":0.6241,"254_0":0.5877,"254_2":0.637,"255_3":0.6133,"255_1":0.6214,"255_2":0.6327,"256_3":0.5305,"256_1":0.6189,"256_0":0.5745,"256_2":0.629,"257_3":0.3359,"257_0":0.5745,"257_2":0.6257,"258_3":0.934,"258_1":0.6273,"258_0":0.5745,"259_3":0.3893,"259_1":0.6242,"259_0":0.5745,"259_2":0.6331,"260_3":0.4263,"260_1":0.6214,"260_2":0.6293,"261_3":0.321,"261_0":0.5837,"261_2":0.626,"262_3":0.3255,"262_0":0.5745,"263_3":0.8313,"263_2":0.6334,"264_3":0.4585,"265_3":0.303,"265_1":0.6795,"265_2":0.6397,"266_3":0.4545,"266_1":0.6704,"266_0":0.6204,"266_2":0.6352,"267_3":0.365,"267_1":0.6623,"267_0":0.5745,"267_2":0.6311,"268_3":0.4502,"268_1":0.6552,"268_2":0.6276,"269_3":0.236,"269_1":0.6489,"269_0":0.5745,"269_2":0.6244,"270_3":0.2783,"270_1":0.6433,"270_2":0.6216,"271_3":0.1456,"271_0":0.5745,"271_2":0.6191,"272_3":0.822,"272_1":0.6482,"272_0":0.5745,"272_2":0.617,"273_3":0.8508,"273_1":0.6427,"273_2":0.615}
 
 -- they fail 'harder' towards the end of the race?
 
 - final race with LOTs of failure is very chaotic indeed :-( 
 
 - could add a weight to all of the elements, not just the effort? but weighting the effort essentially de-weights the fatigue??	
 
 - still seems to be an issue with the refs...
 
   Latex found 13 multiply defined reference(s)
  Latex failed to resolve 1 citation(s)
  
  LaTeX Warning: Citation 'Williams2020' on page 5 undefined on input line 65.
  
  - this is defo in the file, must be an issue in it somewhere?
  
  - weird 
  LaTeX Warning: Label `fig:y equals x' multiply defined.

LaTeX Warning: Label `sub@fig:y equals x' multiply defined.


LaTeX Warning: Label `fig:three sin x' multiply defined.

LaTeX Warning: Label `sub@fig:three sin x' multiply defined.


LaTeX Warning: Label `fig:five over x' multiply defined.

LaTeX Warning: Label `sub@fig:five over x' multiply defined.


LaTeX Warning: Label `fig:y equals x' multiply defined.

LaTeX Warning: Label `sub@fig:y equals x' multiply defined.


LaTeX Warning: Label `fig:three sin x' multiply defined.

LaTeX Warning: Label `sub@fig:three sin x' multiply defined.#

LaTeX Warning: Label `fig:five over x' multiply defined.

LaTeX Warning: Label `sub@fig:five over x' multiply defined.

LaTeX Warning: Label `fig:powerOutputFailure' multiply defined.



LaTeX Warning: Reference `fig:avg_3_trainTestLandscapeContours3d_3Strong' on page 19 undefined on input line 305.

LaTeX Warning: Reference `fig:avg_3_averageNoOfInstructionsWithDifferentGA_Noise_levels' on page 19 undefined on input line 305.


-- hmmmmmmmmmmmmmmmmmm 


LaTeX Warning: Reference `fig:finishTimesNoiseSevenLevelsMishearing' on page 5 undefined on input line 75.

-- issue with the williams article citation was the COMMA in the bib listing, I had "Williams, M., A., and Wigmore, T." as the author, the comma in A., was the issue. comibe author names with "and" only.

- should i run a bunch of tests on varying the effect of failure with the rider 'proneness' held firm?
performance_failure_base_max_percentage

{"iterations":21,"active":0,"variations":[{"iterations":[7,6,5,4,3,2,1],"type":"global","property":"performance_failure_base_max_percentage","values":[0,0.17,0.34,0.51,0.68,0.85,1]}],"experiments":[]}



- i could create a visual showing examples of failure?

- just have a simple starting level, set a effort changes, then add, manually, some failures.

- instrucitons 
[[0,"effort=6"],[0,"effort=5"],[0,"effort="],[0,"effort=9.67"],[0,"effort=9.67"],[0,"effort=9.67"],]

- how can i evolve strategies with NO drop instructions??

- hmm, it;s way more complex than I had expected, it accelerates, recovers, etc. Try evolove one 

- made graph using this result: ResultsJuly_2025_Testing_Noise_C_All_Equal_NO_DROP + [ all equal NO drop ] | _id | 688412ef0d5d5a4b28a59081
- http://127.0.0.1:3003/tpgame.html?source=results&results_id=688412ef0d5d5a4b28a59081&startorder=1,3,0,2&instructions=%5B%5B1,%22effort=7.13%22%5D,%5B35,%22effort=4.13%22%5D,%5B46,%22effort=9.06%22%5D,%5B50,%22effort=1.62%22%5D,%5B56,%22effort=9.16%22%5D,%5B60,%22effort=5.76%22%5D,%5B64,%22effort=7.01%22%5D,%5B89,%22effort=1.32%22%5D,%5B92,%22effort=1.67%22%5D,%5B97,%22effort=7.46%22%5D,%5B110,%22effort=7.13%22%5D,%5B118,%22effort=7.15%22%5D,%5B128,%22effort=1.8599999999999999%22%5D,%5B136,%22effort=6.3%22%5D,%5B142,%22effort=9.45%22%5D,%5B154,%22effort=5.37%22%5D,%5B168,%22effort=3.86%22%5D,%5B175,%22effort=3.08%22%5D,%5B184,%22effort=7.77%22%5D,%5B196,%22effort=5.15%22%5D,%5B197,%22effort=3.73%22%5D,%5B201,%22effort=6.55%22%5D,%5B233,%22effort=1.44%22%5D,%5B240,%22effort=7.53%22%5D,%5B253,%22effort=7.3%22%5D%5D&noise_alterations=%7B%7D&performance_failures=%7B%7D&instruction_noise_choke_under_pressure=%7B%7D&instruction_noise_overeagerness=%7B%7D


-- manually add a sequence of failures 

{"20_1":0.5,"40_1":0.5,"60_1":0.5,"80_1":0.5,"100_1":0.5,"120_1":0.5,"140_1":0.5,"160_1":0.5,"180_1":0.5,"200_1":0.5,"220_1":0.5,"240_1":0.5,"260_1":0.5,"280_1":0.5}

{"20_1":0.8,"40_1":0.8,"60_1":0.8,"80_1":0.8,"100_1":0.8,"120_1":0.8,"140_1":0.8,"160_1":0.8,"180_1":0.8,"200_1":0.8,"220_1":0.8,"240_1":0.8,"260_1":0.8,"280_1":0.5}

- create a function (Python?) that spits out a bunch of random failures in a range

- example 
{"34_1":0.44,"67_1":0.73,"70_1":0.44,"83_1":0.42,"145_1":0.42,"150_1":0.5,"227_1":0.16,"236_1":0.5,"278_1":0.5,"285_1":0.64}

287.789 - 272.885 = 14.904

- july 26th

- run experiment where no drop instructions are added, and there's only one effort, the one at 0 added by default.

- interestingly the best that seems possible is [[0,"effort=5.25"]] with a time of 297.768 seconds
- if we allow the usual drop and effort mix we get a much faster time, e.g., [[1,"effort=7.13"],[35,"effort=4.13"],[46,"effort=9.06"],[50,"effort=1.62"],[56,"effort=9.16"],[60,"effort=5.76"],[64,"effort=7.01"],[89,"effort=1.32"],[92,"effort=1.67"],[97,"effort=7.46"],[110,"effort=7.13"],[118,"effort=7.15"],[128,"effort=1.8599999999999999"],[136,"effort=6.3"],[142,"effort=9.45"],[154,"effort=5.37"],[168,"effort=3.86"],[175,"effort=3.08"],[184,"effort=7.77"],[196,"effort=5.15"],[197,"effort=3.73"],[201,"effort=6.55"],[233,"effort=1.44"],[240,"effort=7.53"],[253,"effort=7.3"]] with a time of 272.885

- running one more but need to get back to the main noise tests

what values can choke_under_pressure_tendency be?

bbuugg, something is NOT being reset, if I run the race, delete the choke, and run it again, it remembers somethign and the times are BAD
- n ochoke logged, so it's not resetting the rider's actual capabilities... i guess this doesn't happen in the GA?

- gets set here:
race_rider.threshold_power -= (race_rider.threshold_power * changes[cup+1]);
race_rider.max_power -= (race_rider.max_power * changes[cup+1]);

- the real stuff's in load_race() 
- ok, so it's only ever changed in one place, so right there, could record the original values, and then in load_race(), check to see if those orginal properties are there.. if they are, apply them?
- load_rider.original_threshold_power
- load_rider.original_max_power

so, these two lines shoulllld help?
  race_rider.original_threshold_power = race_rider.threshold_power;
  race_rider.original_max_power = race_rider.max_power;
  
  let choke_under_pressure_value_list = [1, rider_choke_under_pressure_tendency,1,10]; //guessing the values here really
  let choke_under_pressure_probability_variables = [];
  prob_choke_under_pressure = calculate_linear_space_value(choke_under_pressure_value_list,choke_under_pressure_probability_variables);
	// value list contains sets of 4, each set representing a paramter in the expression, which is built using a loop
    //v1 - multiplier / weighting
    //v2 - value
    //v3 - exponent
    //v4 - max value
	
	- sooooooooooo the max value is 10 then, golly that's a lot of work to find out.
	
	even at max value they tend to choke only towards the end... this work is unfinished, then?
	
	
	- hmmmm, need to fully understan the choking mechanism 
	speed_higher_than_best is 1 or 0
	let end_race_better_time_factor = speed_higher_than_best*(race_rider.distance_covered/race_r.distance);
	
	- this means you can't choke near the beginning/ how do i make choking really common? should be a way I can make a rider very very prone to it??
	
	
	- how abouts i make it a fully fledhed 4-param property? i know it maxes out at 1. as a prob it will be 0 unless the race is faster, sooo the choking can NEVER happen unless it is faster, and even then, only really towards the end, even if the rider is at maximum choke-level.
	

	
	
                  - make it a combo with the new-PB switch and ALSO a 'regular' weighted param.
				  
- need to add global settings for choke under pressure (to the two exisiting ones)

  		  
		"choke_under_pressure_switch": 0,
        "choke_under_pressure_amount_percentage": 0.5,
		
        "choke_under_pressure_rider_tendancy_weight":1,
        "choke_under_pressure_rider_tendancy_exponent":1,
        "max_rider_choke_under_pressure_tendency":10,
        "choke_under_pressure_new_best_speed_pressure_weight":1,
        "choke_under_pressure_new_best_speed_pressure_max":1,
        "choke_under_pressure_new_best_speed_pressure_exponent":1,
		

-- need to copy these changes to the same calc for the chasing rider 
start at

let prob_choke_under_pressure = 0;
...
...
prob_choke_under_pressure = ...

--hmmmmmmmm not really doing what i want? seems to only fail near the end, and also in a weird consecutieve way

- so, why oh why does it roll like this@
	{"188":[2,0.5],"189":[1,0.5,3,0.5],"190":[0,0.5]}
	and
	{"324":[1,0.5,0,0.5],"325":[3,0.5],"326":[2,0.5]}
	
- seems like the effect is always 0.5??

- ah, it is a fixed amount choke_under_pressure_amount_percentage:0.5

- why don't all riders fail on the same timestep??
- add the rider name to the console log messages.

- perhaps it is working and the search is selecting for strategies that start really slow and the failure happens much later??
- i can see that failure is indeed happening.... how could i verify this, maybe by looking at all failures for a tiny population of 2 or 3 races?

- should the best time being looked at be the current generation or the GLOBAL? global, no??

yes, generation_best_time is currently being used
- created a new variable all_generations_best_time

- save some new CUP data 

- for generation population
    - for each choke event
	    - timestep of choke and finish time 
	- can then either work out and save or later work out:
	- % of riders that choke in a generation 
	- avg. timestep of a choke event 
	- avg. finish time of races with at least one choke event
		
		
- adding generation result properties 
generation_results.percentage_of_riders_that_choke = 0
generation_results.average_timestep_of_choke_event = 0;
generation_results.choke_event_timestep_pairs = [];

	- reset a new array for a race to store any choke events 
  let race_choke_under_pressure_events = [];
  
  - log the timestep 
    race_choke_under_pressure_events.push(race_r.race_clock);
	
	- at the end of the race, create pairs of timestep and race finish time


    //create choke_under_pressure data points (if they exist)
      let sum_choke_under_pressure_timesteps = 0;
      
      if(race_choke_under_pressure_events.length > 0){
        for(int cup = 0;cup<race_choke_under_pressure_events.length;cup++){
          choke_event_timestep_pairs.push([race_choke_under_pressure_events[cup],Math.floor(finish_time)]);
          sum_choke_under_pressure_timesteps += race_choke_under_pressure_events[cup];
        }
      }
	  
	  - so, need to move most of this code OUTSIDE the race loop. first need to return results.
	  
	  - retuen this 
	  
	  race_choke_under_pressure_events_result:race_choke_under_pressure_events
	  
	  - need generation level variable(s). ooh they already ar ein this scope. add one more 
	  let sum_of_choke_events = 0;
	  
	  - add three columns after CHOKE UNDER PRESSURE NOISE in the results 
	  
	  - issue, weren't logging the chasing rider CUP events.
	  
	  - again, the results are BLANK for those nw columns, so something is getting lost?
	  
	  - now they're showing, had been zeroing the results values by mistake after setting them 
	  - need to round the timestep
	  
	  - so, the amount of CUP events falls over time, as expected, since fewer races exceed the fastest found, so they don't set new PBs.
	  - CUP is workign as a direct impediment to fitness-biased convergence? It can be set to heavily punish races that look like they are going to perform well.
	  
	  - shoot, had drop instructions turned off
	  
	  - how can percentage_of_riders_that_choke be > 1? I see 3.15, for example.
	  
	  -- hmmmmm, 432309 for... oh, thats sum_of_choke_events_timestep_in_generation, it shouldn't be that, it should be the count of chokes not the sum of their timesteps
	  
	  - what to include then in the writing about CUP...
	  - compare the fitness bias in the search with the opposing effect of failure when finding a better time. 
	  
	  - create a new graph for raw data 
	  
	  cup_noise_events
	  
	  -  bring back best and average timnes 
	  stats_average_time
	  
	  
	  - mundee 11th.
	  
	  - need to add en example of instruction noise, plus its effect.
	  
	  - do i keep all the results in one area as before?	
	  
	  - hmmm, the mishearing noise is NOT being rounded... should round it!
	  
	  - rounded it, and made effort change range smaller 
	  
	  - ran 200 gens and put instructions into text.
	  
	  - need to highlight that the GA is not able to search very well.0,0.17,0.34,0.51,0.68,0.85,1
	  
	  -ok, so these ran, now i have a new image noise_mishearing_7_levels_2025-7-11_16-42.png
	  
	  - no noise 260.574
	  [[0,"effort=5"],[3,"effort=6.7"],[7,"drop=3"],[8,"drop=3"],[21,"drop=3"],[59,"drop=3"],[77,"drop=2"],[105,"drop=2"],[118,"effort=7.28"],[123,"effort=6.77"],[137,"drop=2"],[142,"effort=8.29"],[156,"effort=6.91"],[162,"drop=3"],[194,"drop=3"],[207,"drop=3"],[231,"effort=8.56"],[239,"drop=3"],[258,"drop=1"]]
	  
	  
	  - maximum noise . with noise 272.794  without noise 281.511 
	  [[4,"effort=7.06"],[32,"drop=2"],[47,"effort=5.37"],[62,"effort=5.88"],[71,"drop=2"],[90,"drop=1"],[96,"effort=5.85"],[104,"drop=1"],[135,"drop=3"],[163,"effort=6.44"],[169,"drop=3"],[186,"drop=2"],[189,"effort=7.07"],[191,"effort=5.15"],[192,"drop=1"],[199,"effort=4.720000000000001"],[200,"effort=5.45"],[201,"drop=1"],[209,"drop=2"],[212,"effort=5.3"],[215,"drop=3"],[216,"effort=4.59"],[225,"effort=6.93"],[237,"drop=3"],[241,"effort=8.68"],[269,"effort=9.4"],[272,"drop=1"]]
	  
	  - would be a good idea to run robustness tests on this... as part of the analysis stage 
	  
	  - but first, need to work on the overeagerness part. 
	  
	  - add reference about starting too fast 
	  https://www.runnersworld.com/uk/training/marathon/a62541938/tips-to-avoid-going-out-too-fast-in-a-race/
	  
	  - added. now try run the code. 
	    "overeagerness_switch":1,
        "overeagerness_race_distance_end_point":0.3,
        "overeagerness_effort_inflation_min_amount": 0.1,
        "overeagerness_effort_inflation_max_amount": 0.4,
        "overeagerness_exponent":2,	
		
		-crashes, line 3306 failure_level "is not defined"
		// prevent overeagerness if the rider is recovering from fatigue
            if(race_rider.endurance_fatigue_level < failure_level){
			
			-- can replace this by looking at the 'new'   race_rider.recovery_mode property (1 for on, 0 for off)
	  
	  -- ok, seems to run now. nothing logged. is this feature built? missing a rider property?
	  -- affects every rider, need to only affect instructions? move it elsewhere in the code? maybe after the instruction delivery mishearing noise section? except it is tied to the rider too, not just the instruction?
	  
	    let leadingRider = race_r.riders_r[race_r.current_order[0]];
    leadingRider.output_level = effort;
	
	-- kinda worked? produces this set of events: {"0":6.3,"3":6.9248,"13":5.952,"20":1.3287,"22":6.9688,"88":11.1684,"105":3.9116}
	- could make these more explainable, or do I really need to store the original values? 
	- just try to get them working on the replay page
	
	in load_race(), the values are loaded into instruction_noise_overeagerness_r
	
	- kinnnnda wurks, need to round the new vlaues.
	
	- trying to write formula but very confused, not sure how i was trying to build this, needs to be redone?
	
	- log the generation overeagerness events, log all effort instructions and whether or not they were altered by the noise?
	
	- create two new generation level arryas 
	generation_list_of_overeagerness_affected_effort_timesteps
	generation_list_of_NON_overeagerness_affected_effort_timesteps
	
	- in results make a new listing and function 
	over_eagerness_event_arrays
	
	- need to create new vars witin the race context/scope, they can't get at the generation level ones
	race_generation_list_of_overeagerness_affected_effort_timesteps	
	race_generation_list_of_NON_overeagerness_affected_effort_timesteps
	
	- seems to work, need to get the graph in sooooooon.
	
	- save the 6 diagrams created 
	overeagernessEffortInstructionsHistNOeffectGen0.png
	overeagernessEffortInstructionsHistNOeffectGen99.png
	
	overeagernessEffortInstructionsHistp3ditancemaxRidereffectGen0.png
	overeagernessEffortInstructionsHistp3ditancemaxRidereffectGen99.png
	
	overeagernessEffortInstructionsHistp5ditancep5RidereffectGen0.png
	overeagernessEffortInstructionsHistp5ditancep5RidereffectGen99.png
	
	# Aggregated effort instruction with overeagerness, Generation 0, $\theta_i=1$, $d_{oe}=4000/3$
	
	- create a diagram for the fitness per GA for those 3 tests 
	
	fitnessForOvereagernessTestOfThreeLevels
	
	ok, so much to do but feel at a loss again... nois enosie nosie noise. noie nosie nosien niosneiznioenisoneiosnioenosnionieo
	
	- run a test for each kind of the noise, to create a new comparison graph.
	
	
	
	- hmmmmmmmm i think i need to rework the performance failure altogether. 
	
	1- split out the probability and amount, they don't need to be linked the way I had them.
	
	- func calculate_rider_performance_failure_probability()
		
	- current version
	
	  let rider_performance_failure_probability = ((((Math.pow(effort,performance_failure_probability_exponent)/Math.pow(effort_max,performance_failure_probability_exponent))*performance_failure_effort_importance_multiplier + (Math.pow(current_fatigue,performance_failure_probability_exponent)/Math.pow(current_fatigue_max,performance_failure_probability_exponent)) + (Math.pow(accumulated_fatigue,performance_failure_probability_exponent)/Math.pow(accumulated_fatigue_max,performance_failure_probability_exponent)))/(3+(performance_failure_effort_importance_multiplier-1)))*(rider_performance_failure_rate/rider_performance_failure_rate_max));
	  
	  - use the method I built to handle weights etc/ with groups of four params 
	  
	  - calculate_linear_space_value(value_list, probability_variables)
	  
	  - value list needs groups of 4, [weight multiplier, value, exponent, max value]
	  - probability_variables is another array of modifiers, can send none. none in this case?
	  
	  - create 3 groups of 4, for effort/fatigue_current/fatigue_accumulated 
	  
	  - need 3 weights, rename globals 
	  
	  - rename performance_failure_effort_importance_multiplier to performance_failure_effort_weight
	  -rename performance_failure_probability_exponent to performance_failure_effort_exponent,
	  - need to add 4 new props in the globals 
	  - performance_failure_current_fatigue_weight
	  - performance_failure_current_fatigue_exponent
	  - performance_failure_accumulated_fatigue_weight
	  - performance_failure_accumulated_fatigue_exponent
	  performance_failure_current_fatigue_weight,performance_failure_current_fatigue_exponent,performance_failure_accumulated_fatigue_weight,performance_failure_accumulated_fatigue_exponent
	  
	  - added these to functino calls to calculate_rider_performance_failure_probability()
	  
	  - change in settings.
	  
	  - now change how the value is worked out. 
	  calculate_rider_performance_failure_percentage_amount() 
	  
	  - here I want just 2 values? min and max percentage that power is reduced by?? 
	  - old version is such a mess tbh 
	  function calculate_rider_performance_failure_percentage_amount(effort, effort_max, current_fatigue, current_fatigue_max, accumulated_fatigue, accumulated_fatigue_max, rider_performance_failure_multiplier,rider_performance_failure_multiplier_max,  performance_failure_base_max_percentage,performance_failure_amount_exponent,performance_failure_effort_weight,failure_type ){

    //how much will the rider fail by?
    // dk feb 22; adding a new version of this where the % of failure amount is more random

    //dk22 found issue where current_fatigue > current_fatigue_max sometimes... can happen 'legally'
    //set the upper bound to be current_fatigue_max and just limit current_fatigue
    if (current_fatigue > current_fatigue_max){
      current_fatigue_max = current_fatigue; //current_fatigue/current_fatigue_max will now max out at 1
    }

    //donalK25, try the same for the accumulated fatigue...
    if (accumulated_fatigue > accumulated_fatigue_max){
      accumulated_fatigue_max = accumulated_fatigue;
      //console.log("***dk25: adjusting accumulated_fatigue_max  since it is < accumulated_fatigue");
    }

    let rider_performance_failure__percentage_amount = (
      (
        (
          (Math.pow(effort,performance_failure_amount_exponent)/Math.pow(effort_max,performance_failure_amount_exponent))*performance_failure_effort_weight +
          (Math.pow(current_fatigue,performance_failure_amount_exponent)/Math.pow(current_fatigue_max,performance_failure_amount_exponent)) +
          (Math.pow(accumulated_fatigue,performance_failure_amount_exponent)/Math.pow(accumulated_fatigue_max,performance_failure_amount_exponent))
        )/(3+(performance_failure_effort_weight-1))

      )
      * (rider_performance_failure_multiplier/rider_performance_failure_multiplier_max)
    );

    if (rider_performance_failure__percentage_amount > 1){
      debugger;
    }
    //console.log("rider_performance_failure__percentage_amount =  " + rider_performance_failure__percentage_amount + " * " + performance_failure_base_max_percentage + " = " + (rider_performance_failure__percentage_amount*performance_failure_base_max_percentage));
    rider_performance_failure__percentage_amount  = rider_performance_failure__percentage_amount*performance_failure_base_max_percentage;

    //check the type to applying#
    let version = 1;
    if(failure_type){
      version = failure_type;
    }

    if(version == 2){
      // make it a probabilitsic range from 0 to the original amount
      let p1 = Math.random();
      let amount1 = (rider_performance_failure__percentage_amount*p1);

      // if (amount1 > max_performance_failure_percentage){
      //   max_performance_failure_percentage = amount1;
      //   //log info if this is really high
      //   console.log("####****max_performance_failure_percentage breached****####");
      //   console.log("max_performance_failure_percentage " + max_performance_failure_percentage
      //   + " rider_performance_failure__percentage_amount " +        rider_performance_failure__percentage_amount + " p1 " + p1 + " effort " + effort + " effort_max " + effort_max
      //   + " current_fatigue " + current_fatigue + " current_fatigue_max " + current_fatigue_max
      //   + "\n accumulated_fatigue " +  accumulated_fatigue
      //   + "\n accumulated_fatigue_max " +  accumulated_fatigue_max
      //   + " rider_performance_failure_multiplier " + rider_performance_failure_multiplier
      //   + " rider_performance_failure_multiplier_max " + rider_performance_failure_multiplier_max
      //   + "\n performance_failure_base_max_percentage " + performance_failure_base_max_percentage
      //   + " performance_failure_amount_exponent " + performance_failure_amount_exponent
      //   + "\n performance_failure_effort_weight " + performance_failure_effort_weight
      //   + " failure_type " + failure_type);
      //
      // }
      //console.log("Performance failure, adjusting from deterministic " + rider_performance_failure__percentage_amount + "to randomised " + amount1);
      return DecimalPrecision.round(amount1,4);

    }
    else // assume version == 1, i.e. the standard
    {
      return DecimalPrecision.round(rider_performance_failure__percentage_amount,4);
    }
  }
  
 -- now have calculate_rider_performance_failure_percentage_amount(performance_failure_amount_min,performance_failure_amount_max)
 - need to add those as globals 
	       "performance_failure_amount_min":0.1,
        "performance_failure_amount_max":0.35,
 - now, update anywhere that calls the func()
 
 - testing. performance_failure_effort_exponent is undefined
 
 - results url fails, maybe toooo long, need to ROUND the failures to 2 or 3 places??
    
	
- weirddd, it finds a very fast strategy, has a stack of failuires 



- run a sequence with increasing performance_failure_rate (riders)


{"iterations":7,"active":1,"variations":[{"iterations":[7,6,5,4,3,2,1],"type":"rider","rider_no":0,"property":"performance_failure_rate","values":[0,1.7,3.4,5.1,6.8,8.5,10]},{"iterations":[7,6,5,4,3,2,1],"type":"rider","rider_no":1,"property":"performance_failure_rate","values":[0,1.7,3.4,5.1,6.8,8.5,10]},{"iterations":[7,6,5,4,3,2,1],"type":"rider","rider_no":2,"property":"performance_failure_rate","values":[0,1.7,3.4,5.1,6.8,8.5,10]},{"iterations":[7,6,5,4,3,2,1],"type":"rider","rider_no":3,"property":"performance_failure_rate","values":[0,1.7,3.4,5.1,6.8,8.5,10]}],"experiments":[]}


{"iterations":7,"active":1,"variations":[{"iterations":[7,6,5,4,3,2,1],"type":"global","property":"performance_failure_amount_min","values":[0,0.17,0.34,0.51,0.68,0.85,1]},{"iterations":[7,6,5,4,3,2,1],"type":"global","property":"performance_failure_amount_max","values":[0,0.17,0.34,0.51,0.68,0.85,1]}],"experiments":[]}

- so, if the size of the p. failure gets higher the ability to be better than a non-noise version fades.

- add a random factor to the expression, can then test a 'descent into randomness'. into chaos?
- add property 

"performance_failure_accumulated_random_factor_weight":1,

- can fix the exponent to 1 and the max to 1.

- why is it FASTER with noise??

- is it becauase they are getting to recover more??

- I could display the amount of recovery in the game viewer??

- also add one more weight, to allow for a form where the result is rider_tendency-driven entirely, so w_x(effort/fatigue/etc)*rider_T )1-

-  "performance_failure_race_state_weight": 0,
- can this be part of the function call, it needs to be separate, no?

- ok, so can I make every rider fail by an exact percentage at every timestep?

-hmmm, nope nobody failed in the test at all?

- ohhh BUG, division by 0 returning a NaN, this is MAJOR. e.g. when fatigue is 0, failure doesn't happen.

- current_fatigue_max was not being passed in, current_fatigue was being sent in by mistake. yikes on a bikes.

- wait, is my race clock a second wrong, am i forgetting to add 1 since it is zero based??

- ok, so if the ALWAYS fail by 20%, it is basically deterministic and it can find a good result.

- if I set the rider tendency to 0.5 i can get all to fail by 0.2 50% of the time??

- maybe delete all of the existing performance_failure results?? can't relly use them given the NaN bug?

- where does it get the accum. fatigue max from?

- 4 tests 100 gens 
- A: constant amount of 0.2 every rider every timestep performance_failure_example_A_fixed_amount.png
- B: accumulated fatigue only, exponent 2, value 0-0.8, all riders 10
- C: all riders 10, all weights 1 except for w1=0.5, so eery factor is enabled, all exponents 1, value = 0.1-0.9
- C: 1 rider only, random + effort equal weights, others zero, value 0-0.8.

- still dividing by zero if all the non-random factors are weighted to 0... end up with a NaN again.

- fixed NaN issue, reran the tests of the 4 setups
- add them as images- need a group of 4 images 

- 4 images in - they are badly positioned though. how can i get them to appear in a better place in the text?

- add the 4 finish times to the graph captions. 

- 4 graphs in and a discussion about each. damn seciton is still not done though.

- create a sequence for 7 levels of all-factor failure. can copy the one I ran in Portland.

- still left to run for six types comparison:
	- no noise	
	- mishearing+perf. fail.
	- mishearing
	- delays only
	- performance failure
	- choke-under-pressure 
	- overeagerness 
	

- references not being found again, cursafook on it. 
- downloaded a bibtex checker python script called /BibLatex-Check, see https://tex.stackexchange.com/questions/173621/how-to-validate-check-a-biblatex-bib-file
- to run 
./biblatex_check.py <-b input.bib> [-a input.aux] [-o output.html]

-b (--bib=file.bib) Set the input Bib File
-a (--aux=file.aux) Set the input Aux File
-o (--output=file.html) Write results to the HTML Output File.
-v (--view) Open in Browser. Use together with -o.
-N (--no-console) Do not print problems to console. An exit code is always returned.



python C:\\Users\\donak\\Documents\\RESEARCH\\PythonChartsAndAnalysis\\bibtex_checker\\biblatex_check.py -b C:\\Users\\donak\\Documents\\RESEARCH\\thesisDraft1\\repository_files\\research_draft\\8_references.bib -o C:\\Users\\donak\\Documents\\RESEARCH\\PythonChartsAndAnalysis\\bibtex_checker\\biblatex_check_output.html -v

- fixed the bibtex issue, i had commented out most, but not all, of a reference, and it has an incorrect apostrophe in it, too.

- sections still not showing up properly, they are all listed under List of Tables??

- needed to include a chapter and then sections and subsections 


- how do i enable the search-test system? 


this is in the sequence: best_in_final_gen_tests

here's one sequence

{"iterations":21,"active":0,"variations":[{"iterations":[21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1],"type":"global","property":"enable_instruction_noise_1_random","values":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]},{"iterations":[21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1],"type":"global","property":"noise_1_probability_instruction_misheard","values":[1,0.95,0.9,0.85,0.8,0.75,0.7,0.65,0.6,0.55,0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15,0.1,0.05,0]}],"best_in_final_gen_tests":[{"iterations":21,"repeat_each":20,"variations":[{"type":"global","property":"noise_1_probability_instruction_misheard","values":[1,0.95,0.9,0.85,0.8,0.75,0.7,0.65,0.6,0.55,0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15,0.1,0.05,0]}]}],"experiments":[]}

- make a little one 

{"iterations":3,"active":1,"variations":[{"iterations":[3,2,1],"type":"global","property":"enable_instruction_noise_1_random","values":[1,1,1]},{"iterations":[3,2,1],"type":"global","property":"noise_1_probability_instruction_misheard","values":[1,0.5,0]}],"best_in_final_gen_tests":[{"iterations":3,"repeat_each":5,"variations":[{"type":"global","property":"noise_1_probability_instruction_misheard","values":[1,0.5,0]}]}],"experiments":[]}

- only runs on the final generation 

- gets stored in best_in_gen_tests_results 

- ok, well it does... something. encourage

- seeeems to return results, e.g., for 3 levels of search noise and 3 levels of test noise

[[1,1,307.2078],[1,0.5,300.3264],[1,0,305.323],[0.5,1,302.9846],[0.5,0.5,303.3532],[0.5,0,310.642],[0,1,301.4402],[0,0.5,289.265],[0,0,280.45]]

- can I graph this? 

- the graph I'm looking for is LandScapeGraph3dWIthNoiseVersion1.py 

- search with no noise and test with a bunch of values 

[[0.7,1,254.457],[0.7,0.95,254.457],[0.7,0.9,254.457],[0.7,0.85,254.457],[0.7,0.8,254.457],[0.7,0.75,254.457],[0.7,0.7,254.457],[0.7,0.65,254.457],[0.7,0.6,254.457],[0.7,0.55,254.457],[0.7,0.5,254.457],[0.7,0.45,254.457],[0.7,0.4,254.457],[0.7,0.35,254.457],[0.7,0.3,254.457],[0.7,0.25,254.457],[0.7,0.2,254.457],[0.7,0.15,254.457],[0.7,0.1,254.457],[0.7,0.05,254.457],[0.7,0,254.457]]

- ah shit, ahve to rerun that, noise was never turned on :-( 

- run a big one and go to bed 
{"iterations":21,"active":1,"variations":[{"iterations":[21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1],"type":"global","property":"enable_instruction_noise_1_random","values":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]},{"iterations":[21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1],"type":"global","property":"noise_1_probability_instruction_misheard","values":[1,0.95,0.9,0.85,0.8,0.75,0.7,0.65,0.6,0.55,0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15,0.1,0.05,0]}],"best_in_final_gen_tests":[{"iterations":21,"repeat_each":20,"variations":[{"type":"global","property":"noise_1_probability_instruction_misheard","values":[1,0.95,0.9,0.85,0.8,0.75,0.7,0.65,0.6,0.55,0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15,0.1,0.05,0]}]}],"experiments":[]}

- Aug 20,

- sequnce didn't run for the ones over 10??

ok, so i figured it was to do with the SIZE of the results it is trying to save, and this does seem to be the case. 
- error is 
{ client_id: '86.45.238.255_2025_7_20_10_44_26', iteration: 21 }
save new results
*******ERROR SAVING EXPERIMENT RESULTS*******
RangeError [ERR_OUT_OF_RANGE]: The value of "offset" is out of range. It must be >= 0 && <= 17825792. Received 17825794
    at validateOffset (node:buffer:112:3)
    at Buffer.write (node:buffer:1063:5)
    at serializeString (C:\Users\donak\Documents\RESEARCH\TeamPursuitModel\experiment_server\node_modules\bson\lib\bson\parser\serializer.js:33:14)
    at serializeInto (C:\Users\donak\Documents\RESEARCH\TeamPursuitModel\experiment_server\node_modules\bson\lib\bson\parser\serializer.js:919:17)
    at serializeObject (C:\Users\donak\Documents\RESEARCH\TeamPursuitModel\experiment_server\node_modules\bson\lib\bson\parser\serializer.js:347:18)
    at serializeInto (C:\Users\donak\Documents\RESEARCH\TeamPursuitModel\experiment_server\node_modules\bson\lib\bson\parser\serializer.js:727:17)
    at serializeObject (C:\Users\donak\Documents\RESEARCH\TeamPursuitModel\experiment_server\node_modules\bson\lib\bson\parser\serializer.js:347:18)
    at serializeInto (C:\Users\donak\Documents\RESEARCH\TeamPursuitModel\experiment_server\node_modules\bson\lib\bson\parser\serializer.js:937:17)
    at BSON.serialize (C:\Users\donak\Documents\RESEARCH\TeamPursuitModel\experiment_server\node_modules\bson\lib\bson\bson.js:64:28)
    at Msg.serializeBson (C:\Users\donak\Documents\RESEARCH\TeamPursuitModel\experiment_server\node_modules\mongodb\lib\core\connection\msg.js:124:22) {
  code: 'ERR_OUT_OF_RANGE'
}
getting list of active sequences

- redcued gens to 150, trying to run those TEN GAs again.

- theey now seem to be running. yay. Where even is the MongoDB stored?? Need to make sure I back this up!!
- added it but didn't run it, not sure where i have space :-( 

- BUG, replayign mishearing noise in the player, something NOt being reset. drop q? 

- still waiting for the average-of-4 experiments to finish 

- build a diagram showing the instructions in the best-in-gen strats for rising levels of noise. need to collect a lot of data for this. can also include the number of effort and drop lines.

- built this diagram and added it... not a lot of findings tbh, it doesn't agree witht the idea I had before where the number of instructions falls as noise goes up. why??

- try to create the instruction scatterplot with new data 

- issue: it only logs gen 0 and gen 49... surely it should by default log the LAST gen?
- it's actually in the global settings, tells it which gens to log.

- could default it to alwasy log the last gen? or work with what's there?

- should do a run for a different team setup?
- ran overnight for 3 more team types, need to collect data, can use 3 graphs for each:
- 1: 3d landscape of search and test 
- 2: effort instruction scatterplot, generation 150
- 3: drop instructions, genertion 150

- bollox, the tests didn't save the instructions for generation 149 :-( 

- bug, if i rn a search-test set with rider props, the output is messed up, all the triples have 0 as the first value

- ah ok, in app.js it assumes we are going to log the mishearing value as the first value, but here we are using the rider property

return_data_element.best_in_final_gen_noise_value = ga_settings_c.noise_1_probability_instruction_misheard;

BUT we don't know that all the riders are set to use the same prop value, it could be anything... i can manually add these values?

- perf fail speeds

- p.f. = 1, best time, last gen = 270.987
- p.f. = 0.5, best time, last gen = 260.23
- p.f. = 0, best time, last gen = 260.442


- analyse 1 strong/3 weak 

Timestep of the earliest drop instruction for final best-in-gen strategy for GA searches with rising levels of noise. As mishearing becomes common, early lead changes tend to disappear to allow the one strong rider to remain at the front


[[2,"effort=6.88"],[53,"drop=1"],[61,"drop=1"],[75,"drop=1"],[102,"effort=5.27"],[108,"effort=5.35"],[109,"effort=5.35"],[129,"drop=2"],[134,"effort=6.37"],[148,"drop=2"],[155,"drop=3"],[158,"drop=3"],[178,"drop=3"],[208,"drop=2"],[221,"drop=1"],[222,"effort=7.96"],[234,"drop=3"],[244,"effort=7.21"]]


{"33":{"original_instruction":[33,"drop=2"],"altered_instruction":[33,"drop=3"],"type":"random_drop"}}


- cussed references broke agin

- they seem to work in the test file??

- can graduyally add bits of the doc back in to check?

- weird, seems to work if i copy everything to the other file. what was goign wrong then?

- need to add a conclusion to the noise part 

- compare noise 0.4 with and without AVG 
search_and_test all_equal perf_fail compWithNoAVG

- writing some of the intro.



The main problem with the
manuscript is that there are insufficient details to allow for experimental repeatability .

"One thing that is missing is details of the simulation environment. Is the cycling simulation an existing simulation model? If so, cite it . If not, it is important to provide some details on this . What simulation framework/library/etc is it implemented in? Or is it a custom simulation? Is the simulation publicly available , and if so, where?"


- describe the GA in more detail, to make it more replicable. need to link to the source code so that the simulation is publically available (GitHub)
- selection type 
- elitism 
- mapping from genotype to phenotype 
- mention that it is a custom code. how do I cite or include this?
- from https://academia.stackexchange.com/questions/20358/how-should-i-reference-my-github-repository-with-materials-for-my-paper

: "Such resources, especially if they are a supplementary to the paper, i.e. in some sense a part of it, should be referenced in a footnote and not in bibliography.

Do include not only the URL but also a short description; and do try to keep that URL valid - once you publish that link, it's frozen forever."

url to include; https://github.com/aramicon/TeamPursuitModel/tree/main/experiment_server



Reviewer 1:

It would be worthwhile to highlight how this approach builds upon existing robustness
evaluation techniques, and to benchmark the results against some baseline methods (such as manually
designed strategies, or other optimisers like particle swarm optimisation or reinforcement learning) to
better show the comparative gains in robustness and performance.

So, to improve its linkage to other research, need a few more references. But how can I benchmark it?

- need to edit the paper on overleaf, not locally... can work on adding the changes to the main doc later.

- added a footnote to link the github. 

- need to add some setup info on the github!

- added a comment describing the example on page 4

"The Related Work section is relevant but can be further improved by including more recent studies on robust evolutionary algorithms as well as applications in sports analytics"

- need to bed the work better into other work, esp. EC/robustness, e.g.,
@article{he2018robust,
  title={Robust multiobjective optimization via evolutionary algorithms},
  author={He, Zhenan and Yen, Gary G and Yi, Zhang},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={23},
  number={2},
  pages={316--330},
  year={2018},
  publisher={IEEE}
}

This, from 1998 has quite a few citations 
@inproceedings{branke1998creating,
  title={Creating robust solutions by means of evolutionary algorithms},
  author={Branke, J{\"u}rgen},
  booktitle={International Conference on Parallel Problem Solving from Nature},
  pages={119--128},
  year={1998},
  organization={Springer}
}

they mention the average quality of the phenotypic neighbourhood of a solution. "a solution on a high plateau should be preferred over a solution on a thin peak"

"The standard EA by nature favors hills over peaks"

I could use a description like this one? "As simple EA we use real-valued, direct encoding of the decision variables, generational replacement with elitism (i.e. the best individual survives), ranking selection, two-point-crossover, mutation rate of 0.1, and an island model 1 with 5 subpopulations, 50 individuals each, run for 500 generations. The same settings are used throughout all experiments unless stated otherwise."

"duplicant avoidance"	w(y) e< p(5) such that y = x + 5.

- how do i find a result used for a specific test? can just search through the results page, and add some specific tag to narrow them down if searching again? 
- data_used added that as a tag ]


- updatign images.

rm_iv_fitness_spread_comparison_two_strong_200gens_Jun18

Fig 1 and Fig 2 have NOT been changed, since they are from the d3 code. Will need to go back to this.

- monday sep 15th, write part of intro to new chapter. 

- find at least one reference to cite- good one from France in 2018 9Scelles, Nicolas and Mignot) studying actual breakaways in le Tour.

scelles2018temporary

"a breakaway can be seen as a coopetitive temporary organizational form"

- coopetitive is mixture of cooperation and competition, a real word.

- design questions for new work.

How do the riders start?
is it a standing or flying start?
How is the stratign order defined?
Will the starting order be part of the genotype?
Can there be multiple groups or one group?
How does a group leader decide how fast to go?
How does a group leader decide when to drop back?
	- could stay on the front until the acheive a certain percentage that they are happy with... e.g, the group size is 4, they spend 1/4 of some distance there?
	- 1/4 of what?
If they drop back, how many spaces do they drop back?
If a rider chooses to NOT cooperate, do they hide at the back or come to the front and immediately drop back?

Can a rider choose o sprint from any position?
	- yes, they generally do not sprint from the front.
What's the difference between a sprint and an attack?
If a rider attacks, how hard do they go?
If a rider attacks, how do they transition to a steady 'solo' state? 
	- perhaps the size of the gap they open up is important?
If a rider sprints, how far/long do they sprint for?
	- until they cross the finish line or failure?
	- what about an intermediate sprint?
		- maybe don't model that?
can a sprint, or an attack, be visualized?
	- sure, the they could pull alongside and have their state displayed somewhere 
How will a cooperate state be translated into instructions?
	- need to develop some pseudocode. If they are leading they lead until a certain point then drop back, otherwise if they assume the lead, they begin to copperate 
	- Again, how do they choose the power/effort level?
How do attributes translate in general to specific instructions? 
	- probabilistically. the default state is to be in a group and cooperating to some degree- this degree can be zero, e.g., for a hiding sprinter. however a rider will have some probability at every timestep of attacking or sprinting.
How are an attack and a sprint related?
	- closely, but an attack is generally further from the finish and will generally need to transition to a sole state or back to a group state before the race finish.
	- Could a sprint therefore not just be a very late attack at high ppower?
		-yes, but I haven't figured out how to model the power and duration of an attack. A rider might attack with less power than their final sprint, and if so, how do manage this? 
		- Could you include another dynamic property, like "attack-strength" that could change via strategy as the race goes on?
			Possibly. I might try to build it this way and see if it works.
When does the race finish?
	- when all riders have crossed the line: each rider will be given a finish time, and a placing. This should be visualised.
Why use distance and not time to specify attribute instructions?
	- well, consider a sprint: a rider will lanuch with a certain distance remaining. This is harder to do with time.
	- why didn't I use distance for the original?
		- good question. it seemed to make more sense that riders would be dividing up the time on the front. They are deeply related. A strategy in terms of distance seems to make more sense, it is independent of the speed/time taken. The time seems more relevant in the case of the track pursuit?
How long will the race be?
	- can experiment with different values, probbaly somethign like 5km to allow for various happenings?
How does the bunch catch the breakaway?
	- the chasing bunch will have a fixed pace. Once it passes a rider that rider's race is over, so when it catches all riders, or all riders ahead have finished, the race ends.
	- Will this be visualised?
		- yes, the peleton will appear as a chasing figure, but at a slightly different 'lane'. Riders will change how they look somehow when 'absorbed'. Their race after that is not considered.
		Is the peloton not much more dynamic than this?
			- yes but that's being left out of the scope. i may have to simply even more.
			
How do I make these groups really dynamic, e.g., with complex rules, e.g.,
	- a rider will chase down a non-teammate but not a teammate, and it will refuse to work with another rider IF its designated leader is waiting behind.
		- I could add team designations and roles, and decision making logic for these specfic scenarios? I could later test the GA with these roles, e.g. evolve a teamate, but this means that the propensity to chase down a teammate or non-teammate needs to be IN THE GENOTYPE. This might get way too complex?
	- a rider will attack with higher liklihood if others are not cooperating. 
		- again, this couple be rendered as in-game decision-making tied to properties that can be updated in the genotype (and subject to variance).
	- riders that chase down the strongest rider every time, but are less worried about a lesser-known or weaker rider. I.e., their strategy is tied to specific opponents and has complex rules.
		- how could I even model this in a genotype? As another 'propensity'? I will have sooo many things to tune?

How do I test basic aspects of racing, e.g. that if all riders are equal, the one who has worked the least in the race, i.e., the freshest, will win the sprint?
	- can test and tbh, adjust settings to make this so.
	- in real sprints, riders wait behind until the last possible moment. Will this happen?
		- maybe, but we may have to express sprints purely in terms of distance. 
		
		
	

What data would I need to record?
	- When it comes to saving GA results, all the setup config settings, then for each rider, every instruction they are issued during the race: it will need to be fully re-playable, like with the original. I will need to be able to show the power of riders but also some other form of visualisation to 'see' what happened in a race. Maybe some kind of graph that shows the race state as the time passes, like a vertical series of coloured dots?
what experiments would I need to run?
	- i need to come up with a sequence, beginning with something very simple.
	1: no strategy, riders cooperate by default until they finsish 
	2: cooperation levels: each rider is given a different level of cooperation 
	3: target group effort level: each rider is given a different level, so that when they are on the front, they rider at this level. The others, for simplicity, may just follow, or they might apply some kind of rule, e.g. "if the group goes too slow i will take over at the front." I might ignore this for now and mayyybe add it later.
	4: sprints: riders are given property changes near the end to raise their chance of a sprint attack.
	5: attacks. riders are given earlier property changes to give them a liklihood of attacking.
	
	10: can I run an experiment where the fitness function is based on the team, i.e., a win for the team is highly valuable, and the evolving rider has a stronger-finishing teamamte- might they evolve behaviour to cooperate more, and chase down non-temamates?
	
	
	
What is the core research question?
	-  Can we model this scenario and use a GA to search for strategies?
	- Is this enough? Does it need more detail and precision? What domain is it contributing to?
	- It highlights the delicate scenario and how cycling, and sports as a whole, can include sophisticated problems of coordination and cooperation. it also provides insight into how a simulation migh be built, its limitations too, and perhaps add something to our understanding of breakaways, perhaps even how a rider should act in them.
	- Do you think the model will be good enough to have something to say at the level of the coach or athelte?
		No, tbh, I think that would be a bigger project. But it may suggest a way of doing it.



- create a new game page
- add it to the mage menus 

- created page and updated menus 
- original race now does not run (only works when opened via results page via link)

- let's add a dropdown to select a settings config that is then loaded, rather than typing in details here (will help later on, too)

- copied experiment_names control from the GA page.
- need to inlcude populateNamesDropdown function 
- and getExperimentNames()

- now make the dropdown selection do what the load_details_from_url() used to do.


- key lines 
  race = JSON.parse(data[0].race_settings);
          settings = JSON.parse(data[0].global_settings);
          riders = JSON.parse(data[0].rider_settings);

          $("#global_settings").val(data[0].global_settings);
          $("#race_settings").val(data[0].race_settings);
          $("#rider_settings").val(data[0].rider_settings);

          $("#database_connection_label").html("<strong>Loaded Settings "+data[0].name+"</strong> | _id | <span id = 'settings_id'>"+data[0]._id);
          $("#new_settings_name").val(data[0].name);

          //set the id (global)
          selected_settings_id = data[0]._id;

- not running, needs a team order at least? and blank instructions? 
$("#teamorder").val(DEFAULT_TEAM_ORDER);

- race object exists but race.riders is blank, must need to set this... need to run

-- hmmm, so took out all the noise code as best i found, it runs but the power graph looks very wonky indeedy.

- it's wonky because default_starting_effort_level is set to 2. If i set it to 8, it looks very different- looks like it is running as expected.

- try pasting in some instructions.

- yes, if i run the GA then copy/paste the final instructions, the race gets the same time.

- look at code that draws the turns/etc. how do i draw a LINE instead?

- can get the riders to never 'leave' straight1, i.e. go in a stright line, but the quickly leave the screen, start in the wrong place, and are goign the wrong way 

- take out the backgorund image to help visibility.

- if i update "track_centre_x": 10 and "track_centre_y": 370 settings I can better position the start- though it is not a flying start.

- can I use the scale mechanism to keep the whole race 'in the box'

the scale amount is settings.vis_scale. can this by dynamic, to fit in the whole race no matter how big... would take a lot of work to have a moving frame?

- scale works BUT the offset has disappeared.
- maybe it's 'right' but the dots are too big to show the gaps? in terms of the scale as a whole?
- tried with a race length of 100m and yes, the gaps are much bigger in this one. so do I need some kind of sliding window?

	Let's draw a finish line...
    // ************* draw a finish line START *********** 
    ctx.beginPath();
    let race_finish_point = DISPLAY_LENGTH;
    ctx.moveTo(race_finish_point, 0);
    ctx.lineTo(race_finish_point, 150);
    ctx.stroke();
    // ************* draw a finish line END ***********
	
- add 2 props to try and model a chasing bunch 
 "chasing_bunch_starting_gap":200,
       "chasing_bunch_speed":11, (metres per second)
	   
- need to draw a line for this... gets a bit longer each time...

- add a new prop to each rider to signal how many timesteps they will spend at the front of a group 
                "breakaway_cooperation_time":12,
- whenever they get to the front of a group, they keep track of how long they spend there, and after the clock expires, they add a new drop instruction, which tells them to go to the back of the group at the next timestep

- do i need to remove the leading/chasing distinction entirely?

- also how the hey am i going to get the instructions code to work if all rider can be issued instructions???

- would need to add an instruct to race.race_instructions_r[]
// **** cooperation effort check START ****

- addded this to load_race() 
  load_rider.time_leading_group = 0;
  
  
- note we will need to scrap the limitation on 1 instruction per timestep, will need to be 1 instruction per rider per timestep?

- kinda works, but i think it is still limiting WHEN the drops are allowed- if i set breakaway_cooperation_time to 0 for a rider they still spend quite a while on the front. 

- took out bend material 

- rider told to drop back NOT dropping back because of the rule that only one rider can drop back at a time... what happens if I take this out?

- add a new prop for attacking probability to each rider 
 "breakaway_attacking_probability":0,

- need to create a new state in the race, called "ATTACK", which is very like "LEAD" but involves 
- version 1, only attack from a following state (never off the front)
IF your current state is FOLLOW, at the end of your move, decide if you will attack on your next turn
1- picking an amount to raise your output level by 
2- picking a duration of attack, some number of seconds 
3- holding that output for the duration (if possible) 
4- then, if you are ahead by some fixed amount, transitioning to a "SOLO" state



hmmmmmmmmm 

added a random check for attacking at the end of the FOLLOW code. 
let attack_choice = Math.random();
      if(attack_choice < race_rider.breakaway_attacking_probability){
        race_rider.current_aim = "ATTACK";
        race_rider.breakaway_attack_duration_elapsed = 0;
      }
Lots of questions- can you attack right at the beginning as everyone is still accelerating?
- let's add a basic earliest attack time to allow the riders to get up to speed? 

- add props to the rider for the duraiton and level increase 
               "breakaway_attack_duration":10,
                "breakaway_attack_effort_level_increase":2,  
				
- now at the beginning of moverace, maybe treat the rider as a LEAD rider and see what happens?

- hmmm, need to have some kind of transition to a SOLO state, so add a basic level to the rider props 
               "breakaway_solo_effort_level":6,
			   

- what is he difference between lead and attack and solo???

- maybe create a grouping system, where more than one can form
- can use an array parallel to race.riders
race.riders_groups

  "breakaway_riders_groups":[],
  
  the position of the rider is i, the rider is race.current_order[i]...  we loop through the current order for each timestep
  
- hmmmm, race.breakaway_riders_groups ends up containign a NaN

- works but the attacker almost immediately drops back  
- is adding a drop instruction from the cooperate check
- still brokened
-race_rider.breakaway_attack_duration_elapsed is undefined 

drop is comign form the 'real' leader and switchLead() is being called for the attacker??

- oh crap, now there's no leader, the first rider drops back and nobody takes over. the switch lead is broken?

race distance being overwritten by update_race_settings() - can take this stuff out??
- commented out all calls to the function for now.

- tuesday 23rd.

work on the CHASE and the SPRINT.

do all riders spritn at the end?
what influences their decision to sprint?

- create a spreadsheet to model the sprint and chase decision making 

=((C9*(POW(F9,D9)/POW(E9,D9))) + (C10*(POW(F10,D10)/POW(E10,D10)))+ (C11*(POW(F11,D11)/POW(E11,D11))) + (C12*(POW(F12,D12)/POW(E12,D12))))/(SUM(C9:C12))

need lots of params here, exponents, weights, rider props...

// distance to begin considering a sprint 
"breakaway_max_sprint_distance":400,

copy across the function calculate_linear_space_value(value_list, probability_variables)
needs quartets of values   //[weight multiplier, value, exponent, max value]
and a list of modifiers that are multipied in, the probability_variables (empty here, or could put the rider sprint_eagerness in here?)

- added new rider prop 
              "breakaway_sprint_eagerness":5,
- need new props for quartets for factors 
	"breakaway_sprint_inverse_remaining_distance_weight":1,
	"breakaway_sprint_inverse_remaining_distance_exponent":1,

- how to implement the sprint?
- assume there is no end, ithey try to sprint until the very end.
- assume they go all out or almost all out? can add a new prop, e.g.,
              "breakaway_sprint_effort_level":9,
- or, couls just go to max? (10).

- ok, so they are launchign a sprint but don't stay in that  mode



race.current_order should be updated at each step- the rider distance should be used... but riders dropping back should be left as is, in their new target positions.

- need to really improve the visuals of the race finish.

- sprinters get lanes 
- winner is marked and final positions and times of all are marked.
- final gap of peleton is marked.

if peloton makes the catch, this is marked.

firstly, stop the riders from disappearing after the end.

- hmm, maybe they are just off the screen and need more space??

- maybe use breakaway_riders_groups and STATUS_LANE_POSITIONS.SPRINT and STATUS_LANE_POSITIONS_LANE_WIDTH to have an idea that-

- when you sprint you get your own lane.
- this lane is the lowest integer that is not already a lane (so not necessarily a max()) 

- ok, can now kinda see it, need to record the finish time of riders as they cross the line, and then display them- each rider will have a finish time.

  let extra_distance_covered = last_rider.distance_covered - race.distance;
  let finish_time = DecimalPrecision.round(((race.race_clock-1) - (extra_distance_covered/last_rider.velocity)),3);
  
- add a finish_time to rider props. 
- also added              "finish_position":-1,
- and need somethign in the race to know how many have already finished?
race.riders_finished = 0;

- need to work on the finish positions, they seem to be off...

- basic sprint seeems to work, but has only one factor... but let's keep it that simples for now.

- rider who coops cannot set a new power?
- add a new rider prop to set a power level when they take the group lead??

               "breakaway_cooperation_effort_level":6.2,

- seems to work, gave each rider a different value as a test.

- start looking at bsic CHASE mechanism.

- choose to chase at the end of the timestep

- the ATTACK choice is too simplistic, needs to use the same format as SPRINT? with weights and exponents and multiple factors?

    let race_rider = race.riders[race.current_order[i]];
	
- maybe only check sprint prob if breakaway_sprint_eagerness > 0?

- is a rider sprinting, stopping, and sprinting?

- seems to be working ok for now, move back to the CHASE 

note: can create an inverted parabola shape, like a normal cirve, with an expression like (1-((x-m)^2/m^2))

add rider prop 
              "breakaway_chase_eagerness":3,
			  
and global 
       "breakaway_chase_inverse_distance_weight":1,
       "breakaway_chase_inverse_distance_exponent":2,
       "breakaway_chase_eagerness_maximum":10,
	   
also, the number of riders ahead 
       "chase_number_of_riders_ahead_weight":1,
       "chase_number_of_riders_ahead_exponent:1,
	   
add a 3rd property of 'freshness'

1 - (race_rider.endurance_fatigue_level/race_rider.rider_fatigue_failure_level) 
- have to make sure that endurance_fatigue_level can never be more than rider_fatigue_failure_level?

       "chase_inverse_fatigue_weight":1,
       "chase_inverse_fatigue_exponent":1,

- test the weights?

- attacks are too hard, the SOLO state leads to failure too quickly? Can I really have realistic attacks, solos, chases, etc???
- no, obvs 

- Mundee 29thee

- need to make a ton of progress this week.

- add a prop for the rider: the target rider that it will chase
- breakaway_chase_target_rider

- ok, the chase kinnnnnd runs, but badly. need to log what the target rider is?

- chase riders are not even being drawn. need to rework how the lanes are drawn and use breakaway_riders_groups somehow?
- need to use a combination of the group and the current_aim.

- added const STATUS_LANE_POSITIONS_BASE_POSITION = 180;

- the chasers are not changing their group properply?

- the GAP is wrong for a chaser 
- need to round the velocity being shown in the rider display - done 

- one of the riders is not visible. warum?
- no, it is there, but the gap is too small, the FOLLOW is on top of the LEAD

- how does a chase become organised, i.e., they share the effort? 
- maybe after some distance they revert to lead and follow?? but they are in the same group as the chasee.

- oh dear,. the bahaviour is so all over the place.
- rider 1 attacks, later rider 4 chases ctaches passes them, and is now way out in front but still 'chasing'

- fixed one bug.
- looks liek a rider goes into ATTACK and then immediately goes out of it again? 
- maybe track their aim from timestep to timestep?

in load_race()
    load_rider.current_aim_history = [];

- push current aim to this array each time moverace() runs.
- print these statuses when the race finishes.	
	
- need to display the gap to the chasing peloton AND the correct race finish time.
- ok, it prints, it'sa lot of data. n

- move 
  "chasing_bunch_starting_gap":400,
  "chasing_bunch_speed":11,
  
  into race from setings
  
  - redoing the race finsih, lots of odd code here.
  - need to mark a rider as caught... could simply make them disappear and stop moving? Go to the back of the bunch with a group of -1??
  
  - add a new rider aim/status of CAUGHT
    if(race.riders[x].distance_covered > race.chasing_bunch_current_position){
	
	- ooh, can use the riders_to_sort object to figure out the order/etc.
	- added a couple more props to that obj 
		- rider
		- distance_covered
		- current_aim
		- group
		
	- winner is either the peloton OR race.riders[riders_to_sort[0]]
	
	- we need finish_time, not distance_covered??
	
	- lots of changes, kinnnnda works, what happens if the peloton catches them??
	
	- hmmm, not picking up the peloton passing riders, maybe it is being updated later than it needs to be
	- oops, now it catches them right at the beginning!
	
	- oh, it updates it insie the rider loop (again) ... move it out. I can move it before or after all of the other logic... maybe move it BEFORE?
	
	- better, finishes. 
	- the caught riders keep moving. warum?
	- ok, so it just doesn't update the velocity... we could set the velocity to zero?
	- this seems to work.
	
	- attack transition should have a factor based on the gap to the peloton? 
	
	- can an attack become a chase? it happens... e.g. LEAD,LEAD,DROP,FOLLOW,FOLLOW,ATTACK,CHASE,CHASE
	
	- first, stop the attack-chase case.
	
	a- added 2 new consts 
	const BREAKAWAY_SOLO_TO_LEAD_GAP_SIZE = 5;
const BREAKAWAY_SOLO_TO_FOLLOW_GAP_SIZE = 5;

- note that in this model a rider might  never get out of failure mode.

- chasing seems to be broken :-( 

-- oops, the IF/ELSE IF makes no sense... it can only go in to ONE.
- have a rule whereby you can only make one decision, use a boolean to manage. 
- split it into a bunch of separate IFs rather than one IF/ELSE IF... construct.
- hmmm, now no chase OR attack.

- the attack has to be moved to the new section
- was missing () so a rider that attacked immediately went back to follow :-) 
- now have some CHASE and ATACK, but have single timestep ATTACK- warum?
- e.g., FOLLOW,FOLLOW,ATTACK,FOLLOW,FOLLOW,FOLLOW


 - bit of a mangled pile of poo tbh, how on earth do I get it to calm down?
 
 - show the breakaway group on the rider display 
 
 - show the chasee on the rider display
- added to display 
- attacker changing to lead, group becomes undefined. warum?
- hmmm, gap_to_chaser is -4272.33642092344
- oh, bugo in code. 

- the power graph only seems to show up to timesrtep 190 or so??

- ah, it expects all datasets to have the same lengths, and drawsn points for the lowest number- when a rider is caught, it stops adding values to the data.
- add 0 values to the rider_power_data array for riders that are CAUGHT

- good, fixed graph. 

now, big buggo
chaser goes to follow attacker, from LEAD role... goes into attacker group, but chases last rider in original group.

- if a leader chooses to CHASE, surely another rider must take over as the leader??

- here the issue is with current_order, which originally assumed that the rider to follow was (1) in the same group and (2) ahead of you in the actual array ordering.
- so, if we change group, we should move to the back of that group in the current_order array??
- have to be very careful as we are looping through that actual array :-( 
- can update current_order at the end of moverace()

- it is putting dropped riders in the wrong position, before the followers... not preserving their order

- need to assign a new leder if the leader of a group attacks. if they chase they just drag everyone else up?
- actually you can't attack from LEAD. But you can CHASE?

- first, maybe look at the transition from CHASE to FOLLOW?
- oh wait, I did this yesterday. so why is it all so messy?

- chaser 1 seems to go from leading group 1 directly to following group 2? or is that it goes to chase and then directly to follow?
- choice_made was not being updated?

- improves. but chaser 1 suddenly went from following in group 2 to following in group 0. warum?

- hmm, issue in chase-follow code? and will this not mean that a follower who chases will instantly revert to following?
- found bugs, it was not assigning the group properly, was using the group as an index to breakaway_riders_groups[]. le yikes.

- hmm, added code to select a new leader for a group, but it's not being reached, maybe because of the last change or changes?

- next issue... the second group is NOT rotating... warum?

- oh shoot... I'm not adding the rider ID to the drop instructions... I thought I already did this??

- need a new way to queue and follow drops 
- race.drop_instruction currently stores one value with no rider id. since there's only one per rider, could move this prop to the rider??

-- e.g. 
    race.riders[race.current_order[i]].drop_instruction = 0;
	
- kiinnnda works, but only one rider is dropping back? warum?

- technically, there are a couple of DROPs by another rider... but look at this: 
,LEAD,LEAD,LEAD,LEAD,LEAD,DROP,DROP,LEAD,DROP,DROP,LEAD,DROP,DROP,LEAD,DROP,DROP,LEAD,DROP,DROP,LEAD,DROP,DROP,LEAD,DROP,DROP,LEAD, 

Surely a rider should go from DROP to follow??


Oh, it ends up being 2 groups: SOLO/FOLLOw, and FOLLOW/FOLLOW

- why doesn't SOLO go to LEAD?

it seems to be too far ahead of the rider behind... but the gap shown is 2m. what gives? the offset maybe?

- the issue is that the attzacker has already moved, but the chaser has not... need to make this decision AFTER every rider has actually moved.

- tried making a whole new loop after all the riders ahve moved

- code runs but the issue is still there :-( 

- drops ony happen early in the race. warum?

drop=3 now only goes back 1 space when all are in group 0. warum?

i think the re-ordering is causing the problem?

- time on the front makes no sense now? the number is ust wrong

- when you try to chase, don't imeediatley revert to following riders in the group you are in... for some period try to chase the original target, then re-assess.

- need a new global prop.

       "chase_original_target_period":10,
	   
	   - need a rider prop to count how long it has been chasing
	   
	   load_rider.chase_period_time_elapsed = 0;
	   
- it does now chase and follow the attacker, but still very messy.
- work on getting the ssecond group to also switch the lead.
- log all drop instructions as they are created.
- seems to be creating the drops?? but not imping them?

- oops, need to rewrite how the reordering works, it is assuming a drop from position 0

- creates a drop=4 instruction, how is this possible?

- ooops, amkes current_order toooo long 
||||||||||| DROP: original_order 0,1,2,3 move 3 back 3 positions, new order 0,1,2,3,3 |||||||||||

-tried a fix, but still have 
||||||||||| DROP: original_order 0,1,2,3 move 3 back 2 positions, new order 0,1,2,3,3 |||||||||||

- Fixed some bugs, but non-chaser now doesn't actually drop at all after attacker 1 attacks.

- hmmmmm, still doign odd stuff 
||||||||||||| added drop instruction 52,drop=3,3 |||||||||||||
model3breakaway.js:1923 Race Complete/paused
model3breakaway.js:2293 button forward invoked.
model3breakaway.js:630 52 **FOUND INSTRUCTION** DROP: 3 rider Non-Chaser 4
model3breakaway.js:464 **** rider trying to drop back 3 but contiguous_group_size is 1

So- rebuilt how it works, race.contiguous_group_size is gone, replaced with undropped_riders_behind_me_in_group

- ok, so now a few riders drop?

- well, still when one rider moves from chase to follow, the OLD group does not get  anew leader

-ok, so maybe when a rider drops the wrong oher rider is updated to leader??

- seems to select a new leader BUT it is then changed to FOLLOW by the loop beginning line 600
- what happens if i remove this loop altogether?

- getting better. still odd transitions though. Attacker 2 goes from DROP to LEAD, without FOLLOW, while Chaser 2 goes from LEAD to FOLLOW,. no DROP

- is race_rider.number_of_riders_in_front wrong??

the gap shown for non-chaser 4 is wrong, way too high. warum?
- the % of time leading is also wrong, need to recalc it.

- gap i shown using display_rider.distance_from_rider_in_front
- set here   display_rider.distance_from_rider_in_front = min_distance;
- just need to factor in the groups here? 

- after one buggo, think it now works better. the slowness of riders to drop back is really noticeable. 

- now fix the time on front stat. related?
- what does this stat even mean now? leading the group, or leading the whole race? 
- leading the race may be more useful??
- stored in display_rider.time_on_front
- ok, that seeeems to work, what next.... look at the dropping back slownesss again.

- attacker 2 when dropping back stays at 440. 
- chaser 1 doesn't even go into DROP status, they FOLLOW, and with a power of 0. maybe since the gap is < 2m?

LEAD riders have a GAP until the DROP rider is actually behind them, maybe I should change this- the dropping rider would have pulled alongside?? That was the assump with the track race?
- hmmm, track model seems to have the same issue? maybe leave for now>

- debug attacker 2 when in DROP mode and timestep is 150+

so, attacker 2 is dropping back but even when this begins it has a lower velocity than chaser 1. is this becuase chaser 1 is stronger and moves to 450 watts when it takes over the lead

- maybe the issue is that attacker 1 keeps attacking whenever they follow?

- maybe i should factorize the attack decision so that they attack less mechanically?

- if there's one sprinter only and they sprint then fail, the oters will not pass it out - the all follow it, though they stay in their original gorup
- ran this test again and the sprinter comes last
- it defo happens sometimes 

- found it, happens if the sprinter sprints from a LEAD role. so shodl be fixable?

-- adda time leading group property to each rider
- time_on_front_of_group added to race_rider

- seeems to work, moved it before the dispolay code to fix a little issue.

- now need to use this to measure group cohesion... groups are fluid, but don't want to lose info on a rider

- record number of turns on front?

race_rider.number_of_turns++;

- update this whenever you transition AWAY from leading.. can then use time_on_front_of_group/number_of_turns to get an average time of turn?
- seems to be updating it TWICE. warum?

- ok, seems to be useful, round the value shown...

-- adding code to have a zoom switch that runs the race over smaller segments so we can better see what is happenign (want to use a graphic using a screenshot)

- need to link the drawing of the finish line with the race.distance value?
- can use CURRENT_ZOOM_SEGMENT_NO 

- need to display the current segment value?

- draw some distance lines with text on each segment?
SEGMENT_DISTANCE_MARKERS_TO_DRAW

- the race distance doesn't adjust when I go step by step. warum?
race_info_lap
- moved code a little, works now.

- start looking at the ATTACK choice, need to add factors?
- add group_cohesiveness

- basic attack form added.... attacks shoudl not happen if the riders are very cohesive?

- if a rider is being caught, they will either follow another group, or that group will follow IT, but if it is going slower, it is important that it FOLLOWS- at the back of the bunch?
- the attacker attacks even though it is fatgiued.

- cohesiveness- test if attacks happen when the riders are all co-operating. 

- weirrrd. have 3 leaders, all in the same group! arrrrg. warum? - fixed, ahd = instead of == :-o 

- added fatigue factor, copied from chase 
- add a 'are we goign too slow' factor?
- need to use chasing_bunch_current_position and chasing_bunch_speed


- if an exhausted rider gets caught, they need to attempt to follow, they should not become the leader

- if you are caught by a faster rider, you always go to the back of their group 
- if you pass a slower rider, ignore them, pass them, let them decide to follow you
- just making it DROP doesn't really work... maybe calling switchLead(positions_to_drop_back, rider_no)??

- fatigue factor needs to consider accumulated fatigue as well as current. in one weighted factor. half half?

how do we measure accumulated fatigue??
race_rider.accumulated_fatigue, settings_r.accumulated_fatigue_maximum, 
race_rider.endurance_fatigue_level, settings_r.fatigue_failure_level is for the current fatigue level?

- want to also do this for the chase to keep them the sames 

- group 0 manages to get stuck with one DROP and one FOLLOW, with FOLLOW behind DROP

- Chaser 2 manages to end up in group -1. um. see this again for the same rider after dozens of more tests. how do i debug this?

- drop state is weird- other riders can do stuff while you are dropping. how do you respond?

- if you are dropping back, you FOLLOW again when you are behind the target rider? then you switch to following them? but what if they are now in a different group?

how can you end up as the only member of a group, in a drop state, behind all the other riders?

- what if you are already behind and alone when the drop is begun?

Co-op 4 is leading a group of 3
sprinter sprints
chaser chases
Co-op 4 is now alone leading
Co-op 4 is issued a DROP instruction
||||||||||||| added drop instruction 345,drop=3,3 |||||||||||||

- fix: don't issue a drop if there's nobody else in the group!

-also, if you are dropping and for whatever reason there is nobosy else in the group (e.g. they sprinted or chased), need to change into another state 

- if dropping and there is nobody else in the group
	if there is nobody in front of you, switch to LEAD
	else follow the nearest rider in front of you and move to their group.


- ok to stay DROP but need to move to the group of the sprinter

-- hmmm, this seeems to work, rider does drop for one ts but then converts to SOLO, and from there might rejoin another group

- right, worked on poster for a couple of days. way too slow. Let's do an hout now tryign to make progress.

- work on adding strategy to the rders. need a new rider array 
     "in_race_updates":[[3000,"breakaway_attack_duration=5"]],
	 
- currently use distance in m, could change this. 0-1 % of race distance, or distance remaining (in m?). wondering what happens if the race length changes. I feel like riders are more tuned into the distance remaining? 

- ok, so adjust to distance_remaining in m?

- make a sort funciton to sort using the nested array 

updates_list.sort((a, b) => (a[0] < b[0]) ? 1 : -1);

- can use array.shift() method to 'pop' off the first element, then only need to look forwards for eleemnts to pop based on distance remaining.

- start integrating the GA.
- add a setting.
      "race_type":"BREAKAWAY",
	  
	  
	 
- added a BIG new function, a copy of run_track_race_ga(), and called it breakaway_race_ga().

- shouldn't use max_timestep any more, should use the race.distance: distance will be used instead of time

- need a new version of create_new_race, how's about renaming the old version to create_new_team_pursuit_race

- nopw make a copy called create_new_breakway_race()

- do we still evolve the start order? can we just fix it here for simplicity? we no longer send instructs to the starting rider.

- we can create a discreet number of distance steps by defining one and dividing the total distance by it.

 "breakaway_race_number_of_race_update_distance_slots":100,
 
 
 - have to mark which rider is being evolved... for now at least it can only be the one.
             "evolve_this_rider":1,
	  
 - ok, so where to now? 
 
 - back to create_new_breakway_race()
 
 - need to control the properties that will evolve using a settings array or objects 
      "ga_properties_to_evolve":
          [{"name":"breakaway_sprint_eagerness",
            "min":0,
            "max":10,
            "distribution":"linear",
            "initial_value":0,
            "mutation_range":2}],
			
- let's get this new GA to ga. october 14.

- instruction format 


- I guess we can re-use ga_probability_of_instruction_per_timestep_lower and ga_probability_of_instruction_per_timestep_upper here to create the updates?

- what accuracy/decimal places should we use here?/ 3?

- ok, it creates a new race, but the sprint only happens at the end of the race, and this will scatter instructions throughout? maybe in this case there should only be ONE? like, only have the initial one, or perhaps an individual rate of apperance for each kind of instruction?

- seems like we have to include the rider number in the instructions, how else would we ever evolve them for more than 1 rider?

- porting moverace into the GA, yikeses.

- need to fully rework 1) how race finish is used as fitness, and 2) add rank-based selection. but first many many buggos 

race_instructions_r is broken by having the rider inside. need to move things into the correct rider's in_race_updates[] array

- i use a different version of switchLead(), need to include and rename it. 
- added switchLeadBreakaway(positions_to_drop_back, rider_no, settings_r, race_r,riders_r)


	

- oooooh it now crashes at the mutate_race() point, so technically it has RUN SOME RACES! 

  let number_of_update_slots = settings_r.breakaway_race_number_of_race_update_distance_slots;
  
    let race_distance_segment_value = race_r.distance;

      let segment_distance = race_r.distance/number_of_update_slots;

      while(race_distance_segment_value > 0){
	  ...
	    race_distance_segment_value -= segment_distance;
      }
	  
- r.instructions, not the rider.in_race_updates is what I need to look through. It seems like in_race_updates ends up with duplicates :-( 

instrucitons array is emptied and added to during the race, can't use it as the genotype in the way that it had been.

- try adding a new array to the race and using that? 
- rider_updates_genotype

- weird, rider_updates_genotype is empty when i get to the mutate part.
- so, the array is in the population, but these are not 'races', they are little subsets, need to assign it to the race before it is run?
race_r.rider_updates_genotype = [...load_race_properties.rider_updates_genotype];

-ok, it seems to work now, need to finish writing the mutate code, maybe first do some pseudocode/

scary things aboundant. oh tis all out of date, of joint, a fit kit in night.

have to add more more more props 
  "mutation_range_for_distance_update":250,
     "p_change_breakaway_update_value":0.008,
     "p_change_breakaway_update_distance":0.008,
	 
- i have been using segments for the race distance remaining- but what happens if I let mutations apply ANY distance?
- for now maybe allow any distance in the mutations? 

   "mutation_prob_of_adding_new_update_for_rider_prop":0.001,
   
   
   - need to sort by TWO props, the distance DESC then the property name ASC
   
   x.sort((a, b) => (((b[1]-a[1])==0)? (a[2].localeCompare(b[2])) :(b[1]-a[1])));
   
   - is my oriignal crossover function even working as expected???????
   
   random_array.slice(0,new_instruction_set_size).sort((a,b)=>a-b)
   
   test
   let x = [3,1,8,9,5,7,6,0,2,4];
   x.slice(0,4).sort((a,b)=>a-b)
   
   
   - ok, so it now seems to have a mutate and crossover step? but what does the population look like at the end of the ga search?
   
   - created a simple new fitness funciton idea in google spreadsheet. need to code it in- return it from the race - only need it for the evolving rider(s).
   
   - need to use time ahead., not distance ahead, as it is too awkward to work out the distance, but we do already have the finish times. note that if a rider is CAUGHT, this can't be used as they may have finished much earlier!
    
	"breakaway_max_time_ahead_from_next_finisher":10,
    "breakaway_fitness_max_average_speed":20,
	
	evolving_rider_fitness
 is now being returned. e.g., value 0.6768376145657465. shoule all be 0-1.
 
 - now it does run a whole ga and ends up with a population (of 10) that seeeeems ok ok.
 
 - need to look at the selection process...

- let's go ahead and add a brand nwe selection type: tournament_breakaway_linear_rank_selection

    "linear_rank_fitness_selective_pressure":1.5,
	
	[[0,5000,"breakaway_sprint_eagerness=0"],[0,4850,"breakaway_sprint_eagerness=5.279"],[0,4800,"breakaway_sprint_eagerness=4.861"],[0,4700,"breakaway_sprint_eagerness=7.36"],[0,4500,"breakaway_sprint_eagerness=3.638"],[0,4450,"breakaway_sprint_eagerness=7.769"],[0,3500,"breakaway_sprint_eagerness=2.025"],[0,1750,"breakaway_sprint_eagerness=3.53"],[0,1350,"breakaway_sprint_eagerness=5.032"]]
	
	
- trying to run a bigger experiment, 50 gens, pop 100, but so so slow, too many console logs?

getting [0,500,"undefined=NaN"] for results after 30 gens. le oops.

- strat not being implemented in the game, rider NOT sprinting if updates are added. warum?

it now runs the instructs, but is the same issue in the GA version of the race????

- seems to run now? but I want to set the update probs to 0, maybe move them to the rider as part of ga_properties_to_evolve ?

            "update_probability_value":0,
            "update_probability_distance":0,
			
			
breakaway_race_ga()
create_new_breakway_race()			
new_population_tournament_selection_breakaway()
mutate_race_breakaway()

- fixed a couple of things. lots of little buggos in the mutations. now it works but I need to see exactly the fitnesses and how they are applied in the selection. doesn't seem to be directing towards any particualr sprint elvel.

baum1995genetic
"GA's seem strong on certain problems, especially in the presence of noise or unknown interactions which can be modeled as noise."

- add new results case, show fitness as well as time.

- ok, it kinnnda works. fitness shoudl be rounded? to 4 places?


- caught,caught_distance_covered,max_distance,finish_position,average_speed,max_average_speed,time_ahead_from_next_finisher,max_time_ahead_from_next_finisher, team_size

- ran pop of 10 for 3 gens, they all get the same fitness score: 
breakaway_fitness_score(0,5001.7776807681485,5000,1,14.249886000911992,20,0.08899999999999864,10,4);
****0 5001.7776807681485 5000 1 14.249886000911992 20 0.08899999999999864 10 4  breakaway_fitness_score 0.6701 ****

if i increase the mutaiton I get some diversity, see 

 ****0 5016.905756119277 5000 3 14.285061254342658 20 0.59699999999998 10 4  breakaway_fitness_score 0.9234 ****
race_function_no_vis.js:6252   ****0 5001.7776807681485 5000 1 14.249886000911992 20 0.08899999999999864 10 4  breakaway_fitness_score 0.6701 ****
race_function_no_vis.js:6252   ****0 5019.202210883003 5000 3 14.290205493154993 20 0.7230000000000132 10 4  breakaway_fitness_score 0.9242 ****
race_function_no_vis.js:6252   ****0 5001.7776807681485 5000 1 14.249886000911992 20 0.08899999999999864 10 4  breakaway_fitness_score 0.6701 ****
race_function_no_vis.js:6252   ****0 5003.1026760738505 5000 1 14.25309505959219 20 0.09000000000003183 10 4  breakaway_fitness_score 0.6701 ****
6race_function_no_vis.js:6252   ****0 5001.7776807681485 5000 1 14.249886000911992 20 0.08899999999999864 10 4  breakaway_fitness_score 0.6701 ****
race_function_no_vis.js:6252   ****0 5043.3804668815255 5000 3 14.356058974690267 20 1.4019999999999868 10 4  breakaway_fitness_score 0.9286 ****

- verify a few of those with the Excel sheet.

finish posiiton confusion aside, they seem to agree.
- rider only ever finishes first or last.


- let's work on making races replayable, and having useful results that show fitness/etc. need to show different resultw if this is a breakaway race
- want to get the best/average fitness graph to work, too.]

- selected_global_settings contains the race_type

- does final_best_race_instructions prop contain race.rider_updates_genotype ??

- yes,   generation_results.final_best_race_instructions = final_best_race_properties.rider_updates_genotype;

-ok, grand, now perhaps I should look at logging choices and race replays.

- need to record the choices of every rider. add a new rider prop:
            "race_choices":[],

- make sure to reset race_rider.race_choices in load_race
-now need to return and add this to a best prop, i.e., best_race_rider_race_choices
- not logged to DB. warum?

- fitness is positive, higher better, race finish time, lower better, need to switch < with > when finding gen best fitness

- really awkward problem becuase i initialise the best/worst to p[0] but can't initialise the best/worst props to this until after it runs, and then it's possible that p[0] IS the best or worst and the < and > might not happen, so settings might not be updated at all. changed them to >= and <=, though this may also have an effect.

- ok, so it does now seem to be saving something in the db, but I need to to create a new link to open up the race-viz.

"determining the robust region in the high-dimensional decision space by using fewer function evaluations."

- the choke under pressure does not work the way I've described it????
- there's no actual distance factor?? and it would need to be distance remaining??

-- so, to look at the choke under pressure mechanism again, and check against how it is described in the text.

- how did i create that pair of graphs showing choke events?

- oooooh, wait, the distance IS being used :-) look at this line 
let end_race_better_time_factor = speed_higher_than_best*(race_rider.distance_covered/race_r.distance);
- not sure why it is being multiplied by speed_higher_than_best here
- doesn't really matter since it will be a 1 or a 0, and is also provided as an entry into choke_under_pressure_probability_variables.

- generate a new link for the breakaway race replay 

http://127.0.0.1:3003/tpgamebreakaway.html?source=results&results_id=68fa298ac23bad05f81dfb6f&startorder=0,1,2,3&race_choices=%5B%5B%5B338,%22SPRINT%22%5D%5D,%5B%5B345,%22CHASE%22%5D%5D,%5B%5D,%5B%5D%5D

- ok, it's doing something, does it open the race page?

- yes. it does not load the settings or do anything else.

- first step is that it needs to recognise that it has been opened with info in the url?

- sample results url, regular 'ol track race 
http://127.0.0.1:3003/tpgame.html?source=results&results_id=68a93032e608023748ea2dd1&startorder=3,1,2,0&instructions=%5B%5B0,%22effort=5%22%5D,%5B1,%22effort=6.35%22%5D,%5B21,%22drop=2%22%5D,%5B23,%22effort=6.95%22%5D,%5B48,%22drop=2%22%5D,%5B51,%22effort=6.63%22%5D,%5B73,%22drop=3%22%5D,%5B101,%22drop=1%22%5D,%5B104,%22drop=1%22%5D,%5B127,%22drop=2%22%5D,%5B144,%22drop=3%22%5D,%5B150,%22drop=3%22%5D,%5B151,%22drop=3%22%5D,%5B154,%22drop=2%22%5D,%5B160,%22effort=8.83%22%5D,%5B162,%22effort=8.83%22%5D,%5B173,%22effort=5.27%22%5D,%5B174,%22effort=7.03%22%5D,%5B184,%22drop=3%22%5D,%5B190,%22drop=2%22%5D,%5B216,%22drop=2%22%5D,%5B224,%22effort=8.25%22%5D,%5B241,%22drop=3%22%5D,%5B242,%22effort=10%22%5D,%5B256,%22drop=1%22%5D%5D&noise_alterations=%7B%7D&performance_failures=%7B%7D&instruction_noise_choke_under_pressure=%7B%7D&instruction_noise_overeagerness=%7B%7D

- ok, so if we load from results, then load up the race?

- ok so it now loads the race_choices into the instructions textarea: 
[[[338,"SPRINT"]],[[345,"CHASE"]],[],[]]

- note that there are blanks, and no rider number.

- work with no rider number, assign to the evolving rider for now. should stop two riders from having that setting set to true/1/on 
- no, wait, it needs EVERY rider's choices. oh, oh, that's what we have, it's 4 arrays in that array, 2 riders make NO choices at all.
- in load_race, load these into a rider property if they exist?

- ok, assigning the race_choices to a rider prop via 
load_rider.race_choices = race_choices_all_riders[race.start_order[i]];

- now, need to load these, maybe have a global run_type boolean that I can check to know we are running from results? 
  RACE_RUN_TYPE = "RESULTS";
  
  
-ok, so the race runs, but there's a time discrepancy :-( leave that until tomorrows.

- need to work out and display the fitness of the evolving rider, and try to get this to match the GA race.

- huh, changed nothign and the finish time seems to be the same now? 

- get it to display the FITNESS at the end (of each rider)

- copy across the fitness function 
breakaway_fitness_score(caught,caught_distance_covered,max_distance,finish_position,average_speed,max_average_speed,time_ahead_from_next_finisher,max_time_ahead_from_next_finisher, team_size)

- ok, so seeeeem to have the same fitness

- is there an issue with the distance covered in the fitness calculation, since they will keep riding past the race distance until all others have finished?? could use the race distance if they aren't caught?
 - ooh it IS using the race distance and rider finish time, and it is not distance ahead, it is TIME ahead, so I already grappled with this problem :-) 
 
 - mundee nov 3rd
 - rider on solo that fails doesn't even try to follow the group as it passes?
 
 - also, HUGE discrep in replay race, the evolved rider doesn't win, finishes 3rd. how do i debug??

- it's not going into ATTACk because it is in a DROP state... but it is in a DROP state when it originally goes into attack??
- or is it possible that it goes into a DROP state later in the timestep? or... well, I guess I need to know what aim a rider is in when they make a choice??

- so there is defo isses, the original aims don't line up with the replay aims. out of sync. 

- do we have thw correct rider?? add the name to the race_rider.race_choices array

- only one rider seems to have race_choices, is that legit?

- are there other random choices being made??

comparing images, it seems that the races differ from the beginning. warum?

- why does the rider begin at power of 400 - is this some kind of default? surely they should begin with their breakaway power level? 
- is something not being reset in the GA, like the timer for breakway efforts?
- race_rider.time_leading_group?

- weirddd, that seems to be reset correctly.

also, look at this set of updates,- the last one's distance is < 0:
[[0,5000,"breakaway_sprint_eagerness=0"],[0,2600,"breakaway_cooperation_time=3.449"],[0,-142.122,"breakaway_cooperation_time=8.474"]]	

- hypothesis 2: the coopertion time is being set in the GA at the beginning becasue there is a weird < 0 instruction, ala 
[[0,4729.636,"breakaway_cooperation_time=18.254"],[0,-142.122,"breakaway_cooperation_time=8.474"]]	
AND this is NOT happening in the replay 

rider_updates_genotype is the race level construct 
load_rider.in_race_updates_stack is what the rider sees during the race, a queue they pop things off, via updates_list via updates_list = [...race_r.rider_updates_genotype.filter(a=>a[0] == race_r.start_order[i])];

- shoot, strugglign to replicate this negative value. maybe look at the mutation code?

- added checks for zero distances, don't see them now, but the initial turn is still really short. warum?

- wait, maybe the breakaway_cooperation_time is not being reset to its original value for when the next race begins??

- ooh i think that's it - caught an example where it is 6... and it is not there in the first generation, so makes sense it gets added.

- how do i make sure all the props are reset? 
- ned to do some kind of deep copy of the riders from the original ones? 

- 1: store copies of the rider objects before any races are run 
- 2: restore from these copies before each race.

- could use obj = JSON.parse(JSON.stringify(o));

let riders_r_original = JSON.parse(JSON.stringify(riders_r));

- the replay is not implementing the breakaway_cooperation_time value?? [[0,5000,"breakaway_cooperation_time=2.766"],[0,5000,"breakaway_sprint_eagerness=1.462"]]	

- wait, why is it setting breakaway_sprint_eagerness to 0??

- wait, race.riders[i].in_race_updates_stack[0]; looks nothing like what's shown in the results table??

- add a new tab that shows the genotype updates


  if(!(Object.keys(instruction_noise_alterations_from_url).length === 0 && instruction_noise_alterations_from_url.constructor === Object)){
            //console.log("loaded instruction_noise_alterations from URL: " + JSON.stringify(instruction_noise_alterations_from_url));
            $("#rider_updates_genotype_textarea").val(instruction_noise_alterations_from_url);
          } 

- displaying, but it's NOT the same as the GA. warum??

race.rider_updates_genotype

- misconception: I need to load these from the generation results, not the global settings objects: these are common to ALL races.

- should rename this tbh 
generation_results.final_best_race_instructions = final_best_race_properties.rider_updates_genotype;

final_best_race_rider_updates_genotype

http://127.0.0.1:3003/tpgamebreakaway.html?source=results&results_id=690a753755bb05478c3d5232&startorder=0,1,2,3&race_choices=%5B%5B%5B333,%22SPRINT%22,%22LEAD%22,%22EVOLVE%201%22%5D%5D,%5B%5B344,%22CHASE%22,%22LEAD%22,%22%20Sprint%202%22%5D,%5B349,%22SPRINT%22,%22CHASE%22,%22%20Sprint%202%22%5D%5D,%5B%5B343,%22SPRINT%22,%22FOLLOW%22,%22Sprint%203%22%5D%5D,%5B%5D%5D&final_best_race_rider_updates_genotype=%5B%5B0,5000,%22breakaway_cooperation_time=24.413%22%5D,%5B0,5000,%22breakaway_sprint_eagerness=1.101%22%5D%5D

  $("#rider_updates_genotype_textarea").val(JSON.stringify(final_best_race_rider_updates_genotype_from_url));
  
    let new_rider_updates_genotype = $('#rider_updates_genotype_textarea').val();
	
- getting maybe closer to 'real' results.

- get the race to begin with the coop level

- add the ability to run repeats of the best-in-gen races, to record a best_in_gen_win_ratio value. 

-     "best_in_gen_win_ratio_test_quantity": 50,

- could put this where the robustness tests went?



- try a really dumb scenario where the rider always wins 

- try a secnario where they can't really win 

- try a scenario where the bunch catches them 

- try a scenario where the evolving rider has no sprint but can attack.

- could also record the average fitness of the win ratio testing.

- try one where opponents chase?

- work on witing up a description of the race state transition mechanisms, maybe a flowchart?

- chase distance factor seems wrong, shouldn't i be subtracint it from the max distance, i.e. distance_max-distance instead of just distance?

- group cohesion, could extend this to also be high if the rider is doing longer turns than the others? like, they might be all going slower but by the same amount? or will this already be captured? it's just a bit diluted- if one is going slower it'll be more obvious... if all 3 are going slower? maybe i could compare the rider's own turns with others, not the average with others??

- retest basic sprinter GA, and work on creating a new diagram: best fitness, average fitness, and win ratio.

- am i recording the average fitness of each generation??

- old graph uses stats_average_time, need to re-use or add something new here.

- stats_total_fitness, based on stats_total_time
- ok, so create a new graph, a copy of the fitness graph.

- what is the best race fitness called? best_evolving_rider_fitness
- also need the win ratio: best_in_gen_win_ratio_test_result

- new results save but the graph doens't show up. warum??

- why doesn't the average fitness converge to 1- in  both tests it goes to .95 and stays there

- ga_percentage_of_random_new_strategies_to_inject_each_gen is 0 

- i can't run the worst-in-gen race, didn't update the code... why would a seemingly constant % of races have a lower fitness, why is the average so consistent?

- oh wait, i'm confused, the average does change. the BEST is static. the average increases. The BEST maxes at < 1. why is it so static?

- look at the actual choices made for the best-in-gen races, and the fitness values 
25 [[[320,"SPRINT","LEAD","EVOLVE 1"]],[],[],[]] fitness 0.9372/346.32
20 [[[316,"SPRINT","LEAD","EVOLVE 1"]],[],[],[]] fitness: 0.9377/346.231
15 [[[320,"SPRINT","LEAD","EVOLVE 1"]],[],[],[]] fitness: 0.9372/346.32
10 [[[316,"SPRINT","LEAD","EVOLVE 1"]],[],[],[]] fitness: 0.9377/346.231
5 [[[320,"SPRINT","LEAD","EVOLVE 1"]],[],[],[]] fitness: 0.9372/346.32
0 [[],[],[],[]] fitness: 0.67/349.184

- ok, so the two fastest moments to sprint at are 316 and 320. both can occur for various sprint abilities in a big population. what if i have a tiny population, would there not be more variance?

- could also record the average fitness in the win ratio tests, and include these in the graph?

- useful reference about drafting savings here: https://en.wikipedia.org/wiki/Peloton

- back to the breakaway work... add the average fitness to the win ratio testing? 

- add this best_in_gen_win_ratio_test_average_fitness_result to best_in_gen_win_ratio_test_result

- isssues with the graph, 4th label not showing, gaps too big? and the lines under the legends are not working

- is this line a problem: let legend_line_segment_y = -32;

- graph looks better - replace the current one with this one, abd write a bit more about it...

- month on file image  names is zero-based.

- maybe create a win-ratio test that can be run from the GA screen manually? could then check the ratios for a bunch of values of sprint eagerness, and create a graph?

- do i also need a way to visualise the genotype convergence? like the bubble scatter plots? but that plot can only have 1 y range to be readable? would need a new plot for every gene type?

- added a new button with button_run_win_ratio_test name, based on button_play_race

run_win_ratio_test, LIKE run_single_race or maybe more like run_robustness_check?

- need to set race_r.rider_updates_genotype

in the worker I can't call run_single_race, I need to create something new here. Better to make ONE call for all runs rather than one each?

- created a new function and messageType run_breakaway_win_ratio_test

hitting a bug- it will not run if the textareas are left blank, maybe because of the start order? If this is blank it shoul dnot be set??

- return and display win_ratio and average_fitness

- edited code in the wrong function :-( fix!

- kinnnnda workign but getting undefined for both results

- ok, seeems to wurk. test for a 'real' example.
[0,1,2,3]
[[0,5000,"breakaway_sprint_eagerness=6.941"]]	

- need to ad the WORST race playability to see what's happening there... is it that the sprint never happens, or they go too early??

are the losses due to a sprint NEVER happening??

- bug- had an incorrect variable name, the correct one is rider_race_choices, for the worst race... updated this, will need to run a new experiment to test?

- ok, progress, can now see the worst race choices. it is never empty, but contains 4 empty arrays.
- run a win ratio test for the worst strategy?
-create a worst_in_gen_win_ratio_test_quantity variable, same as best_in_gen_win_ratio_test_quantity

- rename best_in_gen_win_ratio_test_quantity to breakaway_strategy_win_ratio_test_quantity

- ok, so it now seems to work, I can see thw worst race, the rider sprints but too late.

- now, also need to save some generattion genotypes, so that we can look at the convergence.
- had used log_generation_instructions_info for this. can reuse. 

- shoudl be stored in generation_instructions_info

- it's wonky, has mostly nulls, two empty {} objectsd for effoprt and drop, and some zeros (they are correct?

Huh, it stores 0 but then they become null? warum??

- wrong data format, [] instead of {}. fixed, saves now.

- create new 'graph' to get out the data. does it not already exist?

- ok, so here's the format we get:
{"0":{"breakaway_sprint_eagerness":{"5000":[0,0,0,0,0,0,0,0,0,0]}},"9":{"breakaway_sprint_eagerness":{"5000":[0,1.901,0,0,0,0,0,0,0,0]}}}

- weird, why so many 0s??

- crap, can't save results, too big... pop 1000, gens 50, bit saving info for 5 gens. this could get tricky.

- there is huge convergence to very specfic values... i feel like this is a bug tbh, it's like a bunch of entries are being duplicated, or all point to the same value. need to debug, very big deal!

- weird, after 100 g ens we have all 0s. warum???

- look at this, bottom fitness rank for the ONLY non-zero sprint race in a group:
  >> race 3, genotype [[0,5000,"breakaway_sprint_eagerness=0"]] fitness 0.67, fitness rank 4, prop. fitness 0.15000000000000002
  >> race 4, genotype [[0,5000,"breakaway_sprint_eagerness=0.565"]] fitness 0.67, fitness rank 5, prop. fitness 0.1
  - why do they both have identical fitness??
  - maybe it's just random- it may have not sprinted 
  here's 2 that are TOp of the rankings 
     >> race 0, genotype [[0,5000,"breakaway_sprint_eagerness=0.565"]] fitness 0.9237, fitness rank 1, prop. fitness 0.30000000000000004
race_function_no_vis.js:3179    >> race 1, genotype [[0,5000,"breakaway_sprint_eagerness=0.565"]] fitness 0.7954, fitness rank 2, prop. fitness 0.25

- now look at this: is somethign being set to 0??? 
    >> mutate parent 1: genotype [[0,5000,"breakaway_sprint_eagerness=0.565"]], prop fitness 0.30000000000000004, rank 1
	*** old_genotype	[[0,5000,"breakaway_sprint_eagerness=0"]]
	*** new_genotype	[[0,5000,"breakaway_sprint_eagerness=0"]]
    >> new race: genotype [[0,5000,"breakaway_sprint_eagerness=0"]]

- huh, looks like I was referring to race object in mutate() instead of the passed in parent object: they will both have a rider_updates_genotype array

- now, is elitism working??
- oooh it looks like NOPE, that I had a < instead of a >. geeeeeeez. Run again.

- ok, finally, much improved, it ends up with almsot all 10s in the population.
- comment out the console logs and run again. need to re-run all tests :-( I guess it was still convergign before despite the "anti-elitism"