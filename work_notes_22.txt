-- startign a new notes file in 2022. just trying to get a shift, to see if I can actually make something happen here.

-- got mongodb ported across to the new G14, system seems to run, had already installed Node and other stuff.

-- have to get the next paper work started... maybe test running sequences again first?

or maybe a better idea would be to being collecting references? Build up a database somehow? Online?


--test out the sequences again: do a run of experiments where noise increases each time?

-- performance noise only, go from 0 to 100 in steps of 10?

-- how does the sequence setup work again?


-- example (after running)

{"iterations":2,"active":0,"variations":[{"iterations":[3,2,1],"type":"rider","rider_no":0,"property":"threshold_power","values":[200,300,400]},{"iterations":[3,2,1],"type":"rider","rider_no":0,"property":"max_power","values":[800,900,1000]}],"experiments":[{"client_id":"86.43.200.150_Galway_IE_None_2021-6-14 10:41:47","iteration":2,"status":"complete"},{"client_id":"86.43.200.150_Galway_IE_None_2021-6-14 10:41:47","iteration":1,"status":"complete"}]}

-- strip it back to the basics

{"iterations":11,"active":1,"variations":[{"iterations":[10,9,8,7,6,5,4,3,2,1],"type":"global","property":"performance_failure_enabled","values":[1,1,1,1,1,1,1,1,1,1]},{"iterations":[10,9,8,7,6,5,4,3,2,1],"type":"rider","rider_no":0,"property":"performance_failure_rate","values":[10,9,8,7,6,5,4,3,2,1]},{"iterations":[10,9,8,7,6,5,4,3,2,1],"type":"rider","rider_no":1,"property":"performance_failure_rate","values":[10,9,8,7,6,5,4,3,2,1]},{"iterations":[10,9,8,7,6,5,4,3,2,1],"type":"rider","rider_no":2,"property":"performance_failure_rate","values":[10,9,8,7,6,5,4,3,2,1]},{"iterations":[10,9,8,7,6,5,4,3,2,1],"type":"rider","rider_no":3,"property":"performance_failure_rate","values":[10,9,8,7,6,5,4,3,2,1]}]}

-- hmmm, doesn't seem to work, adds "experiments":[{"client_id":"","iteration":2,"status":"active"}]} so maybe it runs or tries to run once and crashes? One experiment defo ran.

-- Hmmm, browser_client_id is empty so maybe this causes it to end without saving anything?

-- ok, so this is failing:
  $.getJSON('http://www.geoplugin.net/json.gp', function(data) {
  
  jquery-3.4.1.min.js:2 GET http://www.geoplugin.net/json.gp net::ERR_BLOCKED_BY_CLIENT
  
-- so need a different way to get the IP address? Or can I find another way to 

-- huh, seems to work in Postman, so maybe it is the adblocker?

-- turned those off; it is defo doing more  now but still failing :-(

-- problem seems to be Ghostery

-- ok I think  it ran?

-- need to make a bunch of code changes, e.g. more realistic start, better performace failure, need to run whole bunches of experiments and collate lots and lots of results.##


	

get the paper into their format (tomorrow)

special case of scheduling. maybe in gecco. 

sac
gecco 


suggested reviewers.

-- run a sequence again
{"iterations":2,"active":1,"variations":[{"iterations":[2,1],"type":"global","property":"performance_failure_enabled","values":[1,1]},{"iterations":[2,1],"type":"rider","rider_no":0,"property":"performance_failure_rate","values":[10,1]},{"iterations":[2,1],"type":"rider","rider_no":1,"property":"performance_failure_rate","values":[10,1]},{"iterations":[2,1],"type":"rider","rider_no":2,"property":"performance_failure_rate","values":[10,1]},{"iterations":[2,1],"type":"rider","rider_no":3,"property":"performance_failure_rate","values":[10,1]}]}

format for sciendo IJCSS International Journal of Computer Science in Sport (https://sciendo.com/journal/IJCSS)
> Times New Roman size 12 DONE
> fully justified - seems already ok?
> indented by 3cm from both sides - seems already ok? Nope, seems bigger on mine than on the sample. Check another sample or two and compare font/spacing/etc. 

Ok, used the geometry package and it seeems to work now, just visually basing it on the other sample papers

> Number the pages
consecutively, with no line numbering and no 'headers and footers'
> no footnotes

How do I remove the force calculator website footnote? Add it as a reference?

added it as an @online entry in the bib

-- tried to fix up the one table, improved but probably  not perfect. need to look again at the online citation, think it has no year showing?

-- oh nope it's fine.


> headers:
“Section_Headline_IJCSS” (Arial 12, bold),
“Subsection_Headline_IJCSS” (Arial 12, bold and italic) and
“Subsubsection_Headline_IJCSS” (Times New Roman 12, italic)

-- right, lotsa work there,  has it improved? sore eyes again.

> title
Title and subtitle are separated by a hyphen “-“. Each word starts with a capital letter, except
conjunction such as “and”, “or”, “a”, “on” etc. Use font Times New Roman size 18 and bold
style print (see Example 1).

> authors
Authors and institution must be written in size 12 and in italics. Sur- and forename of multiple
authors are separated by a comma. The first name(s) is/are abbreviated with the first letter of
the name. eg. Novatchkov, H., Bichler, S., Tampier, M., Kornfeind, P.
Department of Biomechanics, Kinesiology and Computer Science,
Faculty of Sport Science,University of Vienna,
Auf der Schmelz 6A, 1150 Vienna, Austria

> abstract
The abstract must not exceed 200 words and it should summarize the paper, giving a clear
indication of the conclusions it contains. It must be inserted in the article after the authors’
addresses, indented by 1 cm from both sides of the normal text. The abstract must not contain
figures or tables (see Example 4)

left-align abstract header

-- remove paragraph indentation
-- done

-- why do the images take up whole pages in some places?

-- right, have to finish tthis paper reformat, need to add in their seciton headers, but where? feel lost right now
Introduction
Methods
Results
Discussion
Conclusion

-- guess I just have to try find the most natural home for them and go form there, email Colm tomorrow and mention that?



From: https://tex.stackexchange.com/questions/69869/image-taking-up-full-page
Most likely it ended up being a float page p because the constraints on size stopped it being a t float. in which case change [htp] which allows p and constrains the number and size of floats in the t area to [!ht] which does not allow p and removes the numeric and size constraints.

If that isn't sufficient, edit the question to add a complete example which shows the problem.

-- adjust other image placements?


-- need to put fulls stops and not commas to get the proper APA format in the references?

-- maybe usepackage{apacite} ?

-- took time but i think? the apa format is now ok... certainly looks like the sample ones. 

-- need to put in Methods, Discussion, and Results and fit everything under those headers? But my stuff doesn't map to those does it?




-- meeting with COlm... 

idea for paper 2
exploration of noise and robustness
-- try out different kinds of failure and noise and find ways to measure their robustness

-- improve the performance failure and the size of the failures (don't tie them directly to the rate of failure)
-- find different ways to work out robustness and compare strategies.

-- e.g. 1: evolve strategies in a  noisy environment, as I have done
-- 2, evolve in a clean environment and then somehow 'add perturbations' to the final strategy, I guess to improve robustness? Or do I use mutations to measure it as I had done before?

-- need a form of noise to model a coach's lack of knowledge about a rider, or a general ambiguity about a rider's actual power, which at the beginning of any race may vary within some range instead of being a fixed point

-- need to be able to add enough noise in different ways to make it totally chaotic, or serene, and all of these have to be replayable as before.


-- how do I take an evolved strategy and consider how risky it is? E.g. evolve one then run it with some rider failure. And some noise. How Bout just small changes in the timing. 




-- monday feb 7th.
--  need to begin the next piece of work and paper... no idea what will happen if paper 1 doesn't get accepted. but what can ya do?

-- need a title... Robustness and Noise in a Genetic Algorithm Search for Simulated Track Cycling Strategies?  Good enough for now.

-- created a new doc and added a title and abstract.

-- first extend the performance failure and add the 'hot headed' noise?

-- yup yup, get coding, but make the new form of performance failure optional so the old stuff for now is still repeatable.

-- added  "performance_failure_effect_type": 2,#-- type 1 can be the old one, and the default, and type 2 can be a new version 

-- so I can add this in calculate_rider_performance_failure_percentage_amount()


-- how do i see again if a setting exists and default it if not?

-- ran a test version but there's not a ton of failure happening- want to max it out to see it... 

-- yeah more failure, tho not really maxxxing it out, I wanna see mad chaos when everyone keeps failing all the time?

-- maybe I can make the performance failure larger, i.e. that they can fail by more... what's the max % they can fail by now?

-- hmmmm, the value seems > 1, that's mad odd

-- yikes, getting very high fatigue values... wonder what those races are up to? 

-- looks like race_rider.endurance_fatigue_level gets very high... but how can it if a rider is supposed to recover after crossing their limit?

effort 4 effort_max 9 current_fatigue 181.42766666666668 current_fatigue_max 100
 accumulated_fatigue 181.42766666666668
 accumulated_fatigue_max 500 rider_performance_failure_multiplier 10 rider_performance_failure_multiplier_max 10
 performance_failure_base_max_percentage 1 performance_failure_amount_exponent 2
 performance_failure_effort_importance_multiplier 1 failure_type 2
 
  accumulated_effect = (settings_r.accumulated_fatigue_maximum - race_rider.accumulated_fatigue)/settings_r.accumulated_fatigue_maximum;
  
  failure_level = settings_r.fatigue_failure_level*accumulated_effect;
  
  accumulated_effect = (500 - 181.42766666666668)/500;
  failure_level = 100*0.6371446666666666;
  = 63.71446666666666
    if(race_rider.endurance_fatigue_level >= failure_level){
if (181.42766666666668 > 63.71446666666666)	
-- how can fatigue get so high like this?
-- maybe it is sometimes adding a ton of fatigue in one go?
 let fatigue_rise = race_rider.fatigue_rate*Math.pow(( (race_rider.power_out- race_rider.threshold_power)/(race_rider.max_power-race_rider.threshold_power)),settings_r.fatigue_power_rate);
 
 -- max fatigue rise doe snot look so high, so it is being let grow very high... how so?
 -- does it happen without noise?
 -- fatigue_rise 15.563999999999998 max wihout performance failure... but in this case I don't see the max failure level? That's what is driving the effect?
 
 
-- ok, so very high fatigu can accumulate even with no noise at all. need to store the settings of a race that has this (instructions and start order only needed as I know which set of settings are being used....)

-- can i replicate this race?
max_endurance_fatigue_level 182.16366666666664 fatigue_rise 0.9056666666666673 race_rider.fatigue_rate 20 race_rider.power_out 427.17 race_rider.threshold_power 400 race_rider.max_power 1000 settings_r.fatigue_power_rate 1 Start Order [2,3,0,1] Instructions [[16,"drop=3"],[19,"drop=3"],[78,"effort=6.16"],[116,"drop=3"],[119,"drop=3"],[169,"effort=5.94"],[194,"drop=3"],[198,"drop=2"],[202,"effort=5.32"],[207,"drop=1"],[219,"drop=3"],[223,"effort=8.71"],[227,"effort=9.98"],[255,"drop=2"],[266,"effort=6.89"],[267,"effort=9.68"],[289,"effort=4.32"]]

doesn't seem to pick up the instructions?

-- ah, ok, good news is that it seems legit, that if a rider gets an effort 9 with no fatigue it builds up a head of steam and can only reduce power so fast, ends up clocking up a ton of fatigue.

-- so,  clarify again what the issue is... ah, the maximum 

-- oh dear, so max_performance_failure_percentage found 1.1843064351922996. what happens when this happens? 
-- shite,  target_power = target_power - (target_power*performance_failure_percentage); 
-- this can return a BIGGER value, not a smaller... performance_failure_percentage needs to be limited to < 1.
-- end up with NEGATIVE target power :-( I guess this just means the rider will start slowing down, and since they can only slow down by a certian rate this is very limited, and if they are just following they will essentially reset their effort in the next timestep?
-- huh, so the failure is actually constrained by the maximum power drop allowed per step... currently 40 
-- does this get weird tho if the LEADING rider fails? probably IS the leading rider accumuating this big level of fatigue?
-- how do we fix this and allow a rider to really fail in a seemingly organic way?
-- 1: allow the rider to slow by more than 40 watts in one go (e.g. 100)?
-- 2: maximum failure amount = 1, never > 1. This will make them slow by 100 and no more.

-- worth a try to see what happens
-- so the crux is where I use current_fatigue/current_fatigue_max and current_fatigue>current_fatigue_max.

-- simples fix: if (current_fatigue>current_fatigue_max) then current_fatigue_max = current_fatigue, so this will just max out this?

change "power_adjustment_step_size_down": -40
to
"power_adjustment_step_size_down": -100

-- results are... different. riders get dropped far more easily... step size down is probably too big in some cases? like are there cases where it hsould be lower or higher? try run 20 gens with no noise and see what happens

-- idea, use robustness to represent or influence  fitness. Here' how I explained the idea in an email to Colm> split the population into tournaments as usual.
> run each race and record its result (finish time, lower = better). But also, for each, run N other races, where for each one you add a mutation. So, for race 0 there is no mutation, for race 1 there is 1, and so on until race N includes N mutations (either accumulate the mutations or generate new ones each time). Record the result of each. The original genome is selected, not the mutated ones.
> return, as fitness, 0_mutations_result*x + (average_cost_of_each_additional_mutation)*y where x,y are [0,1] range so can weight the importance of each. I'd like to see what happens if you make the fitness purely based on the cost of mutations, might look strange! Could also try out a few other metrics other than average_cost_of_each_additional_mutation, or a different way to generate mutations that would be probing the landscape around a solution to try and find the slopes.

-- need to build a sequence that will trigger the testing of best_in_final_gen strategy for different noise levels and store the results: end goal is to make a 3d graph

x-axis: evolved fitness noise level
y-axis: test fitness noise level
z-axis: average speed of ten runs of best-in-gen from x in y  noise level

-- to test, try it with two main iterations.

{"iterations":2,"active":0,"variations":[{"iterations":[2,1],"type":"global","property":"enable_instruction_noise_1_random","values":[1,1]},{"iterations":[2,1],"type":"global","property":"noise_1_probability_instruction_misheard","values":[0.5,0]}],"best_in_final_gen_tests":[{"iterations":[11,10,9,8,7,6,5,4,3,2,1],"type":"global","property":"noise_1_probability_instruction_misheard","values":[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0]}]}

what would we need to add to results?

in results, add a new struct; key thing is to be able to name/label each result correctly, i.e. the x,y,z of any graph

best_in_gen_tests: [{variation:[{type:"global","property":"noise_1_probability_instruction_misheard","value":1}],"reps":10,"test_result":276.45},{"noise_1_probability_instruction_misheard":0.9,"reps":10,"average_result":304.01}...]

-- where do i start? add them to the sequence, read them, then look at parsing?

-- not running the sequence. json is fierce frail

{"iterations":2,"active":1,"variations":[{"iterations":[2,1],"type":"global","property":"enable_instruction_noise_1_random","values":[1,1]},{"iterations":[2,1],"type":"global","property":"noise_1_probability_instruction_misheard","values":[0.5,0]}],"best_in_final_gen_tests":[{"iterations":[11,10,9,8,7,6,5,4,3,2,1],"type":"global","property":"noise_1_probability_instruction_misheard","values":[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0]}],"experiments":[{"client_id":"","iteration":2,"status":"active"}]}


{
	"iterations": 2,
	"active": 1,
	"variations": [
		{
			"iterations": [
				2,
				1
			],
			"type": "global",
			"property": "enable_instruction_noise_1_random",
			"values": [
				1,
				1
			]
		},
		{
			"iterations": [
				2,
				1
			],
			"type": "global",
			"property": "noise_1_probability_instruction_misheard",
			"values": [
				0.5,
				0
			]
		}
	],
		"best_in_final_gen_tests": [
		{
			"iterations": 11,
			"repeat_each":10,
			"variations":[
			{
					"type": "global",
					"property": "noise_1_probability_instruction_misheard",
					"values": [
						1.0,
						0.9,
						0.8,
						0.7,
						0.6,
						0.5,
						0.4,
						0.3,
						0.2,
						0.1,
						0.0
					]
				}
			]
		}
	]
}


-- error with client_id again, since I am OFFLINE

-- prints the new settings in the sequence running part now, but need to send it to the GA... maybe could add it to the global settings object itself? wouldn't have to add any arg that way.

-- in the GA, need to 
IF LAST GEN
run games
IF best_in_final_gen_tests
get best-in-gen instructions
look for iterations, parse variations, for each, update the settings then run the race
package results and add to the main results data object 

-- finally it is saving new data... doesn't seem to have the last one (0.0). how many does it actually run?

-- doesn't add details for the 0.0 value I guess because 0 is falsy?

-- arg, thought i had it but i broke it :-( used 
  if(typeof v_details.values[current_iteration] === 'undefined'){
  instead of
    if(typeof v_details.values[current_iteration] !== 'undefined'){
	
	
-- need to email paper to 

DiscoveringTeamPursuitTrackCyclingStrategiesUsingAGeneticAlgorithm_DK_COR_2022


-- try to get the data back out from the mongo 

-- just want simple list of triples or three single lists 
-- lob it into the data_display textarea

-- results are in the last generation... should really be outside but howsover

-- monday 21st feb
-- do the results appear in the textarea?
-- yup, they look like this:
["[{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":1}],\"reps\":10,\"test_result\":328.5271},{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":0.9}],\"reps\":10,\"test_result\":319.44710000000003},{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":0.8}],\"reps\":10,\"test_result\":298.1650000000001},{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":0.7}],\"reps\":10,\"test_result\":320.9687},{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":0.6}],\"reps\":10,\"test_result\":317.6809},{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":0.5}],\"reps\":10,\"test_result\":325.3721},{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":0.4}],\"reps\":10,\"test_result\":321.40500000000003},{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":0.3}],\"reps\":10,\"test_result\":303.8983},{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":0.2}],\"reps\":10,\"test_result\":292.4171999999999},{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":0.1}],\"reps\":10,\"test_result\":293.97920000000005},{\"variation\":[{\"type\":\"global\",\"property\":\"noise_1_probability_instruction_misheard\",\"value\":0}],\"reps\":10,\"test_result\":288.00500000000005}]"]

-- example variation
{"variation":[{"type":"global","property":"noise_1_probability_instruction_misheard","value":1}],"reps":10,"test_result":328.5271}

-- see can i parrs this and instead produce simple values with the noise_1_probability_instruction_misheard and test_result... will then just need to add the noise_1_probability_instruction_misheard of the final-best-in-gen-race itself, and select multiple entries to create the 3d dataset.

--  nasty bug based on me not understanding how select case works in JS. fixed.

-- now it shows doubles, but need to add the third datapoint then be able to select multiple data results. how/where do i add this? return it from app.js? might need to extend the data that is sent back, and add on a best_in_final_gen_noise_value?

-- so now the data returned should have
	return_data.best_in_final_gen_noise_value = 0;
	return_data.data_rows = [.......];
	
-- Tuesday 22/2. need to run a bigger sequence 
{"iterations":11,"active":1,"variations":[{"iterations":[11,10,9,8,7,6,5,4,3,2,1],"type":"global","property":"enable_instruction_noise_1_random","values":[1,1,1,1,1,1,1,1,1,1,1]},{"iterations":[11,10,9,8,7,6,5,4,3,2,1],"type":"global","property":"noise_1_probability_instruction_misheard","values":[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0]}],"best_in_final_gen_tests":[{"iterations":11,"repeat_each":20,"variations":[{"type":"global","property":"noise_1_probability_instruction_misheard","values":[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0]}]}]}



-- have collected data for a few scenarions now, but the terrain is very mountainous... need to rerun one e.g. 3 strong and see if they vary a lot. if they vary a lot then it is struggling to find an optimum?

-- march 7th. can I fix the 3d graphs or even twig the problem?

-- do i need to re-run the 0-strong/2-strong/3-strong versions with the 21 data points instead of 11?

-- 3d graphs defo seem wrong, like it is picking up the wrong points- seems to be peaks at test noise = 0.65 or so, but this is not in the data.

-- hmmm, it does appear that when the ga noise is 0.65, the results are poor, i.e. always slow, much more so than when noise is 0.7

-- does this mean it simply happens to find a bad solution? does it struggle to find good solutions here or is it just chance.

-- rerun the experiment and see if the graph looks very different.

-- March 11th. Set up a few experiments to try find the fastest race for all weak... larger population, more generations, different mutation rates?

-- current default 
	"ga_population_size": 3000,
	"ga_population_size_first_generation": 3000,
	"ga_number_of_generations": 50,
	"ga_max_timestep": 450,
	"ga_probability_of_instruction_per_timestep_lower": 0.02,
	"ga_probability_of_instruction_per_timestep_upper": 0.04,
	"ga_probability_of_drop_instruction": 0.6,
	"ga_p_crossover": 0.3,
	"ga_crossover_length_adjustment_probability": 0.5,
	"crossover_apply_mutation_probability": 0.5
	
	"ga_p_shuffle_start": 0.003,
	"ga_p_add_instruction": 0.009,
	"ga_p_delete_instruction": 0.2,
	"ga_p_change_effort": 0.015,
	"ga_p_change_drop": 0.015,
	"ga_p_move_instruction": 0.015,
	"ga_range_to_move_instruction": 12,
	"ga_range_to_change_effort": 2.5,
	

let's try a bunch of these... make pop 5000, 50 gens fine, just tweeak some ga probs
-- first just see if the crossover choice matters>
	"ga_p_crossover": 0.3,


-- Monday 21st. March. Need to finish paper 2 this week. But what is the actual next task? 

ok, so the issue with the odd 0.65 times in 3 Strong seems to makse sense. The best-in-final-gen race finishes in a speedy 

instructions 
[[18,"effort=4.63"],[89,"drop=2"],[138,"drop=3"],[142,"drop=1"],[213,"drop=1"],[243,"effort=7.68"],[260,"effort=7.44"]]
This finishes in 269.894 seconds

how do i cite and image again in Overleaf? Like so: 

refer to figure \ref{fig:powerOutputFailure}

\begin{figure}[htp]
  \centering
  \includegraphics[width=1\textwidth]{failure_only_gen50_0_61701aefeeefc52d541b5a36_2021-9-20_14-44.png}
  \caption{Power Output for Winning Races in High-Failure Environment }
  \label{fig:powerOutputFailure}
\end{figure}##


-- need the graphs to look alike so will have to do all the graphs with Matplotlib- get it to export the data into the textarea for every graph?

Need to explain WHY the 0.6 levels are so much higher than the 0.7 ones. They require a very specific level of noise, i.e. to push UP the first effort instruction. 

-- run a bunch with 0.6/0.65/0.7 GA noise and tests?
{
	"iterations": 12,
	"active": 0,
	"variations": [
		{
			"iterations": [
				12,
				11,
				10,
				9,
				8,
				7,
				6,
				5,
				4,
				3,
				2,
				1
			],
			"type": "global",
			"property": "enable_instruction_noise_1_random",
			"values": [
				1,
				1,
				1,
				1,
				1,
				1,
				1,
				1,
				1,
				1,
				1,
				1
			]
		},
		{
			"iterations": [
				12,
				11,
				10,
				9,
				8,
				7,
				6,
				5,
				4,
				3,
				2,
				1
			],
			"type": "global",
			"property": "noise_1_probability_instruction_misheard",
			"values": [
				0.7,
				0.7,
				0.7,
				0.7,
				0.65,
				0.65,
				0.65,
				0.65,
				0.6,
				0.6,
				0.6,
				0.6
			]
		}
	],
	"best_in_final_gen_tests": [
		{
			"iterations": 21,
			"repeat_each": 20,
			"variations": [
				{
					"type": "global",
					"property": "noise_1_probability_instruction_misheard",
					"values": [
						1,
						0.95,
						0.9,
						0.85,
						0.8,
						0.75,
						0.7,
						0.65,
						0.6,
						0.55,
						0.5,
						0.45,
						0.4,
						0.35,
						0.3,
						0.25,
						0.2,
						0.15,
						0.1,
						0.05,
						0
					]
				}
			]
		}
	]
}


-- thursday 24th of March. Or is it May? September? 2055? did i ever exist? heat death of the universe be the backdrop for all that exist?

-- get the data and graph the 0.6/0.65/0.7 in matplotlib... then get the other diagram in matplotlib, then add graphs for the all weak/1 strong/2strong versions. do i have to run any of those again? could add a search and select-all to the UI?

-- hmmmm, looks like the sequence is ballsed up, the tests only ran up to 0.55. ah crap, I had iterations at 11 instead of 21. SHould have a UI way to re-run those manually :-( Would be slow to make though.

maybe add a tags entry in sequence and results that stores the sequence tags in the results ,which can then be searched? there are kinda too many results to just browse now. can then also add a select all button?

-- added a sequence_form_tags form textarea
-- more complex than i thought. Added resultTags to results form. 


-- added a graph...  but it is so so messy. I need to explain why particular strategies are so noise-intolerant... and then figure out why they are actually found by the GA.	

-- find the result for 0.6 and 0.7 to compare-- 0.6 62260d7a4ebddf4748185351 race url http://127.0.0.1:3003/tpgame.html?source=results&results_id=62260d7a4ebddf4748185351&startorder=1,2,0,3&instructions=%5B%5B18,%22effort=4.63%22%5D,%5B89,%22drop=2%22%5D,%5B138,%22drop=3%22%5D,%5B142,%22drop=1%22%5D,%5B213,%22drop=1%22%5D,%5B243,%22effort=7.68%22%5D,%5B260,%22effort=7.44%22%5D%5D&noise_alterations=%7B%2218%22:%7B%22original_instruction%22:%5B18,%22effort=4.63%22%5D,%22altered_instruction%22:%5B18,%22effort=6.151875784572508%22%5D,%22type%22:%22random_effort%22%7D,%22138%22:%7B%22original_instruction%22:%5B138,%22drop=3%22%5D,%22altered_instruction%22:%5B138,%22drop=2%22%5D,%22type%22:%22random_drop%22%7D,%22142%22:%7B%22original_instruction%22:%5B142,%22drop=1%22%5D,%22altered_instruction%22:%5B142,%22drop=3%22%5D,%22type%22:%22random_drop%22%7D,%22213%22:%7B%22original_instruction%22:%5B213,%22drop=1%22%5D,%22altered_instruction%22:%5B213,%22drop=3%22%5D,%22type%22:%22random_drop%22%7D,%22243%22:%7B%22original_instruction%22:%5B243,%22effort=7.68%22%5D,%22altered_instruction%22:%5B243,%22effort=5.887529149495269%22%5D,%22type%22:%22random_effort%22%7D,%22260%22:%7B%22original_instruction%22:%5B260,%22effort=7.44%22%5D,%22altered_instruction%22:%5B260,%22effort=9%22%5D,%22type%22:%22random_effort%22%7D%7D&performance_failures=%7B%7D

[[18,"effort=4.63"],[89,"drop=2"],[138,"drop=3"],[142,"drop=2"],[213,"drop=1"],[243,"effort=7.68"],[260,"effort=7.44"]]
[[18,"effort=6.151875784572508"],[89,"drop=2"],[138,"drop=2"],[142,"drop=3"],[213,"drop=3"],[243,"effort=5.887529149495269"],[260,"effort=9"]]

noise 
{"18":{"original_instruction":[18,"effort=4.63"],"altered_instruction":[18,"effort=6.151875784572508"],"type":"random_effort"},"138":{"original_instruction":[138,"drop=3"],"altered_instruction":[138,"drop=2"],"type":"random_drop"},"142":{"original_instruction":[142,"drop=1"],"altered_instruction":[142,"drop=3"],"type":"random_drop"},"213":{"original_instruction":[213,"drop=1"],"altered_instruction":[213,"drop=3"],"type":"random_drop"},"243":{"original_instruction":[243,"effort=7.68"],"altered_instruction":[243,"effort=5.887529149495269"],"type":"random_effort"},"260":{"original_instruction":[260,"effort=7.44"],"altered_instruction":[260,"effort=9"],"type":"random_effort"}}


-- fruiday 25th. mad slow progress. needs to 
-- maybe I can build the search tags button?
-- started this. need to get search term then actually filter the results. 
-- then need to finish the explanation of that noise section. then on on on.

-- mumber of instructions- is it falling as noise is added, i..e does it affect the tolerance?

-- Monday 4 4. let's try do 4 hours.

-- first build that dumb tag search?

-- l ooks like |I might need to create an index on the tags field 
e.g.
db.experiment_results.createIndex( { tags: "text", notes: "text" } )

how does this work then?

db.experiment_results.find( { $text: { $search: "\"3StrongA\"" } } )

seems to work... implement this so in the Node code

-- if term is blank show all...
-- also add a dedicated Show All button ?

-- it is actually searching the tags and the notes... improve the button text 

-- add a Select All button

-- make it a proper toggle, add a gobal var to keep track of the toggle state

-- ok, this now seems to work... do i need to be able to search the sequences?

-- limit the height of the sequences list

-- might as well add the search to the sequences as well, need to keep improving this.

-- nasty issue not reading the e object in the keypress. 

also, search brings back everything... 

-- error searching sequences:  err MongoError: text index required for $text query 
need to add the index for the sequences

db.experiment_results.createIndex( { tags: "text", notes: "text" } )

had to replace the d3 key handling with jquery.

-- next up, need to get the rawdata from the other graphs so that I can build them in all via Matplotlib

-- have some data in the raw box now... bug, it is missing the 1st entry except for the first selected row? warum?

-- loop was starting at 1 not 0 for some daft reason.

-- try to remake the graph in Overleafd using matplotlib 

-- looks like the original 0.6/.65/.7 data comes from the sequence 621fb189e07d6b17109622cf ?
result ids 
621fd5bd44647e2364004b2c
621fd4f944647e2364004b2b
621fd41644647e2364004b2a

Nop. It is sequence 621fb189e07d6b17109622cf
result ids
62260d7a4ebddf4748185351
62260ccf4ebddf4748185350
62260c224ebddf474818534f

ah wait, same sequecne id as I reused it. dumb dumb dumb.
actual data 
[[[0,273.795],[1,273.562],[2,272.581],[3,271.882],[4,271.414],[5,272.315],[6,271.97],[7,270.795],[8,270.733],[9,271.662],[10,270.479],[11,271.575],[12,271.786],[13,271.834],[14,270.284],[15,270.743],[16,270.284],[17,270.739],[18,270.936],[19,271.153],[20,271.72],[21,271.701],[22,270.538],[23,271.343],[24,270.918],[25,270.47],[26,269.091],[27,271.143],[28,270.782],[29,270.49],[30,271.478],[31,271.762],[32,270.795],[33,270.947],[34,270.442],[35,271.523],[36,271.758],[37,270.162],[38,270.462],[39,271.793],[40,271.611],[41,271.155],[42,270.453],[43,269.737],[44,271.519],[45,271.096],[46,270.582],[47,271.49],[48,270.245],[49,271.149]],[[0,273.795],[1,273.562],[2,272.581],[3,271.882],[4,271.414],[5,272.315],[6,271.97],[7,270.795],[8,270.733],[9,271.662],[10,270.479],[11,271.575],[12,271.786],[13,271.834],[14,270.284],[15,270.743],[16,270.284],[17,270.739],[18,270.936],[19,271.153],[20,271.72],[21,271.701],[22,270.538],[23,271.343],[24,270.918],[25,270.47],[26,269.091],[27,271.143],[28,270.782],[29,270.49],[30,271.478],[31,271.762],[32,270.795],[33,270.947],[34,270.442],[35,271.523],[36,271.758],[37,270.162],[38,270.462],[39,271.793],[40,271.611],[41,271.155],[42,270.453],[43,269.737],[44,271.519],[45,271.096],[46,270.582],[47,271.49],[48,270.245],[49,271.149]],[[0,273.795],[1,273.562],[2,272.581],[3,271.882],[4,271.414],[5,272.315],[6,271.97],[7,270.795],[8,270.733],[9,271.662],[10,270.479],[11,271.575],[12,271.786],[13,271.834],[14,270.284],[15,270.743],[16,270.284],[17,270.739],[18,270.936],[19,271.153],[20,271.72],[21,271.701],[22,270.538],[23,271.343],[24,270.918],[25,270.47],[26,269.091],[27,271.143],[28,270.782],[29,270.49],[30,271.478],[31,271.762],[32,270.795],[33,270.947],[34,270.442],[35,271.523],[36,271.758],[37,270.162],[38,270.462],[39,271.793],[40,271.611],[41,271.155],[42,270.453],[43,269.737],[44,271.519],[45,271.096],[46,270.582],[47,271.49],[48,270.245],[49,271.149]]]

-- moving python project to main repo... do I need to add stuff to the ignore file? Oh, this top level RESEARCH folder is not the git repo. 


-- need to add the result/sequence id to the search index for results/sequences 

-- first get the indexes 
db.experiment_results.getIndexes()

index name is tags_text_notes_text
delete this with 
db.experiment_results.dropIndex( "tags_text_notes_text" )
-- now recreate it with the id 
db.experiment_results.createIndex( { _id: "text", tags: "text", notes: "text" } )
-- new index has name _id_text_tags_text_notes_text

-- do the same for the sequences 
db.experiment_sequences.dropIndex( "tags_text_notes_text" )
db.experiment_sequences.createIndex( { _id: "text", tags: "text", notes: "text" } )
-- new index _id_text_tags_text_notes_text

-- do they work?
nope. seems to not search but the id :-( 

-- need to add an OR into the find()?
db.inventory.find( { $or: [ { quantity: { $lt: 20 } }, { price: 10 } ] } )

current 
  db.getDB().collection(collectionResults).find({ $text: { $search: "\""+ searchTerm +"\"" } }
new
  db.getDB().collection(collectionResults).find({ $or: [{ "_id" : ObjectId(searchTerm), "x" : 1 }, {$text: { $search: "\""+ searchTerm +"\"" }}] }
  
  nope, returns no results... test one in Robo3T I guess 
  ObjectId("623c75494c8f6617d4055de0")


-- can't match up the data in pycharm with the results now... what the fuck am i even doing?
-- 0.6 data should be either
result 62260d7a4ebddf4748185351  or 
result 621fd5bd44647e2364004b2c (older)

-- search fails if it is not an objectid format... need to improve it; check to see if the term is a valid objectid before using it 

const ObjectId = require('mongoose').Types.ObjectId;
  function isObjectIdValid(id) {    
  if (ObjectId.isValid(id)) {
  if (String(new ObjectId(id)) === id) { 
  return true      } else {        return false      }    } else {      return false    }  }

-- seems to work, need this for sequences, too?

ok. seems to work.

find result 62260d7a4ebddf4748185351 then find the other two next to it. generate graphs again

data for all three 
[[[0,273.795],[1,273.562],[2,272.581],[3,271.882],[4,271.414],[5,272.315],[6,271.97],[7,270.795],[8,270.733],[9,271.662],[10,270.479],[11,271.575],[12,271.786],[13,271.834],[14,270.284],[15,270.743],[16,270.284],[17,270.739],[18,270.936],[19,271.153],[20,271.72],[21,271.701],[22,270.538],[23,271.343],[24,270.918],[25,270.47],[26,269.091],[27,271.143],[28,270.782],[29,270.49],[30,271.478],[31,271.762],[32,270.795],[33,270.947],[34,270.442],[35,271.523],[36,271.758],[37,270.162],[38,270.462],[39,271.793],[40,271.611],[41,271.155],[42,270.453],[43,269.737],[44,271.519],[45,271.096],[46,270.582],[47,271.49],[48,270.245],[49,271.149]],

[[0,273.795],[1,273.562],[2,272.581],[3,271.882],[4,271.414],[5,272.315],[6,271.97],[7,270.795],[8,270.733],[9,271.662],[10,270.479],[11,271.575],[12,271.786],[13,271.834],[14,270.284],[15,270.743],[16,270.284],[17,270.739],[18,270.936],[19,271.153],[20,271.72],[21,271.701],[22,270.538],[23,271.343],[24,270.918],[25,270.47],[26,269.091],[27,271.143],[28,270.782],[29,270.49],[30,271.478],[31,271.762],[32,270.795],[33,270.947],[34,270.442],[35,271.523],[36,271.758],[37,270.162],[38,270.462],[39,271.793],[40,271.611],[41,271.155],[42,270.453],[43,269.737],[44,271.519],[45,271.096],[46,270.582],[47,271.49],[48,270.245],[49,271.149]],

[[0,273.795],[1,273.562],[2,272.581],[3,271.882],[4,271.414],[5,272.315],[6,271.97],[7,270.795],[8,270.733],[9,271.662],[10,270.479],[11,271.575],[12,271.786],[13,271.834],[14,270.284],[15,270.743],[16,270.284],[17,270.739],[18,270.936],[19,271.153],[20,271.72],[21,271.701],[22,270.538],[23,271.343],[24,270.918],[25,270.47],[26,269.091],[27,271.143],[28,270.782],[29,270.49],[30,271.478],[31,271.762],[32,270.795],[33,270.947],[34,270.442],[35,271.523],[36,271.758],[37,270.162],[38,270.462],[39,271.793],[40,271.611],[41,271.155],[42,270.453],[43,269.737],[44,271.519],[45,271.096],[46,270.582],[47,271.49],[48,270.245],[49,271.149]]]

data for .6 only 
[[[0,273.303],[1,271.672],[2,272.673],[3,272.284],[4,270.447],[5,270.235],[6,270.447],[7,270.25],[8,271.334],[9,270.524],[10,270.605],[11,271.094],[12,269.514],[13,271.382],[14,270.842],[15,271.177],[16,269.435],[17,271.439],[18,271.181],[19,270.559],[20,269.901],[21,268.999],[22,270.681],[23,271.246],[24,270.034],[25,269.679],[26,269.747],[27,270.02],[28,270.337],[29,270.988],[30,268.619],[31,270.875],[32,269.7],[33,271.307],[34,269.678],[35,270.746],[36,270.951],[37,270.392],[38,271.12],[39,270.754],[40,269.852],[41,270.903],[42,270.749],[43,269.99],[44,270.268],[45,270.537],[46,271.066],[47,270.9],[48,271.138],[49,269.894]]]

NOT the same... what's a goin on? 

ahhh, all three are the same... muck.
-- hadn't updated an index, all were at 0. eejit.

[[[0,273.795],[1,273.562],[2,272.581],[3,271.882],[4,271.414],[5,272.315],[6,271.97],[7,270.795],[8,270.733],[9,271.662],[10,270.479],[11,271.575],[12,271.786],[13,271.834],[14,270.284],[15,270.743],[16,270.284],[17,270.739],[18,270.936],[19,271.153],[20,271.72],[21,271.701],[22,270.538],[23,271.343],[24,270.918],[25,270.47],[26,269.091],[27,271.143],[28,270.782],[29,270.49],[30,271.478],[31,271.762],[32,270.795],[33,270.947],[34,270.442],[35,271.523],[36,271.758],[37,270.162],[38,270.462],[39,271.793],[40,271.611],[41,271.155],[42,270.453],[43,269.737],[44,271.519],[45,271.096],[46,270.582],[47,271.49],[48,270.245],[49,271.149]],[[0,273.688],[1,270.175],[2,272.986],[3,269.272],[4,270.74],[5,271.639],[6,272.148],[7,271.923],[8,271.212],[9,271.212],[10,271.666],[11,271.289],[12,270.472],[13,270.472],[14,270.398],[15,270.472],[16,270.269],[17,270.055],[18,270.281],[19,269.113],[20,270.298],[21,271.011],[22,271.097],[23,270.602],[24,271.51],[25,271.365],[26,270.587],[27,271.807],[28,270.58],[29,271.519],[30,269.526],[31,269.548],[32,271.747],[33,271.372],[34,270.842],[35,270.753],[36,269.513],[37,270.735],[38,269.851],[39,270.992],[40,270.314],[41,270.403],[42,270.403],[43,269.964],[44,270.838],[45,270.915],[46,270.636],[47,269.129],[48,270.307],[49,270.065]],[[0,273.303],[1,271.672],[2,272.673],[3,272.284],[4,270.447],[5,270.235],[6,270.447],[7,270.25],[8,271.334],[9,270.524],[10,270.605],[11,271.094],[12,269.514],[13,271.382],[14,270.842],[15,271.177],[16,269.435],[17,271.439],[18,271.181],[19,270.559],[20,269.901],[21,268.999],[22,270.681],[23,271.246],[24,270.034],[25,269.679],[26,269.747],[27,270.02],[28,270.337],[29,270.988],[30,268.619],[31,270.875],[32,269.7],[33,271.307],[34,269.678],[35,270.746],[36,270.951],[37,270.392],[38,271.12],[39,270.754],[40,269.852],[41,270.903],[42,270.749],[43,269.99],[44,270.268],[45,270.537],[46,271.066],[47,270.9],[48,271.138],[49,269.894]]]

note that the ordering is REVERSED: 0.6 data at the END.

put new graph in paper... should switch the ordering, to match the previous one.
